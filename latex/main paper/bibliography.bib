
@article{allab_first-passage_2016,
	title = {First-passage {Time} {Estimation} of {Diffusion} {Processes} through {Time}-{Varying} {Boundaries} with an {Application} in {Finance}},
	volume = {6},
	issn = {1927-7040, 1927-7032},
	url = {http://www.ccsenet.org/journal/index.php/ijsp/article/view/63088},
	doi = {10.5539/ijsp.v6n1p59},
	abstract = {In this paper, we develop a Monte Carlo based algorithm for estimating the FPT (ﬁrst passage time) density of the solution of a one-dimensional time-homogeneous SDE (stochastic diﬀerential equation) through a time-dependent frontier. We consider Brownian bridges as well as local Daniels curve approximations to obtain tractable estimations of the FPT probability between successive points of a simulated path of the process. Under mild assumptions, a (unique) Daniels curve local approximation can easily be obtained by explicitly solving a non-linear system of equations.},
	language = {en},
	number = {1},
	urldate = {2022-12-20},
	journal = {International Journal of Statistics and Probability},
	author = {Allab, Imene and Watier, Francois},
	month = dec,
	year = {2016},
	pages = {59},
	file = {Allab en Watier - 2016 - First-passage Time Estimation of Diffusion Process.pdf:C\:\\Users\\Admin\\Zotero\\storage\\8DTMPTXR\\Allab en Watier - 2016 - First-passage Time Estimation of Diffusion Process.pdf:application/pdf},
}

@article{milstein_simulation_1999,
	title = {Simulation of a space-time bounded diffusion},
	volume = {9},
	issn = {1050-5164},
	url = {https://projecteuclid.org/journals/annals-of-applied-probability/volume-9/issue-3/Simulation-of-a-space-time-bounded-diffusion/10.1214/aoap/1029962812.full},
	doi = {10.1214/aoap/1029962812},
	language = {en},
	number = {3},
	urldate = {2022-12-20},
	journal = {The Annals of Applied Probability},
	author = {Milstein, G. N. and Tretyakov, M. V.},
	month = aug,
	year = {1999},
	file = {Milstein en Tretyakov - 1999 - Simulation of a space-time bounded diffusion.pdf:C\:\\Users\\Admin\\Zotero\\storage\\3A6SZGK6\\Milstein en Tretyakov - 1999 - Simulation of a space-time bounded diffusion.pdf:application/pdf},
}

@article{hwang_simulationtabulation_2001,
	title = {The {Simulation}–{Tabulation} {Method} for {Classical} {Diffusion} {Monte} {Carlo}},
	volume = {174},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999101969475},
	doi = {10.1006/jcph.2001.6947},
	language = {en},
	number = {2},
	urldate = {2022-12-18},
	journal = {Journal of Computational Physics},
	author = {Hwang, Chi-Ok and Given, James A. and Mascagni, Michael},
	month = dec,
	year = {2001},
	pages = {925--946},
	file = {Hwang e.a. - 2001 - The Simulation–Tabulation Method for Classical Dif.pdf:C\:\\Users\\Admin\\Zotero\\storage\\BTSXYC8S\\Hwang e.a. - 2001 - The Simulation–Tabulation Method for Classical Dif.pdf:application/pdf},
}

@article{hwang_analysis_2003,
	title = {Analysis and comparison of {Green}’s function first-passage algorithms with “{Walk} on {Spheres}” algorithms},
	volume = {63},
	issn = {03784754},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378475403000910},
	doi = {10.1016/S0378-4754(03)00091-0},
	abstract = {We analyze the optimization of the running times of Green’s function ﬁrst-passage (GFFP) algorithms. The running times for these new ﬁrst-passage (FP) algorithms [1–4], which use exact Green’s functions for the Laplacian to eliminate the absorption layer in the “walk on spheres” (WOS) method [5–9], are compared with those for WOS algorithms. It has been empirically observed that GFFP algorithms are more eﬃcient than WOS algorithms when high accuracy is required [2–4]. Additionally, it has been observed that there is always an optimal distance from the surface of the absorbing boundary, δI , for a GFFP algorithm within which a FP surface can be permitted to intersect the boundary [2–4]. In this paper, we will provide a rigorous complexity analysis consistent with these observations. This analysis is based on estimating the numbers of WOS and GFFP steps needed for absorption on the boundary, and the complexity and running times of each WOS and GFFP step. As an illustration, we analyze the running times for calculating the capacitance of the unit cube using both GFFP and WOS.},
	language = {en},
	number = {6},
	urldate = {2022-12-18},
	journal = {Mathematics and Computers in Simulation},
	author = {Hwang, Chi-Ok and Mascagni, Michael},
	month = nov,
	year = {2003},
	pages = {605--613},
	file = {Hwang en Mascagni - 2003 - Analysis and comparison of Green’s function first-.pdf:C\:\\Users\\Admin\\Zotero\\storage\\HBPK37PS\\Hwang en Mascagni - 2003 - Analysis and comparison of Green’s function first-.pdf:application/pdf},
}

@article{kosztin_introduction_1996,
	title = {Introduction to the diffusion {Monte} {Carlo} method},
	volume = {64},
	issn = {0002-9505, 1943-2909},
	url = {http://aapt.scitation.org/doi/10.1119/1.18168},
	doi = {10.1119/1.18168},
	language = {en},
	number = {5},
	urldate = {2022-12-13},
	journal = {American Journal of Physics},
	author = {Kosztin, Ioan and Faber, Byron and Schulten, Klaus},
	month = may,
	year = {1996},
	pages = {633--644},
	file = {Kosztin e.a. - 1996 - Introduction to the diffusion Monte Carlo method.pdf:C\:\\Users\\Admin\\Zotero\\storage\\UJQSNZJ3\\Kosztin e.a. - 1996 - Introduction to the diffusion Monte Carlo method.pdf:application/pdf},
}

@misc{yilmazer_solving_2022,
	title = {Solving {Inverse} {PDE} {Problems} using {Grid}-{Free} {Monte} {Carlo} {Estimators}},
	url = {http://arxiv.org/abs/2208.02114},
	abstract = {Modeling physical phenomena like heat transport and diffusion is crucially dependent on the numerical solution of partial differential equations (PDEs). A PDE solver finds the solution given coefficients and a boundary condition, whereas an inverse PDE solver goes the opposite way and reconstructs these inputs from an existing solution. In this article, we investigate techniques for solving inverse PDE problems using a gradient-based methodology. Conventional PDE solvers based on the finite element method require a domain meshing step that can be fragile and costly. Grid-free Monte Carlo methods instead stochastically sample paths using variations of the walk on spheres algorithm to construct an unbiased estimator of the solution. The uncanny similarity of these methods to physically-based rendering algorithms has been observed by several recent works. In the area of rendering, recent progress has led to the development of efficient unbiased derivative estimators. They solve an adjoint form of the problem and exploit arithmetic invertibility to compute gradients using a constant amount of memory and linear time complexity. Could these two lines of work be combined to compute cheap parametric derivatives of a grid-free PDE solver? We investigate this question and present preliminary results. CCS Concepts: • Mathematics of computing → Partial differential equations; • Computing methodologies → Rendering.},
	language = {en},
	urldate = {2022-12-13},
	publisher = {arXiv},
	author = {Yılmazer, Ekrem Fatih and Vicini, Delio and Jakob, Wenzel},
	month = aug,
	year = {2022},
	note = {arXiv:2208.02114 [cs, math]},
	keywords = {68U05, Computer Science - Graphics, Mathematics - Analysis of PDEs},
	annote = {Comment: 9 pages (2 pages references and appendix), 9 figures},
	file = {Yılmazer e.a. - 2022 - Solving Inverse PDE Problems using Grid-Free Monte.pdf:C\:\\Users\\Admin\\Zotero\\storage\\RQAZ53HP\\Yılmazer e.a. - 2022 - Solving Inverse PDE Problems using Grid-Free Monte.pdf:application/pdf},
}

@article{hwang_off-centered_2015,
	title = {Off-centered “{Walk}-on-{Spheres}” ({WOS}) algorithm},
	volume = {303},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999115006646},
	doi = {10.1016/j.jcp.2015.10.002},
	language = {en},
	urldate = {2022-12-13},
	journal = {Journal of Computational Physics},
	author = {Hwang, Chi-Ok and Hong, Sungpyo and Kim, Jinwoo},
	month = dec,
	year = {2015},
	pages = {331--335},
	file = {Hwang e.a. - 2015 - Off-centered “Walk-on-Spheres” (WOS) algorithm.pdf:C\:\\Users\\Admin\\Zotero\\storage\\3YHCI5ZF\\Hwang e.a. - 2015 - Off-centered “Walk-on-Spheres” (WOS) algorithm.pdf:application/pdf},
}

@article{deaconu_random_2006,
	title = {A {Random} {Walk} on {Rectangles} {Algorithm}},
	volume = {8},
	issn = {1387-5841, 1573-7713},
	url = {http://link.springer.com/10.1007/s11009-006-7292-3},
	doi = {10.1007/s11009-006-7292-3},
	abstract = {In this article, we introduce an algorithm that simulates eﬃciently the ﬁrst exit time and position from a rectangle (or a parallelepiped) for a Brownian motion that starts at any point inside. This method provides an exact way to simulate the ﬁrst exit time and position from any polygonal domain and then to solve some Dirichlet problems, whatever the dimension. This method can be used as a replacement or complement of the method of the random walk on spheres and can be easily adapted to deal with Neumann boundary conditions or Brownian motion with a constant drift.},
	language = {en},
	number = {1},
	urldate = {2022-12-13},
	journal = {Methodology and Computing in Applied Probability},
	author = {Deaconu, Madalina and Lejay, Antoine},
	month = mar,
	year = {2006},
	pages = {135--151},
	file = {Deaconu en Lejay - 2006 - A Random Walk on Rectangles Algorithm.pdf:C\:\\Users\\Admin\\Zotero\\storage\\LETY9EC9\\Deaconu en Lejay - 2006 - A Random Walk on Rectangles Algorithm.pdf:application/pdf},
}

@misc{noauthor_reflection_2022,
	title = {Reflection principle ({Wiener} process)},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Reflection_principle_(Wiener_process)&oldid=1111342822},
	abstract = {In the theory of probability for stochastic processes, the reflection principle for a Wiener process states that if the path of a Wiener process f(t)  reaches a value f(s) = a at time t = s,  then the subsequent path after time s has the same distribution as the reflection of the subsequent path about the value a. More formally, the reflection principle refers to a lemma concerning the distribution of the supremum of the Wiener process, or Brownian motion. The result relates the distribution of the supremum of Brownian motion up to time t to the distribution of the process at time t. It is a corollary of the strong Markov property of Brownian motion.},
	language = {en},
	urldate = {2022-12-08},
	journal = {Wikipedia},
	month = sep,
	year = {2022},
	note = {Page Version ID: 1111342822},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\LHGS64H3\\Reflection_principle_(Wiener_process).html:text/html},
}

@article{metwally_using_2002,
	title = {Using {Brownian} {Bridge} for {Fast} {Simulation} of {Jump}-{Diffusion} {Processes} and {Barrier} {Options}},
	volume = {10},
	issn = {1074-1240, 2168-8524},
	url = {http://jod.pm-research.com/lookup/doi/10.3905/jod.2002.319189},
	doi = {10.3905/jod.2002.319189},
	language = {en},
	number = {1},
	urldate = {2022-12-08},
	journal = {The Journal of Derivatives},
	author = {Metwally, Steve A.K. and Atiya, Amir F.},
	month = aug,
	year = {2002},
	pages = {43--54},
	file = {Metwally en Atiya - 2002 - Using Brownian Bridge for Fast Simulation of Jump-.pdf:C\:\\Users\\Admin\\Zotero\\storage\\ABLIPAX8\\Metwally en Atiya - 2002 - Using Brownian Bridge for Fast Simulation of Jump-.pdf:application/pdf},
}

@article{beskos_varepsilon-strong_2012,
	title = {\${\textbackslash}varepsilon\$-{Strong} simulation of the {Brownian} path},
	volume = {18},
	issn = {1350-7265},
	url = {https://projecteuclid.org/journals/bernoulli/volume-18/issue-4/varepsilon-Strong-simulation-of-the-Brownian-path/10.3150/11-BEJ383.full},
	doi = {10.3150/11-BEJ383},
	language = {en},
	number = {4},
	urldate = {2022-12-08},
	journal = {Bernoulli},
	author = {Beskos, Alexandros and Peluchetti, Stefano and Roberts, Gareth},
	month = nov,
	year = {2012},
	file = {Beskos e.a. - 2012 - \$varepsilon\$-Strong simulation of the Brownian pa.pdf:C\:\\Users\\Admin\\Zotero\\storage\\G8BZTKXZ\\Beskos e.a. - 2012 - \$varepsilon\$-Strong simulation of the Brownian pa.pdf:application/pdf},
}

@misc{saz_answer_2014,
	title = {Answer to "{Density} of first hitting time of {Brownian} motion with drift"},
	url = {https://math.stackexchange.com/a/1055713},
	urldate = {2022-12-08},
	journal = {Mathematics Stack Exchange},
	author = {saz},
	month = dec,
	year = {2014},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\9UBT4LFE\\density-of-first-hitting-time-of-brownian-motion-with-drift.html:text/html},
}

@misc{saz_answer_2014-1,
	title = {Answer to "{Density} of first hitting time of {Brownian} motion with drift"},
	url = {https://math.stackexchange.com/a/1055713},
	urldate = {2022-12-08},
	journal = {Mathematics Stack Exchange},
	author = {saz},
	month = dec,
	year = {2014},
}

@misc{guy_answer_2017,
	title = {Answer to "{Density} of first hitting time of {Brownian} motion with drift"},
	url = {https://math.stackexchange.com/a/2584850},
	urldate = {2022-12-08},
	journal = {Mathematics Stack Exchange},
	author = {Guy, Comic Book},
	month = dec,
	year = {2017},
}

@misc{guy_answer_2017-1,
	title = {Answer to "{Distribution} of hitting time of line by {Brownian} motion"},
	url = {https://math.stackexchange.com/a/2582640},
	urldate = {2022-12-08},
	journal = {Mathematics Stack Exchange},
	author = {Guy, Comic Book},
	month = dec,
	year = {2017},
}

@article{xu_distribution_2013,
	title = {On the {Distribution} of {First} {Exit} {Time} for {Brownian} {Motion} with {Double} {Linear} {Time}-{Dependent} {Barriers}},
	volume = {2013},
	issn = {2090-5572},
	url = {https://www.hindawi.com/journals/isrn/2013/865347/},
	doi = {10.1155/2013/865347},
	abstract = {This paper focuses on the first exit time for a Brownian motion with a double linear time-dependent barrier specified by
              
                
                  y
                  =
                  a
                  +
                  b
                  t
                
              
              ,
              
                
                  y
                  =
                  c
                  t
                
              
              , (
              
                a
                {\textgreater}
                0
              
              ,
              
                b
                {\textless}
                0
              
              ,
              
                c
                {\textgreater}
                0
              
              ). We are concerned in this paper with the distribution of the Brownian motion hitting the upper barrier before hitting the lower linear barrier. The main method we applied here is the Girsanov transform formula. As a result, we expressed the density of such exit time in terms of a finite series. This result principally provides us an analytical expression for the distribution of the aforementioned exit time and  an easy way to compute the distribution of first exit time numerically.},
	language = {en},
	urldate = {2022-12-08},
	journal = {ISRN Applied Mathematics},
	author = {Xu, Lin and Zhu, Dongjin},
	month = sep,
	year = {2013},
	pages = {1--5},
	file = {Xu en Zhu - 2013 - On the Distribution of First Exit Time for Brownia.pdf:C\:\\Users\\Admin\\Zotero\\storage\\R3QCYSHV\\Xu en Zhu - 2013 - On the Distribution of First Exit Time for Brownia.pdf:application/pdf},
}

@misc{dieker_euler_2017,
	title = {On the {Euler} discretization error of {Brownian} motion about random times},
	url = {http://arxiv.org/abs/1708.04356},
	abstract = {In this paper we derive weak limits for the discretization errors of sampling barrierhitting and extreme events of Brownian motion by using the Euler discretization simulation method. Speciﬁcally, we consider the Euler discretization approximation of Brownian motion to sample barrier-hitting events, i.e. hitting for the ﬁrst time a deterministic “barrier” function; and to sample extreme events, i.e. attaining a minimum on a given compact time interval or unbounded closed time interval. For each case we study the discretization error between the actual time the event occurs versus the time the event occurs for the discretized path, and also the discretization error on the position of the Brownian motion at these times. We show limits in distribution for the discretization errors normalized by their convergence rate, and give closed-form analytic expressions for the limiting random variables. Additionally, we use these limits to study the asymptotic behaviour of Gaussian random walks in the following situations: (1.) the overshoot of a Gaussian walk above a barrier that goes to inﬁnity; (2.) the minimum of a Gaussian walk compared to the minimum of the Brownian motion obtained when interpolating the Gaussian walk with Brownian bridges, both up to the same time horizon that goes to inﬁnity; and (3.) the global minimum of a Gaussian walk compared to the global minimum of the Brownian motion obtained when interpolating the Gaussian walk with Brownian bridges, when both have the same positive drift decreasing to zero. In deriving these limits in distribution we provide a uniﬁed framew√ork to understand the relation between several papers where the constant −ζ(1/2)/ 2π has appeared, where ζ is the Riemann zeta function. In particular, we show that this constant is the mean of some of the limiting distributions we derive.},
	language = {en},
	urldate = {2022-12-08},
	publisher = {arXiv},
	author = {Dieker, A. B. and Lagos, Guido},
	month = aug,
	year = {2017},
	note = {arXiv:1708.04356 [math]},
	keywords = {Mathematics - Probability},
	file = {Dieker en Lagos - 2017 - On the Euler discretization error of Brownian moti.pdf:C\:\\Users\\Admin\\Zotero\\storage\\BPSGSE6D\\Dieker en Lagos - 2017 - On the Euler discretization error of Brownian moti.pdf:application/pdf},
}

@incollection{devroye_exact_2010,
	address = {Heidelberg},
	title = {On {Exact} {Simulation} {Algorithms} for {Some} {Distributions} {Related} to {Brownian} {Motion} and {Brownian} {Meanders}},
	isbn = {978-3-7908-2597-8 978-3-7908-2598-5},
	url = {http://link.springer.com/10.1007/978-3-7908-2598-5_1},
	abstract = {We survey and develop exact random variate generators for several distributions related to Brownian motion, Brownian bridge, Brownian excursion, Brownian meander, and related restricted Brownian motion processes. Various parameters such as maxima and ﬁrst passage times are dealt with at length. We are particularly interested in simulating process variables in expected time uniformly bounded over all parameters.},
	language = {en},
	urldate = {2022-12-08},
	booktitle = {Recent {Developments} in {Applied} {Probability} and {Statistics}},
	publisher = {Physica-Verlag HD},
	author = {Devroye, Luc},
	editor = {Devroye, Luc and Karasözen, Bülent and Kohler, Michael and Korn, Ralf},
	year = {2010},
	doi = {10.1007/978-3-7908-2598-5_1},
	pages = {1--35},
	file = {Devroye - 2010 - On Exact Simulation Algorithms for Some Distributi.pdf:C\:\\Users\\Admin\\Zotero\\storage\\IKVR3JRG\\Devroye - 2010 - On Exact Simulation Algorithms for Some Distributi.pdf:application/pdf},
}

@article{luengo_survey_2020,
	title = {A {Survey} of {Monte} {Carlo} {Methods} for {Parameter} {Estimation}},
	volume = {2020},
	issn = {1687-6180},
	url = {http://arxiv.org/abs/2107.11820},
	doi = {10.1186/s13634-020-00675-6},
	abstract = {Statistical signal processing applications usually require the estimation of some parameters of interest given a set of observed data. These estimates are typically obtained either by solving a multi-variate optimization problem, as in the maximum likelihood (ML) or maximum a posteriori (MAP) estimators, or by performing a multi-dimensional integration, as in the minimum mean squared error (MMSE) estimators. Unfortunately, analytical expressions for these estimators cannot be found in most real-world applications, and the Monte Carlo (MC) methodology is one feasible approach. MC methods proceed by drawing random samples, either from the desired distribution or from a simpler one, and using them to compute consistent estimators. The most important families of MC algorithms are Markov chain MC (MCMC) and importance sampling (IS). On the one hand, MCMC methods draw samples from a proposal density, building then an ergodic Markov chain whose stationary distribution is the desired distribution by accepting or rejecting those candidate samples as the new state of the chain. On the other hand, IS techniques draw samples from a simple proposal density, and then assign them suitable weights that measure their quality in some appropriate way. In this paper, we perform a thorough review of MC methods for the estimation of static parameters in signal processing applications. A historical note on the development of MC schemes is also provided, followed by the basic MC method and a brief description of the rejection sampling (RS) algorithm, as well as three sections describing many of the most relevant MCMC and IS algorithms, and their combined use. Finally, ﬁve numerical examples (including the estimation of the parameters of a chaotic system, a localization problem in wireless sensor networks and a spectral analysis application) are provided in order to demonstrate the performance of the described approaches.},
	language = {en},
	number = {1},
	urldate = {2022-12-07},
	journal = {EURASIP Journal on Advances in Signal Processing},
	author = {Luengo, D. and Martino, L. and Bugallo, M. and Elvira, V. and S ärkkä, S.},
	month = dec,
	year = {2020},
	note = {arXiv:2107.11820 [cs, eess, math, stat]},
	keywords = {Computer Science - Artificial Intelligence, Electrical Engineering and Systems Science - Signal Processing, Mathematics - Numerical Analysis, Statistics - Computation},
	pages = {25},
	file = {Luengo e.a. - 2020 - A Survey of Monte Carlo Methods for Parameter Esti.pdf:C\:\\Users\\Admin\\Zotero\\storage\\AW7RXXX8\\Luengo e.a. - 2020 - A Survey of Monte Carlo Methods for Parameter Esti.pdf:application/pdf},
}

@article{browne_survey_2012,
	title = {A {Survey} of {Monte} {Carlo} {Tree} {Search} {Methods}},
	volume = {4},
	issn = {1943-068X, 1943-0698},
	url = {http://ieeexplore.ieee.org/document/6145622/},
	doi = {10.1109/TCIAIG.2012.2186810},
	abstract = {Monte Carlo Tree Search (MCTS) is a recently proposed search method that combines the precision of tree search with the generality of random sampling. It has received considerable interest due to its spectacular success in the difﬁcult problem of computer Go, but has also proved beneﬁcial in a range of other domains. This paper is a survey of the literature to date, intended to provide a snapshot of the state of the art after the ﬁrst ﬁve years of MCTS research. We outline the core algorithm’s derivation, impart some structure on the many variations and enhancements that have been proposed, and summarise the results from the key game and non-game domains to which MCTS methods have been applied. A number of open research questions indicate that the ﬁeld is ripe for future work.},
	language = {en},
	number = {1},
	urldate = {2022-12-07},
	journal = {IEEE Transactions on Computational Intelligence and AI in Games},
	author = {Browne, Cameron B. and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M. and Cowling, Peter I. and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
	month = mar,
	year = {2012},
	pages = {1--43},
	file = {Browne e.a. - 2012 - A Survey of Monte Carlo Tree Search Methods.pdf:C\:\\Users\\Admin\\Zotero\\storage\\E9YVZ4L9\\Browne e.a. - 2012 - A Survey of Monte Carlo Tree Search Methods.pdf:application/pdf},
}

@misc{llorente_survey_2021,
	title = {A survey of {Monte} {Carlo} methods for noisy and costly densities with application to reinforcement learning},
	url = {http://arxiv.org/abs/2108.00490},
	abstract = {This survey gives an overview of Monte Carlo methodologies using surrogate models, for dealing with densities which are intractable, costly, and/or noisy. This type of problem can be found in numerous real-world scenarios, including stochastic optimization and reinforcement learning, where each evaluation of a density function may incur some computationally-expensive or even physical (real-world activity) cost, likely to give diﬀerent results each time. The surrogate model does not incur this cost, but there are important trade-oﬀs and considerations involved in the choice and design of such methodologies. We classify the diﬀerent methodologies into three main classes and describe speciﬁc instances of algorithms under a uniﬁed notation. A modular scheme which encompasses the considered methods is also presented. A range of application scenarios is discussed, with special attention to the likelihood-free setting and reinforcement learning. Several numerical comparisons are also provided.},
	language = {en},
	urldate = {2022-12-07},
	publisher = {arXiv},
	author = {Llorente, F. and Martino, L. and Read, J. and Delgado, D.},
	month = sep,
	year = {2021},
	note = {arXiv:2108.00490 [cs, stat]},
	keywords = {Statistics - Computation, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Llorente e.a. - 2021 - A survey of Monte Carlo methods for noisy and cost.pdf:C\:\\Users\\Admin\\Zotero\\storage\\ZXRFKLSV\\Llorente e.a. - 2021 - A survey of Monte Carlo methods for noisy and cost.pdf:application/pdf},
}

@misc{herrmann_exact_2021,
	title = {Exact simulation of the first passage time through a given level for jump diffusions},
	url = {http://arxiv.org/abs/2106.05560},
	abstract = {Continuous-time stochastic processes play an important role in the description of random phenomena, it is therefore of prime interest to study particular variables depending on their paths, like stopping time for example. One approach consists in pointing out explicit expressions of the probability distributions, an other approach is rather based on the numerical generation of the random variables. We propose an algorithm in order to generate the ﬁrst passage time through a given level of a one-dimensional jump diﬀusion. This process satisﬁes a stochastic diﬀerential equation driven by a Brownian motion and subject to random shocks characterized by an independent Poisson process. Our algorithm belongs to the family of rejection sampling procedures, also called exact simulation in this context: the outcome of the algorithm and the stopping time under consideration are identically distributed. It is based on both the exact simulation of the diﬀusion at a given time and on the exact simulation of ﬁrst passage time for continuous diﬀusions. It is therefore based on an extension of the algorithm introduced by Herrmann and Zucca [16] in the continuous framework. The challenge here is to generate the exact position of a continuous diﬀusion conditionally to the fact that the given level has not been reached before. We present the construction of the algorithm and give numerical illustrations, conditions on the recurrence of jump diﬀusions are also discussed.},
	language = {en},
	urldate = {2022-12-07},
	publisher = {arXiv},
	author = {Herrmann, Samuel and Massin, Nicolas},
	month = jun,
	year = {2021},
	note = {arXiv:2106.05560 [math]},
	keywords = {Mathematics - Probability},
	file = {Herrmann en Massin - 2021 - Exact simulation of the first passage time through.pdf:C\:\\Users\\Admin\\Zotero\\storage\\DBB4B6I2\\Herrmann en Massin - 2021 - Exact simulation of the first passage time through.pdf:application/pdf},
}

@misc{azzone_fast_2022,
	title = {A fast {Monte} {Carlo} scheme for additive processes and option pricing},
	url = {http://arxiv.org/abs/2112.08291},
	abstract = {In this paper, we present a very fast Monte Carlo scheme for additive processes: the computational time is of the same order of magnitude of standard algorithms for Brownian motions. We analyze in detail numerical error sources and propose a technique that reduces the two major sources of error. We also compare our results with a benchmark method: the jump simulation with Gaussian approximation.},
	language = {en},
	urldate = {2022-12-07},
	publisher = {arXiv},
	author = {Azzone, Michele and Baviera, Roberto},
	month = nov,
	year = {2022},
	note = {arXiv:2112.08291 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance},
	file = {Azzone en Baviera - 2022 - A fast Monte Carlo scheme for additive processes a.pdf:C\:\\Users\\Admin\\Zotero\\storage\\NKJIF6K7\\Azzone en Baviera - 2022 - A fast Monte Carlo scheme for additive processes a.pdf:application/pdf},
}

@inproceedings{binder_complexity_2009,
	title = {The complexity of simulating {Brownian} {Motion}},
	isbn = {978-0-89871-680-1 978-1-61197-306-8},
	url = {https://epubs.siam.org/doi/10.1137/1.9781611973068.7},
	doi = {10.1137/1.9781611973068.7},
	abstract = {We analyze the complexity of the Walk on Spheres algorithm for simulating Brownian Motion in a domain Ω ⊂ Rd. The algorithm, which was ﬁrst proposed in the 1950s, produces samples from the hitting probability distribution of the Brownian Motion process on ∂Ω within an error of ε. The algorithm is used as a building block for solving a variety of diﬀerential equations, including the Dirichlet Problem.},
	language = {en},
	urldate = {2022-12-07},
	booktitle = {Proceedings of the {Twentieth} {Annual} {ACM}-{SIAM} {Symposium} on {Discrete} {Algorithms}},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Binder, Ilia and Braverman, Mark},
	month = jan,
	year = {2009},
	pages = {58--67},
	file = {Binder en Braverman - 2009 - The complexity of simulating Brownian Motion.pdf:C\:\\Users\\Admin\\Zotero\\storage\\9LATAZYY\\Binder en Braverman - 2009 - The complexity of simulating Brownian Motion.pdf:application/pdf},
}

@article{casella_exact_2011,
	title = {Exact {Simulation} of {Jump}-{Diffusion} {Processes} with {Monte} {Carlo} {Applications}},
	volume = {13},
	issn = {1387-5841, 1573-7713},
	url = {http://link.springer.com/10.1007/s11009-009-9163-1},
	doi = {10.1007/s11009-009-9163-1},
	language = {en},
	number = {3},
	urldate = {2022-12-05},
	journal = {Methodology and Computing in Applied Probability},
	author = {Casella, Bruno and Roberts, Gareth O.},
	month = sep,
	year = {2011},
	pages = {449--473},
	file = {Casella en Roberts - 2011 - Exact Simulation of Jump-Diffusion Processes with .pdf:C\:\\Users\\Admin\\Zotero\\storage\\6PDHDU6J\\Casella en Roberts - 2011 - Exact Simulation of Jump-Diffusion Processes with .pdf:application/pdf},
}

@misc{xia_multilevel_2011,
	title = {Multilevel {Monte} {Carlo} method for jump-diffusion {SDEs}},
	url = {http://arxiv.org/abs/1106.4730},
	abstract = {We investigate the extension of the multilevel Monte Carlo path simulation method to jump-diﬀusion SDEs. We consider models with ﬁnite rate activity , using a jump-adapted discretisation in which the jump times are computed and added to the standard uniform discretisation times. The key component in multilevel analysis is the calculation of an expected payoﬀ diﬀerence between a coarse path simulation and a ﬁne path simulation with twice as many timesteps. If the Poisson jump rate is constant, the jump times are the same on both paths and the multilevel extension is relatively straightforward, but the implementation is more complex in the case of state-dependent jump rates for which the jump times naturally diﬀer.},
	language = {en},
	urldate = {2022-12-05},
	publisher = {arXiv},
	author = {Xia, Yuan},
	month = jun,
	year = {2011},
	note = {arXiv:1106.4730 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance},
	annote = {Comment: 36 pages, 10 figures},
	file = {Xia - 2011 - Multilevel Monte Carlo method for jump-diffusion S.pdf:C\:\\Users\\Admin\\Zotero\\storage\\YGXG767H\\Xia - 2011 - Multilevel Monte Carlo method for jump-diffusion S.pdf:application/pdf},
}

@article{devreese_path_2010,
	title = {Path integral approach to {Asian} options in the {Black}-{Scholes} model},
	volume = {389},
	issn = {03784371},
	url = {http://arxiv.org/abs/0906.4456},
	doi = {10.1016/j.physa.2009.10.020},
	abstract = {We derive a closed-form solution for the price of an average price as well as an average strike geometric Asian option, by making use of the path integral formulation. Our results are compared to a numerical Monte Carlo simulation. We also develop a pricing formula for an Asian option with a barrier on a control process, combining the method of images with a partitioning of the set of paths according to the average along the path. This formula is exact when the correlation is zero, and is approximate when the correlation increases.},
	language = {en},
	number = {4},
	urldate = {2022-12-05},
	journal = {Physica A: Statistical Mechanics and its Applications},
	author = {Devreese, Jeroen P. A. and Lemmens, Damiaan and Tempere, Jacques},
	month = feb,
	year = {2010},
	note = {arXiv:0906.4456 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance, Quantitative Finance - Pricing of Securities},
	pages = {780--788},
	annote = {Comment: 13 pages, 3 figures, updated version has added references to path integral literature},
	file = {Devreese e.a. - 2010 - Path integral approach to Asian options in the Bla.pdf:C\:\\Users\\Admin\\Zotero\\storage\\TRU3Y9RR\\Devreese e.a. - 2010 - Path integral approach to Asian options in the Bla.pdf:application/pdf},
}

@article{capuozzo_path_2021,
	title = {Path integral {Monte} {Carlo} method for option pricing},
	volume = {581},
	issn = {03784371},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378437121005045},
	doi = {10.1016/j.physa.2021.126231},
	abstract = {The Markov chain Monte Carlo (MCMC) method, in conjunction with the Metropolis–Hastings algorithm, is used to simulate the path integral for the Black–Scholes–Merton model of option pricing. After a brief derivation of the path integral solution of this model, we develop the MCMC method by discretizing the path integral on a time lattice and evaluating this discretized form for various scenarios. Particular attention is paid to the existence of autocorrelations, their decay with the number of sweeps, and the resulting estimate of the corresponding errors. After testing our approach against closed-form solutions, we demonstrate the utility and flexibility of our method with applications to non-Gaussian models.},
	language = {en},
	urldate = {2022-12-05},
	journal = {Physica A: Statistical Mechanics and its Applications},
	author = {Capuozzo, Pietro and Panella, Emanuele and Schettini Gherardini, Tancredi and Vvedensky, Dimitri D.},
	month = nov,
	year = {2021},
	pages = {126231},
	file = {Capuozzo e.a. - 2021 - Path integral Monte Carlo method for option pricin.pdf:C\:\\Users\\Admin\\Zotero\\storage\\4543G9SW\\Capuozzo e.a. - 2021 - Path integral Monte Carlo method for option pricin.pdf:application/pdf},
}

@misc{noauthor_elsevier_nodate,
	title = {Elsevier {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0378437121005045?token=38A128C3E0B8034BBA0E6F841BAC35240380923C7C4785BDA2B7E151B619375FE2B88589F9B8277F87C5EDC8093578DA&originRegion=eu-west-1&originCreation=20221205170926},
	language = {en},
	urldate = {2022-12-05},
	doi = {10.1016/j.physa.2021.126231},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\SEXX3WVR\\S0378437121005045.html:text/html},
}

@misc{noauthor_path_nodate,
	title = {Path integral approach to {Asian} options in the {Black}–{Scholes} model},
	url = {https://reader.elsevier.com/reader/sd/pii/S037843710900870X?token=23DAA323684A9DC3C7E8FD0A8FE310A6D7427074F544EF16E54533EA80C45EA211E7AAAF1F249986DD15FDEABC3871EA&originRegion=eu-west-1&originCreation=20221204213338},
	language = {en},
	urldate = {2022-12-04},
	doi = {10.1016/j.physa.2009.10.020},
	file = {Ingediende versie:C\:\\Users\\Admin\\Zotero\\storage\\JRSHVBT5\\Elsevier Enhanced Reader.pdf:application/pdf;Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\DSD5C8SC\\S037843710900870X.html:text/html},
}

@article{bormetti_pricing_2006,
	title = {Pricing exotic options in a path integral approach},
	volume = {6},
	issn = {1469-7688, 1469-7696},
	url = {http://www.tandfonline.com/doi/abs/10.1080/14697680500510878},
	doi = {10.1080/14697680500510878},
	abstract = {In the framework of Black-Scholes-Merton model of ﬁnancial derivatives, a path integral approach to option pricing is presented. A general formula to price European path dependent options on multidimensional assets is obtained and implemented by means of various ﬂexible and eﬃcient algorithms. As an example, we detail the cases of Asian, barrier knock out, reverse cliquet and basket call options, evaluating prices and Greeks. The numerical results are compared with those obtained with other procedures used in quantitative ﬁnance and found to be in good agreement. In particular, when pricing at-the-money and out-of-the-money options, the path integral approach exhibits competitive performances.},
	language = {en},
	number = {1},
	urldate = {2022-12-04},
	journal = {Quantitative Finance},
	author = {Bormetti, G. and Montagna, G. and Moreni, N. and Nicrosini, O.},
	month = feb,
	year = {2006},
	pages = {55--66},
	file = {Bormetti e.a. - 2006 - Pricing exotic options in a path integral approach.pdf:C\:\\Users\\Admin\\Zotero\\storage\\5RXL3P32\\Bormetti e.a. - 2006 - Pricing exotic options in a path integral approach.pdf:application/pdf},
}

@misc{noauthor_multilevel_2022,
	title = {Multilevel {Monte} {Carlo} method (wikipedia)},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Multilevel_Monte_Carlo_method&oldid=1070124752},
	abstract = {Multilevel Monte Carlo (MLMC) methods in numerical analysis are algorithms for computing expectations that arise in stochastic simulations. Just as Monte Carlo methods, they rely on repeated random sampling, but these samples are taken on different levels of accuracy. MLMC methods can greatly reduce the computational cost of standard Monte Carlo methods by taking most samples with a low accuracy and corresponding low cost, and only very few samples are taken at high accuracy and corresponding high cost.},
	language = {en},
	urldate = {2022-12-04},
	journal = {Wikipedia},
	month = feb,
	year = {2022},
	note = {Page Version ID: 1070124752},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\NSTZZI8D\\Multilevel_Monte_Carlo_method.html:text/html},
}

@article{zhu_calculating_2007,
	title = {{CALCULATING} {THE} {EARLY} {EXERCISE} {BOUNDARY} {OF} {AMERICAN} {PUT} {OPTIONS} {WITH} {AN} {APPROXIMATION} {FORMULA}},
	volume = {10},
	issn = {0219-0249, 1793-6322},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S0219024907004615},
	doi = {10.1142/S0219024907004615},
	abstract = {In this paper, an algorithm to improve the computational accuracy of the analytical approximation to the value of American put options and their optimal exercise boundary proposed by Zhu (2004) is presented. In the current approach, Zhu’s simple approximation formula is used as an initial guess for the optimal exercise boundary of American put options. The determination of an improved optimal exercise boundary is then achieved by setting a null value of the Theta of option value on the optimal exercise boundary. Test example results show that the improvement is indeed signiﬁcant.},
	language = {en},
	number = {07},
	urldate = {2022-12-04},
	journal = {International Journal of Theoretical and Applied Finance},
	author = {Zhu, Song-Ping and He, Zhi-Wei},
	month = nov,
	year = {2007},
	pages = {1203--1227},
	file = {Zhu en He - 2007 - CALCULATING THE EARLY EXERCISE BOUNDARY OF AMERICA.pdf:C\:\\Users\\Admin\\Zotero\\storage\\2ZSHAVUG\\Zhu en He - 2007 - CALCULATING THE EARLY EXERCISE BOUNDARY OF AMERICA.pdf:application/pdf},
}

@book{oksendal_stochastic_1995,
	address = {Berlin, Heidelberg},
	series = {Universitext},
	title = {Stochastic {Differential} {Equations}},
	isbn = {978-3-540-60243-9 978-3-662-03185-8},
	url = {http://link.springer.com/10.1007/978-3-662-03185-8},
	language = {en},
	urldate = {2022-12-04},
	publisher = {Springer Berlin Heidelberg},
	author = {Øksendal, Bernt},
	year = {1995},
	doi = {10.1007/978-3-662-03185-8},
	file = {Øksendal - 1995 - Stochastic Differential Equations.pdf:C\:\\Users\\Admin\\Zotero\\storage\\NN2LBDZP\\Øksendal - 1995 - Stochastic Differential Equations.pdf:application/pdf},
}

@misc{giles_multilevel_2013,
	title = {Multilevel {Monte} {Carlo} methods},
	url = {http://arxiv.org/abs/1304.5472},
	abstract = {The author’s presentation of multilevel Monte Carlo path simulation at the MCQMC 2006 conference stimulated a lot of research into multilevel Monte Carlo methods. This paper reviews the progress since then, emphasising the simplicity, ﬂexibility and generality of the multilevel Monte Carlo approach. It also offers a few original ideas and suggests areas for future research.},
	language = {en},
	urldate = {2022-12-04},
	publisher = {arXiv},
	author = {Giles, Michael B.},
	month = apr,
	year = {2013},
	note = {arXiv:1304.5472 [math]},
	keywords = {Mathematics - Numerical Analysis, 60H10, 60H15, 60H35, 65C30},
	file = {Giles - 2013 - Multilevel Monte Carlo methods.pdf:C\:\\Users\\Admin\\Zotero\\storage\\YRKQ5XCV\\Giles - 2013 - Multilevel Monte Carlo methods.pdf:application/pdf},
}

@article{cliffe_multilevel_2011,
	title = {Multilevel {Monte} {Carlo} methods and applications to elliptic {PDEs} with random coefficients},
	volume = {14},
	issn = {1432-9360, 1433-0369},
	url = {http://link.springer.com/10.1007/s00791-011-0160-x},
	doi = {10.1007/s00791-011-0160-x},
	abstract = {We consider the numerical solution of elliptic partial differential equations with random coefﬁcients. Such problems arise, for example, in uncertainty quantiﬁcation for groundwater ﬂow. We describe a novel variance reduction technique for the standard Monte Carlo method, called the multilevel Monte Carlo method, and demonstrate numerically its superiority. The asymptotic cost of solving the stochastic problem with the multilevel method is always significantly lower than that of the standard method and grows only proportionally to the cost of solving the deterministic problem in certain circumstances. Numerical calculations demonstrating the effectiveness of the method for one- and two-dimensional model problems arising in groundwater ﬂow are presented.},
	language = {en},
	number = {1},
	urldate = {2022-12-04},
	journal = {Computing and Visualization in Science},
	author = {Cliffe, K. A. and Giles, M. B. and Scheichl, R. and Teckentrup, A. L.},
	month = jan,
	year = {2011},
	pages = {3--15},
	file = {Cliffe e.a. - 2011 - Multilevel Monte Carlo methods and applications to.pdf:C\:\\Users\\Admin\\Zotero\\storage\\EM2WHUW8\\Cliffe e.a. - 2011 - Multilevel Monte Carlo methods and applications to.pdf:application/pdf},
}

@misc{noauthor_parareal_2022,
	title = {Parareal},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Parareal&oldid=1117710630},
	abstract = {Parareal is a parallel algorithm from numerical analysis and used for the solution of initial value problems.
It was introduced in 2001 by Lions, Maday and Turinici. Since then, it has become one of the most widely studied parallel-in-time integration methods.},
	language = {en},
	urldate = {2022-12-04},
	journal = {Wikipedia},
	month = oct,
	year = {2022},
	note = {Page Version ID: 1117710630},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\RCGZQ9J3\\Parareal.html:text/html},
}

@incollection{garcke_sparse_2012,
	address = {Berlin, Heidelberg},
	title = {Sparse {Grids} in a {Nutshell}},
	volume = {88},
	isbn = {978-3-642-31702-6 978-3-642-31703-3},
	url = {http://link.springer.com/10.1007/978-3-642-31703-3_3},
	abstract = {The technique of sparse grids allows to overcome the curse of dimensionality, which prevents the use of classical numerical discretization schemes in more than three or four dimensions, under suitable regularity assumptions. The approach is obtained from a multi-scale basis by a tensor product construction and subsequent truncation of the resulting multiresolution series expansion. This entry level article gives an introduction to sparse grids and the sparse grid combination technique.},
	language = {en},
	urldate = {2022-12-04},
	booktitle = {Sparse {Grids} and {Applications}},
	publisher = {Springer Berlin Heidelberg},
	author = {Garcke, Jochen},
	editor = {Garcke, Jochen and Griebel, Michael},
	year = {2012},
	doi = {10.1007/978-3-642-31703-3_3},
	note = {Series Title: Lecture Notes in Computational Science and Engineering},
	pages = {57--80},
	file = {Garcke - 2012 - Sparse Grids in a Nutshell.pdf:C\:\\Users\\Admin\\Zotero\\storage\\UN7T7FRH\\Garcke - 2012 - Sparse Grids in a Nutshell.pdf:application/pdf},
}

@misc{herrera_parallel_2014,
	title = {Parallel {American} {Monte} {Carlo}},
	url = {http://arxiv.org/abs/1404.1180},
	abstract = {In this paper we introduce a new algorithm for American Monte Carlo that can be used either for American-style options, callable structured products or for computing counterparty credit risk (e.g. CVA or PFE computation). Leveraging least squares regressions, the main novel feature of our algorithm is that it can be fully parallelized. Moreover, there is no need to store the paths and the payoﬀ computation can be done forwards: this allows to price structured products with complex path and exercise dependencies. The key idea of our algorithm is to split the set of paths in several subsets which are used iteratively. We give the convergence rate of the algorithm. We illustrate our method on an American put option and compare the results with the Longstaﬀ-Schwartz algorithm.},
	language = {en},
	urldate = {2022-12-03},
	publisher = {arXiv},
	author = {Herrera, Calypso and Paulot, Louis},
	month = apr,
	year = {2014},
	note = {arXiv:1404.1180 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance, Quantitative Finance - Pricing of Securities},
	annote = {Comment: 36 pages},
	file = {Herrera en Paulot - 2014 - Parallel American Monte Carlo.pdf:C\:\\Users\\Admin\\Zotero\\storage\\MKELBXNC\\Herrera en Paulot - 2014 - Parallel American Monte Carlo.pdf:application/pdf},
}

@misc{noauthor_free_2022,
	title = {Free boundary problem},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Free_boundary_problem&oldid=1117659232},
	abstract = {In mathematics, a free boundary problem (FB problem) is a partial differential equation to be solved for both an unknown function 
  
    
      
        u
      
    
    \{{\textbackslash}displaystyle u\}
   and an unknown domain 
  
    
      
        Ω
      
    
    \{{\textbackslash}displaystyle {\textbackslash}Omega \}
  . The segment 
  
    
      
        Γ
      
    
    \{{\textbackslash}displaystyle {\textbackslash}Gamma \}
   of the boundary of 
  
    
      
        Ω
      
    
    \{{\textbackslash}displaystyle {\textbackslash}Omega \}
   which is not known at the outset of the problem is the free boundary.
FBs arise in various mathematical models encompassing applications that ranges from physical to economical, financial and biological phenomena, where there is an extra effect of the medium. This effect is in general a qualitative change of the medium and hence an appearance of a phase transition: ice to water, liquid to crystal, buying to selling (assets), active to inactive (biology), blue to red (coloring games), disorganized to organized (self-organizing criticality). An interesting aspect of such a criticality is the so-called sandpile dynamic (or Internal DLA).
The most classical example is the melting of ice: Given a block of ice, one can solve the heat equation given appropriate initial and boundary conditions to determine its temperature. But, if in any region the temperature is greater than the melting point of ice, this domain will be occupied by liquid water instead. The boundary formed from the ice/liquid interface is controlled dynamically by the solution of the PDE.},
	language = {en},
	urldate = {2022-12-03},
	journal = {Wikipedia},
	month = oct,
	year = {2022},
	note = {Page Version ID: 1117659232},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\T8LYY8CI\\Free_boundary_problem.html:text/html},
}

@misc{hout_numerical_2021,
	title = {Numerical valuation of {American} basket options via partial differential complementarity problems},
	url = {http://arxiv.org/abs/2106.01200},
	abstract = {We study the principal component analysis based approach introduced by Reisinger \& Wittum [1] and the comonotonic approach considered by Hanbali \& Linders [2] for the approximation of American basket option values via multidimensional partial diﬀerential complementarity problems (PDCPs). Both approximation approaches require the solution of just a limited number of low-dimensional PDCPs. It is demonstrated by ample numerical experiments that they deﬁne approximations that lie close to each other. Next, an eﬃcient discretisation of the pertinent PDCPs is presented that leads to a favourable convergence behaviour.},
	language = {en},
	urldate = {2022-12-03},
	publisher = {arXiv},
	author = {Hout, Karel in 't and Snoeijer, Jacob},
	month = jun,
	year = {2021},
	note = {arXiv:2106.01200 [cs, math, q-fin]},
	keywords = {Mathematics - Numerical Analysis, Quantitative Finance - Computational Finance, Computer Science - Computational Engineering, Finance, and Science},
	file = {Hout en Snoeijer - 2021 - Numerical valuation of American basket options via.pdf:C\:\\Users\\Admin\\Zotero\\storage\\VYEP4C9L\\Hout en Snoeijer - 2021 - Numerical valuation of American basket options via.pdf:application/pdf},
}

@misc{sorge_valuation_1998,
	title = {Valuation of path-dependent {American} options using a {Monte} {Carlo} approach},
	url = {http://arxiv.org/abs/math/9801057},
	abstract = {It is shown how to obtain accurate values for American options using Monte Carlo simulation. The main feature of the novel algorithm consists of tracking the boundary between exercise and hold regions via optimization of a certain payoﬀ function. We compare estimates from simulation for some types of claims with results from binomial tree calculations and ﬁnd very good agreement. The novel method allows to calculate so far untractable path-dependent option values.},
	language = {en},
	urldate = {2022-12-03},
	publisher = {arXiv},
	author = {Sorge, H.},
	month = jan,
	year = {1998},
	note = {arXiv:math/9801057},
	keywords = {Mathematics - Numerical Analysis, Quantitative Finance - Computational Finance},
	annote = {Comment: 32 pages LaTeX including 4 postscript figures},
	file = {Sorge - 1998 - Valuation of path-dependent American options using.pdf:C\:\\Users\\Admin\\Zotero\\storage\\TEBUQCAP\\Sorge - 1998 - Valuation of path-dependent American options using.pdf:application/pdf},
}

@misc{sevcovic_iterative_2007,
	title = {An iterative algorithm for evaluating approximations to the optimal exercise boundary for a nonlinear {Black}-{Scholes} equation},
	url = {http://arxiv.org/abs/0710.5301},
	abstract = {The purpose of this paper is to analyze and compute the early exercise boundary for a class of nonlinear Black–Scholes equations with a nonlinear volatility which can be a function of the second derivative of the option price itself. A motivation for studying the nonlinear Black–Scholes equation with a nonlinear volatility arises from option pricing models taking into account e.g. nontrivial transaction costs, investor’s preferences, feedback and illiquid markets effects and risk from a volatile (unprotected) portfolio. We present a new method how to transform the free boundary problem for the early exercise boundary position into a solution of a time depending nonlinear parabolic equation deﬁned on a ﬁxed domain. We furthermore propose an iterative numerical scheme that can be used to ﬁnd an approximation of the free boundary. We present results of numerical approximation of the early exercise boundary for various types of nonlinear Black–Scholes equations and we discuss dependence of the free boundary on various model parameters.},
	language = {en},
	urldate = {2022-12-03},
	publisher = {arXiv},
	author = {Sevcovic, Daniel},
	month = oct,
	year = {2007},
	note = {arXiv:0710.5301 [math, q-fin]},
	keywords = {Mathematics - Numerical Analysis, Quantitative Finance - Computational Finance, 35K15, 35K55, 90A09, 91B28},
	annote = {Comment: 17 pages},
	file = {Sevcovic - 2007 - An iterative algorithm for evaluating approximatio.pdf:C\:\\Users\\Admin\\Zotero\\storage\\QEPCMV5C\\Sevcovic - 2007 - An iterative algorithm for evaluating approximatio.pdf:application/pdf},
}

@article{bossy_parallel_2010,
	title = {Parallel {Pricing} {Algorithms} for {Multi}--{Dimensional} {Bermudan}/{American} {Options} using {Monte} {Carlo} methods},
	volume = {81},
	issn = {03784754},
	url = {http://arxiv.org/abs/0805.1827},
	doi = {10.1016/j.matcom.2010.08.005},
	abstract = {In this paper we present two parallel Monte Carlo based algorithms for pricing multi–dimensional Bermudan/American options. First approach relies on computation of the optimal exercise boundary while the second relies on classiﬁcation of continuation and exercise values. We also evaluate the performance of both the algorithms in a desktop grid environment. We show the eﬀectiveness of the proposed approaches in a heterogeneous computing environment, and identify scalability constraints due to the algorithmic structure.},
	language = {en},
	number = {3},
	urldate = {2022-12-03},
	journal = {Mathematics and Computers in Simulation},
	author = {Bossy, Mireille and Baude, Françoise and Doan, Viet Dung and Gaikwad, Abhijeet and Stokes-Rees, Ian},
	month = nov,
	year = {2010},
	note = {arXiv:0805.1827 [cs]},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Computer Science - Distributed, Parallel, and Cluster Computing},
	pages = {568--577},
	file = {Bossy e.a. - 2010 - Parallel Pricing Algorithms for Multi--Dimensional.pdf:C\:\\Users\\Admin\\Zotero\\storage\\R7AAXVAF\\Bossy e.a. - 2010 - Parallel Pricing Algorithms for Multi--Dimensional.pdf:application/pdf},
}

@misc{kitapbayev_closed_2021,
	title = {Closed form optimal exercise boundary of the {American} put option},
	url = {http://arxiv.org/abs/1912.05438},
	abstract = {We present three models of stock price with time-dependent interest rate, dividend yield, and volatility, respectively, that allow for explicit forms of the optimal exercise boundary of the finite maturity American put option. The optimal exercise boundary satisfies the nonlinear integral equation of Volterra type. We choose time-dependent parameters of the model so that the integral equation for the exercise boundary can be solved in the closed form. We also define the contracts of put type with time-dependent strike price that support the explicit optimal exercise boundary.},
	language = {en},
	urldate = {2022-12-03},
	publisher = {arXiv},
	author = {Kitapbayev, Yerkin},
	month = jan,
	year = {2021},
	note = {arXiv:1912.05438 [q-fin]},
	keywords = {Quantitative Finance - Pricing of Securities, Primary Primary 91G20, 60G40. Secondary 60J60, 35R35, 45G10, Quantitative Finance - Mathematical Finance},
	file = {Kitapbayev - 2021 - Closed form optimal exercise boundary of the Ameri.pdf:C\:\\Users\\Admin\\Zotero\\storage\\RIREZYP8\\Kitapbayev - 2021 - Closed form optimal exercise boundary of the Ameri.pdf:application/pdf},
}

@article{healy_pricing_2021,
	title = {Pricing {American} options under negative rates},
	issn = {14601559, 17552850},
	url = {http://arxiv.org/abs/2109.15157},
	doi = {10.21314/JCF.2021.004},
	abstract = {This paper starts by deﬁning the criteria where the early-exercise of an American option is never optimal, under positive, or negative rates. It follows with a short analysis of the various shapes of the exercise region under negative interest rates. It then presents a new integral equation, which establishes the option price, and the two early exercise boundaries, under negative rates. It shows how to solve this new equation, through modiﬁcations of the modern and efﬁcient algorithm of Andersen and Lake, from the initial guess of the two boundaries to more subtle changes required in their ﬁxed point method for stability. Finally, the performance and accuracy of the resulting algorithm is assessed against a cutting edge ﬁnite difference method implementation.},
	language = {en},
	urldate = {2022-12-03},
	journal = {The Journal of Computational Finance},
	author = {Healy, Jherek},
	year = {2021},
	note = {arXiv:2109.15157 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance, Quantitative Finance - Pricing of Securities},
	file = {Healy - 2021 - Pricing American options under negative rates.pdf:C\:\\Users\\Admin\\Zotero\\storage\\8RBI4CZR\\Healy - 2021 - Pricing American options under negative rates.pdf:application/pdf},
}

@misc{azze_optimal_2022,
	title = {Optimal exercise of {American} options under time-dependent {Ornstein}-{Uhlenbeck} processes},
	url = {http://arxiv.org/abs/2211.04095},
	abstract = {We study the barrier that gives the optimal time to exercise an American option written on a time-dependent Ornstein–Uhlenbeck process, a diﬀusion often adopted by practitioners to model commodity prices and interest rates. By framing the optimal exercise of the American option as a problem of optimal stopping and relying on probabilistic arguments, we provide a non-linear Volterra-type integral equation characterizing the exercise boundary, develop a novel comparison argument to derive upper and lower bounds for such a boundary, and prove its diﬀerentiability and Lipschitz continuity in any closed interval that excludes the expiration date. We implement a Picard iteration algorithm to solve the Volterra integral equation and show illustrative examples that shed light on the boundary’s dependence on the process’s drift and volatility.},
	language = {en},
	urldate = {2022-12-03},
	publisher = {arXiv},
	author = {Azze, Abel and D'Auria, Bernardo and García-Portugués, Eduardo},
	month = nov,
	year = {2022},
	note = {arXiv:2211.04095 [math, q-fin]},
	keywords = {Mathematics - Probability, Quantitative Finance - Pricing of Securities, Quantitative Finance - Mathematical Finance, 60G40, 60J60},
	annote = {Comment: 22 pages, 3 figures},
	file = {Azze e.a. - 2022 - Optimal exercise of American options under time-de.pdf:C\:\\Users\\Admin\\Zotero\\storage\\HQER3NIQ\\Azze e.a. - 2022 - Optimal exercise of American options under time-de.pdf:application/pdf},
}

@misc{kitapbayev_closed_2021-1,
	title = {Closed form optimal exercise boundary of the {American} put option},
	url = {http://arxiv.org/abs/1912.05438},
	abstract = {We present three models of stock price with time-dependent interest rate, dividend yield, and volatility, respectively, that allow for explicit forms of the optimal exercise boundary of the finite maturity American put option. The optimal exercise boundary satisfies the nonlinear integral equation of Volterra type. We choose time-dependent parameters of the model so that the integral equation for the exercise boundary can be solved in the closed form. We also define the contracts of put type with time-dependent strike price that support the explicit optimal exercise boundary.},
	language = {en},
	urldate = {2022-12-03},
	publisher = {arXiv},
	author = {Kitapbayev, Yerkin},
	month = jan,
	year = {2021},
	note = {arXiv:1912.05438 [q-fin]},
	keywords = {Quantitative Finance - Pricing of Securities, Primary Primary 91G20, 60G40. Secondary 60J60, 35R35, 45G10, Quantitative Finance - Mathematical Finance},
	file = {Kitapbayev - 2021 - Closed form optimal exercise boundary of the Ameri.pdf:C\:\\Users\\Admin\\Zotero\\storage\\99M3PKZV\\Kitapbayev - 2021 - Closed form optimal exercise boundary of the Ameri.pdf:application/pdf},
}

@article{gondzio_interior_2012,
	title = {Interior point methods 25 years later},
	volume = {218},
	issn = {03772217},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221711008204},
	doi = {10.1016/j.ejor.2011.09.017},
	abstract = {Interior point methods for optimization have been around for more than 25 years now. Their presence has shaken up the ﬁeld of optimization. Interior point methods for linear and (convex) quadratic programming display several features which make them particularly attractive for very large scale optimization. Among the most impressive of them are their low-degree polynomial worst-case complexity and an unrivalled ability to deliver optimal solutions in an almost constant number of iterations which depends very little, if at all, on the problem dimension. Interior point methods are competitive when dealing with small problems of dimensions below one million constraints and variables and are beyond competition when applied to large problems of dimensions going into millions of constraints and variables.},
	language = {en},
	number = {3},
	urldate = {2022-10-27},
	journal = {European Journal of Operational Research},
	author = {Gondzio, Jacek},
	month = may,
	year = {2012},
	keywords = {interior point methods, optimization, optimization-constrained},
	pages = {587--601},
	file = {Gondzio - 2012 - Interior point methods 25 years later.pdf:C\:\\Users\\Admin\\Zotero\\storage\\NNLGF4AU\\Gondzio - 2012 - Interior point methods 25 years later.pdf:application/pdf},
}

@article{cockayne_bayesian_2019,
	title = {Bayesian {Probabilistic} {Numerical} {Methods}},
	volume = {61},
	issn = {0036-1445, 1095-7200},
	url = {http://arxiv.org/abs/1702.03673},
	doi = {10.1137/17M1139357},
	abstract = {The emergent field of probabilistic numerics has thus far lacked clear statistical principals. This paper establishes Bayesian probabilistic numerical methods as those which can be cast as solutions to certain inverse problems within the Bayesian framework. This allows us to establish general conditions under which Bayesian probabilistic numerical methods are well-defined, encompassing both non-linear and non-Gaussian models. For general computation, a numerical approximation scheme is proposed and its asymptotic convergence established. The theoretical development is then extended to pipelines of computation, wherein probabilistic numerical methods are composed to solve more challenging numerical tasks. The contribution highlights an important research frontier at the interface of numerical analysis and uncertainty quantification, with a challenging industrial application presented.},
	language = {en},
	number = {3},
	urldate = {2022-09-30},
	journal = {SIAM Review},
	author = {Cockayne, Jon and Oates, Chris and Sullivan, Tim and Girolami, Mark},
	month = jan,
	year = {2019},
	note = {arXiv:1702.03673 [cs, math, stat]},
	keywords = {Mathematics - Numerical Analysis, Statistics - Computation, Mathematics - Statistics Theory, Statistics - Methodology},
	pages = {756--789},
	annote = {Received from professor In’t Hout on 30/09/2022.
},
	file = {Cockayne e.a. - 2019 - Bayesian Probabilistic Numerical Methods.pdf:C\:\\Users\\Admin\\Zotero\\storage\\VGGVNQSB\\Cockayne e.a. - 2019 - Bayesian Probabilistic Numerical Methods.pdf:application/pdf},
}

@article{cockayne_bayesian_2019-1,
	title = {Bayesian {Probabilistic} {Numerical} {Methods}},
	volume = {61},
	issn = {0036-1445, 1095-7200},
	url = {http://arxiv.org/abs/1702.03673},
	doi = {10.1137/17M1139357},
	abstract = {The emergent field of probabilistic numerics has thus far lacked clear statistical principals. This paper establishes Bayesian probabilistic numerical methods as those which can be cast as solutions to certain inverse problems within the Bayesian framework. This allows us to establish general conditions under which Bayesian probabilistic numerical methods are well-defined, encompassing both non-linear and non-Gaussian models. For general computation, a numerical approximation scheme is proposed and its asymptotic convergence established. The theoretical development is then extended to pipelines of computation, wherein probabilistic numerical methods are composed to solve more challenging numerical tasks. The contribution highlights an important research frontier at the interface of numerical analysis and uncertainty quantification, with a challenging industrial application presented.},
	language = {en},
	number = {3},
	urldate = {2022-09-30},
	journal = {SIAM Review},
	author = {Cockayne, Jon and Oates, Chris and Sullivan, Tim and Girolami, Mark},
	month = jan,
	year = {2019},
	note = {arXiv:1702.03673 [cs, math, stat]},
	keywords = {Mathematics - Numerical Analysis, Statistics - Computation, Mathematics - Statistics Theory, Statistics - Methodology},
	pages = {756--789},
	file = {Cockayne e.a. - 2019 - Bayesian Probabilistic Numerical Methods.pdf:C\:\\Users\\Admin\\Zotero\\storage\\9ST6SIRW\\Cockayne e.a. - 2019 - Bayesian Probabilistic Numerical Methods.pdf:application/pdf},
}

@book{hastie_elements_2001,
	title = {The {Elements} of {Statistical} {Learning}  {Data} {Mining}, {Inference}, and {Prediction}},
	abstract = {The many topics include neural networks, support vector machines, classification trees and boosting - the first comprehensive treatment of this topic in any book},
	publisher = {Springer Berlin Heidelberg},
	author = {Hastie, Trevor and Friedman, Jerome and Tibshirani, Robert},
	year = {2001},
	keywords = {Statistics - Machine Learning},
	file = {ESLII_print12_toc-compressed.pdf:C\:\\Users\\Admin\\Zotero\\storage\\Q8DWLFW6\\ESLII_print12_toc-compressed.pdf:application/pdf},
}

@article{haji-sheikh_floating_1966,
	title = {The {Floating} {Random} {Walk} and {Its} {Application} to {Monte} {Carlo} {Solutions} of {Heat} {Equations}},
	volume = {14},
	url = {http://www.jstor.org/stable/2946271},
	language = {en},
	number = {2},
	journal = {SIAM Journal on Applied Mathematics},
	author = {Haji-Sheikh, A. and Sparrow, E. M.},
	year = {1966},
	keywords = {monte carlo, PDE, walk on spheres},
	pages = {370--389},
	annote = {
Kram1032
1 month ago
Love to see this progress! I wonder whether this could be done in the time domain as well? I know, it tends to be the case with Monte-Carlo methods, that they are timeless. They try to sample some steady state, right? But if you make the entire spacio-temporal volume your "steady state", it ought to be possible regardless. Normally you couldn't properly save, and keep access to all that data so you could completely skip out on frames. But perhaps there is a way around that somehow? Maybe something inspired by NeRFs. A sort of data structure that's iteratively updated with gradient descend anyways, so you could probably reformulate that as a PDE that can be handled with a method like this I'd think? Then you could effectively get rid of all explicit grids (globally spatial, locally surface- or volume-spatial, and temporal) and go gridless continuous end to end perhaps. It seems to me the application of refining subsurface scattering is a nice example of how that might be helpful.

·


Rohan Sawhney
1 month ago
Hi! It's possible to handle temporal problems such as the heat equation with walk on spheres, I recommend looking at this paper: https://epubs.siam.org/doi/10.1137/0114031 Since the heat equation is an initial value problem, the high-level idea is to also sample an "exit time" at each step of the random walk from a known distribution (in addition to a uniform exit location on the sphere), and to keep a counter of the total time elapsed during the walk. If the counter value exceeds the predetermined amount/time for which one wants to flow the heat, then the initial value at the current position of the random walk inside the domain is added to the Monte Carlo estimate.
 1 

Kram1032
1 month ago (edited)
 @Rohan Sawhney  thanks I'll check it out! sounds interesting
},
	file = {Haji-Sheikh en Sparrow - 1966 - The Floating Random Walk and Its Application to Mo.pdf:C\:\\Users\\Admin\\Zotero\\storage\\M4YQIH62\\Haji-Sheikh en Sparrow - 1966 - The Floating Random Walk and Its Application to Mo.pdf:application/pdf},
}

@article{su_numerical_2012,
	title = {Numerical {Solution} of {Integro}-{Differential} {Equations} with {Local} {Polynomial} {Regression}},
	volume = {02},
	issn = {2161-718X, 2161-7198},
	url = {http://www.scirp.org/journal/doi.aspx?DOI=10.4236/ojs.2012.23043},
	doi = {10.4236/ojs.2012.23043},
	language = {en},
	number = {03},
	urldate = {2022-09-26},
	journal = {Open Journal of Statistics},
	author = {Su, Liyun and Yan, Tianshun and Zhao, Yanyong and Li, Fenglan and Liu, Ruihua},
	year = {2012},
	keywords = {local regression, ODE},
	pages = {352--355},
	file = {Su e.a. - 2012 - Numerical Solution of Integro-Differential Equatio.pdf:C\:\\Users\\Admin\\Zotero\\storage\\MDM22BGE\\Su e.a. - 2012 - Numerical Solution of Integro-Differential Equatio.pdf:application/pdf},
}

@misc{deaconu_walk_2015,
	title = {The walk on moving spheres: a new tool for simulating {Brownian} motion's exit time from a domain},
	shorttitle = {The walk on moving spheres},
	url = {http://arxiv.org/abs/1401.3695},
	abstract = {In this paper we introduce a new method for the simulation of the exit time and exit position of a δ-dimensional Brownian motion from a domain. The main interest of our method is that it avoids splitting time schemes as well as inversion of complicated series. The method, called walk on moving spheres algorithm, was ﬁrst introduced for hitting times of Bessel processes. In this study this method is adapted and developed for the ﬁrst time for the Brownian motion hitting times. The idea is to use the connexion between the δdimensional Bessel process and the δ-dimensional Brownian motion thanks to an explicit Bessel hitting time distribution associated with a particular curved boundary. This allows to build a fast and accurate numerical scheme for approximating the hitting time. We introduce also an overview of existing methods for the simulation of the Brownian hitting time and perform numerical comparisons with existing methods.},
	language = {en},
	urldate = {2022-09-17},
	publisher = {arXiv},
	author = {Deaconu, Madalina and Herrmann, Samuel and Maire, Sylvain},
	month = oct,
	year = {2015},
	note = {arXiv:1401.3695 [math]},
	keywords = {Mathematics - Probability, walk on spheres},
	file = {Deaconu e.a. - 2015 - The walk on moving spheres a new tool for simulat.pdf:C\:\\Users\\Admin\\Zotero\\storage\\EIYVRXS7\\Deaconu e.a. - 2015 - The walk on moving spheres a new tool for simulat.pdf:application/pdf},
}

@incollection{carmona_least-squares_2012,
	address = {Berlin, Heidelberg},
	title = {Least-{Squares} {Monte} {Carlo} for {Backward} {SDEs}},
	volume = {12},
	isbn = {978-3-642-25745-2 978-3-642-25746-9},
	url = {http://link.springer.com/10.1007/978-3-642-25746-9_8},
	abstract = {In this paper we ﬁrst give a review of the least-squares Monte Carlo approach for approximating the solution of backward stochastic diﬀerential equations (BSDEs) ﬁrst suggested by Gobet, Lemor, and Warin (Ann. Appl. Probab., 15, 2005, 2172–2202). We then propose the use of basis functions, which form a system of martingales, and explain how the least-squares Monte Carlo scheme can be simpliﬁed by exploiting the martingale property of the basis functions. We partially compare the convergence behavior of the original scheme and the scheme based on martingale basis functions, and provide several numerical examples related to option pricing problems under diﬀerent interest rates for borrowing and investing.},
	language = {en},
	urldate = {2022-09-17},
	booktitle = {Numerical {Methods} in {Finance}},
	publisher = {Springer Berlin Heidelberg},
	author = {Bender, Christian and Steiner, Jessica},
	editor = {Carmona, René A. and Del Moral, Pierre and Hu, Peng and Oudjane, Nadia},
	year = {2012},
	doi = {10.1007/978-3-642-25746-9_8},
	note = {Series Title: Springer Proceedings in Mathematics},
	keywords = {monte carlo, SDE},
	pages = {257--289},
	file = {Bender en Steiner - 2012 - Least-Squares Monte Carlo for Backward SDEs.pdf:C\:\\Users\\Admin\\Zotero\\storage\\4LPW4G2Q\\Bender en Steiner - 2012 - Least-Squares Monte Carlo for Backward SDEs.pdf:application/pdf},
}

@misc{vanroose_krylov-simplex_2021,
	title = {Krylov-{Simplex} method that minimizes the residual in \${\textbackslash}ell\_1\$-norm or \${\textbackslash}ell\_{\textbackslash}infty\$-norm},
	url = {http://arxiv.org/abs/2101.11416},
	abstract = {The paper presents two variants of a Krylov-Simplex iterative method that combines Krylov and simplex iterations to minimize the residual r = b−Ax. The ﬁrst method minimizes r ∞, i.e. maximum of the absolute residuals. The second minimizes r 1, and ﬁnds the solution with the least absolute residuals. Both methods search for an optimal solution xk in a Krylov subspace which results in a small linear programming problem. A specialized simplex algorithm solves this projected problem and ﬁnds the optimal linear combination of Krylov basis vectors to approximate the solution. The resulting simplex algorithm requires the solution of a series of small dense linear systems that only diﬀer by rank-one updates. The QR factorization of these matrices is updated each iteration. We demonstrate the eﬀectiveness of the methods with numerical experiments.},
	language = {en},
	urldate = {2022-09-26},
	publisher = {arXiv},
	author = {Vanroose, Wim and Cornelis, Jeffrey},
	month = jan,
	year = {2021},
	note = {arXiv:2101.11416 [cs, math]},
	keywords = {Mathematics - Numerical Analysis, krylov, Mathematics - Optimization and Control, simplex},
	annote = {Comment: 22 pages},
	file = {Vanroose en Cornelis - 2021 - Krylov-Simplex method that minimizes the residual .pdf:C\:\\Users\\Admin\\Zotero\\storage\\M2G9WBDA\\Vanroose en Cornelis - 2021 - Krylov-Simplex method that minimizes the residual .pdf:application/pdf},
}

@article{caglar_solution_2007,
	title = {Solution of fifth order boundary value problems by using local polynomial regression},
	volume = {186},
	issn = {00963003},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0096300306010204},
	doi = {10.1016/j.amc.2006.08.046},
	abstract = {In this paper, we present a novel method based on the local polynomial regression for solving of ﬁfth order boundary value problems. The method is tested on numerical example to demonstrate its usefulness. The method presented in this paper is also compared with those developed by Siddiqi and Akram [Solution of ﬁfth order boundary value problems using nonpolynomial spline technique, Appl. Math. Comput. 175 (2006) 1575–1581], as well and is observed to be better.},
	language = {en},
	number = {2},
	urldate = {2022-09-26},
	journal = {Applied Mathematics and Computation},
	author = {Caglar, Hikmet and Caglar, Nazan},
	month = mar,
	year = {2007},
	keywords = {local regression, ODE},
	pages = {952--956},
	file = {Caglar en Caglar - 2007 - Solution of fifth order boundary value problems by.pdf:C\:\\Users\\Admin\\Zotero\\storage\\Z8EJ5CDR\\Caglar en Caglar - 2007 - Solution of fifth order boundary value problems by.pdf:application/pdf},
}

@misc{noauthor_nevilles_2022,
	title = {Neville's algorithm},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Neville%27s_algorithm&oldid=1100728778},
	abstract = {In mathematics, Neville's algorithm is an algorithm used for polynomial interpolation that was derived by the mathematician Eric Harold Neville in 1934. Given n + 1 points, there is a unique polynomial of degree ≤ n which goes through the given points. Neville's algorithm evaluates this polynomial.
Neville's algorithm is based on the Newton form of the interpolating polynomial and the recursion relation for the divided differences. It is similar to Aitken's algorithm (named after Alexander Aitken), which is nowadays not used.},
	language = {en},
	urldate = {2022-09-26},
	journal = {Wikipedia},
	month = jul,
	year = {2022},
	note = {Page Version ID: 1100728778},
	keywords = {finite differnces, interpolation},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\J69UYIG8\\Neville's_algorithm.html:text/html},
}

@misc{noauthor_github_nodate,
	title = {{GitHub} - {NVIDIA}/fsi-samples: {A} collection of open-source {GPU} accelerated {Python} tools and examples for quantitative analyst tasks and leverages {RAPIDS} {AI} project, {Numba}, {cuDF}, and {Dask}.},
	url = {https://github.com/NVIDIA/fsi-samples},
	urldate = {2022-09-19},
	keywords = {python, quant},
	file = {GitHub - NVIDIA/fsi-samples\: A collection of open-source GPU accelerated Python tools and examples for quantitative analyst tasks and leverages RAPIDS AI project, Numba, cuDF, and Dask.:C\:\\Users\\Admin\\Zotero\\storage\\FTUN9SNE\\fsi-samples.html:text/html},
}

@misc{noauthor_accelerating_2020,
	title = {Accelerating {Python} for {Exotic} {Option} {Pricing}},
	url = {https://developer.nvidia.com/blog/accelerating-python-for-exotic-option-pricing/},
	abstract = {In finance, computation efficiency can be directly converted to trading profits sometimes. Quants are facing the challenges of trading off research efficiency with computation efficiency.},
	language = {en-US},
	urldate = {2022-09-19},
	journal = {NVIDIA Technical Blog},
	month = mar,
	year = {2020},
	keywords = {python, cupy, numba},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\LNJMET6I\\accelerating-python-for-exotic-option-pricing.html:text/html},
}

@misc{lehtinen_noise2noise_2018,
	title = {{Noise2Noise}: {Learning} {Image} {Restoration} without {Clean} {Data}},
	shorttitle = {{Noise2Noise}},
	url = {http://arxiv.org/abs/1803.04189},
	abstract = {We apply basic statistical reasoning to signal reconstruction by machine learning – learning to map corrupted observations to clean signals – with a simple and powerful conclusion: it is possible to learn to restore images by only looking at corrupted examples, at performance at and sometimes exceeding training using clean data, without explicit image priors or likelihood models of the corruption. In practice, we show that a single model learns photographic noise removal, denoising synthetic Monte Carlo images, and reconstruction of undersampled MRI scans – all corrupted by different processes – based on noisy data only.},
	language = {en},
	urldate = {2022-09-19},
	publisher = {arXiv},
	author = {Lehtinen, Jaakko and Munkberg, Jacob and Hasselgren, Jon and Laine, Samuli and Karras, Tero and Aittala, Miika and Aila, Timo},
	month = oct,
	year = {2018},
	note = {arXiv:1803.04189 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Added link to official implementation and updated MRI results to match it},
	file = {Lehtinen e.a. - 2018 - Noise2Noise Learning Image Restoration without Cl.pdf:C\:\\Users\\Admin\\Zotero\\storage\\NAGQ9NY7\\Lehtinen e.a. - 2018 - Noise2Noise Learning Image Restoration without Cl.pdf:application/pdf},
}

@misc{ferguson_deeply_2018,
	title = {Deeply {Learning} {Derivatives}},
	url = {http://arxiv.org/abs/1809.02233},
	abstract = {This paper uses deep learning to value derivatives. The approach is broadly applicable, and we use a call option on a basket of stocks as an example. We show that the deep learning model is accurate and very fast, capable of producing valuations a million times faster than traditional models. We develop a methodology to randomly generate appropriate training data and explore the impact of several parameters including layer width and depth, training data quality and quantity on model speed and accuracy.},
	language = {en},
	urldate = {2022-09-19},
	publisher = {arXiv},
	author = {Ferguson, Ryan and Green, Andrew},
	month = oct,
	year = {2018},
	note = {arXiv:1809.02233 [cs, q-fin]},
	keywords = {Computer Science - Machine Learning, Quantitative Finance - Computational Finance},
	file = {Ferguson en Green - 2018 - Deeply Learning Derivatives.pdf:C\:\\Users\\Admin\\Zotero\\storage\\5KLHN2WM\\Ferguson en Green - 2018 - Deeply Learning Derivatives.pdf:application/pdf},
}

@article{sabelfeld_sparsified_2009,
	title = {Sparsified {Randomization} {Algorithms} for large systems of linear equations and a new version of the {Random} {Walk} on {Boundary} method},
	volume = {15},
	issn = {0929-9629, 1569-3961},
	url = {https://www.degruyter.com/document/doi/10.1515/MCMA.2009.015/html},
	doi = {10.1515/MCMA.2009.015},
	abstract = {Sparsiﬁed Randomization Monte Carlo (SRMC) algorithms for solving large systems of linear algebraic equations are presented. We construct efﬁcient stochastic algorithms based on a probabilistic sampling of small size sub-matrices, or a randomized evaluation of a matrix-vector product and matrix iterations via a random sparsiﬁcation of the matrix. This approach is beyond the standard Markov chain based Neumann–Ulam method which has no universal instrument to decrease the variance. Instead, in the new method, ﬁrst, the variance can be decreased by increasing the number of the sampled columns of the matrix in play, and second, it is free of the restricted assumption of the Neumann–Ulam scheme that the Neumann series converges. We apply the developed methods to different stochastic iterative procedures. Application to boundary integral equation of the electrostatic potential theory is given where we develop a SRMC algorithm for solving the approximated system of linear algebraic equations, and compare it with the standard Random Walk on Boundary method.},
	language = {en},
	number = {3},
	urldate = {2022-09-17},
	journal = {Monte Carlo Methods and Applications},
	author = {Sabelfeld, K. and Mozartova, N.},
	month = jan,
	year = {2009},
	keywords = {monte carlo, linear systems, sparse},
	file = {Sabelfeld en Mozartova - 2009 - Sparsified Randomization Algorithms for large syst.pdf:C\:\\Users\\Admin\\Zotero\\storage\\YBMLVR26\\Sabelfeld en Mozartova - 2009 - Sparsified Randomization Algorithms for large syst.pdf:application/pdf},
}

@article{sawhney_grid-free_2022,
	title = {Grid-free {Monte} {Carlo} for {PDEs} with spatially varying coefficients},
	volume = {41},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/3528223.3530134},
	doi = {10.1145/3528223.3530134},
	abstract = {Partial differential equations (PDEs) with spatially varying coefficients arise throughout science and engineering, modeling rich heterogeneous material behavior. Yet conventional PDE solvers struggle with the immense complexity found in nature, since they must first discretize the problem---leading to spatial aliasing, and global meshing/sampling that is costly and error-prone. We describe a method that approximates neither the domain geometry, the problem data, nor the solution space, providing the exact solution (in expectation) even for problems with extremely detailed geometry and intricate coefficients. Our main contribution is to extend the
              walk on spheres (WoS)
              algorithm from constant- to variable-coefficient problems, by drawing on techniques from volumetric rendering. In particular, an approach inspired by
              null-scattering
              yields unbiased Monte Carlo estimators for a large class of 2nd order elliptic PDEs, which share many attractive features with Monte Carlo rendering: no meshing, trivial parallelism, and the ability to evaluate the solution at any point without solving a global system of equations.},
	language = {en},
	number = {4},
	urldate = {2022-09-17},
	journal = {ACM Transactions on Graphics},
	author = {Sawhney, Rohan and Seyb, Dario and Jarosz, Wojciech and Crane, Keenan},
	month = jul,
	year = {2022},
	keywords = {monte carlo, PDE, walk on spheres},
	pages = {1--17},
	file = {Sawhney e.a. - 2022 - Grid-free Monte Carlo for PDEs with spatially vary.pdf:C\:\\Users\\Admin\\Zotero\\storage\\52QDH9YB\\Sawhney e.a. - 2022 - Grid-free Monte Carlo for PDEs with spatially vary.pdf:application/pdf},
}

@article{sawhney_monte_nodate,
	title = {Monte {Carlo} {Geometry} {Processing}:{A} {Grid}-{Free} {Approach} to {PDE}-{Based} {Methods} on {Volumetric} {Domains}},
	volume = {38},
	language = {en},
	number = {4},
	author = {Sawhney, Rohan and Crane, Keenan},
	keywords = {monte carlo, PDE, walk on spheres},
	pages = {18},
	file = {Sawhney en Crane - Monte Carlo Geometry ProcessingA Grid-Free Approa.pdf:C\:\\Users\\Admin\\Zotero\\storage\\J5MXL5PE\\Sawhney en Crane - Monte Carlo Geometry ProcessingA Grid-Free Approa.pdf:application/pdf},
}

@article{sabelfeld_vector_2016,
	title = {Vector {Monte} {Carlo} stochastic matrix-based algorithms for large linear systems},
	volume = {22},
	issn = {0929-9629, 1569-3961},
	url = {https://www.degruyter.com/document/doi/10.1515/mcma-2016-0112/html},
	doi = {10.1515/mcma-2016-0112},
	abstract = {In this short article we suggest randomized scalable stochastic matrix-based algorithms for large linear systems. The idea behind these stochastic methods is a randomized vector representation of matrix iterations. In addition, to minimize the variance, it is suggested to use stochastic and double stochastic matrices for efficient randomized calculation of matrix iterations and a random gradient based search strategy. The iterations are performed by sampling random rows and columns only, thus avoiding not only matrix matrix but also matrix vector multiplications. Further improvements of the methods can be obtained through projections by a random gaussian matrix.},
	language = {en},
	number = {3},
	urldate = {2022-09-17},
	journal = {Monte Carlo Methods and Applications},
	author = {Sabelfeld, Karl K.},
	month = jan,
	year = {2016},
	keywords = {monte carlo, linear systems},
	file = {Sabelfeld - 2016 - Vector Monte Carlo stochastic matrix-based algorit.pdf:C\:\\Users\\Admin\\Zotero\\storage\\EX64VKZ2\\Sabelfeld - 2016 - Vector Monte Carlo stochastic matrix-based algorit.pdf:application/pdf},
}

@article{benzi_analysis_2017,
	title = {Analysis of {Monte} {Carlo} accelerated iterative methods for sparse linear systems},
	volume = {24},
	issn = {1070-5325, 1099-1506},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/nla.2088},
	doi = {10.1002/nla.2088},
	abstract = {We consider hybrid deterministic-stochastic iterative algorithms for the solution of large, sparse linear systems. Starting from a convergent splitting of the coeﬃcient matrix, we analyze various types of Monte Carlo acceleration schemes applied to the original preconditioned Richardson (stationary) iteration. These methods are expected to have considerable potential for resiliency to faults when implemented on massively parallel machines. We establish suﬃcient conditions for the convergence of the hybrid schemes, and we investigate diﬀerent types of preconditioners including sparse approximate inverses. Numerical experiments on linear systems arising from the discretization of partial diﬀerential equations are presented.},
	language = {en},
	number = {3},
	urldate = {2022-09-17},
	journal = {Numerical Linear Algebra with Applications},
	author = {Benzi, Michele and Evans, Thomas M. and Hamilton, Steven P. and Lupo Pasini, Massimiliano and Slattery, Stuart R.},
	month = may,
	year = {2017},
	keywords = {monte carlo, linear systems, sparse},
	file = {Benzi e.a. - 2017 - Analysis of Monte Carlo accelerated iterative meth.pdf:C\:\\Users\\Admin\\Zotero\\storage\\ZL2JBC57\\Benzi e.a. - 2017 - Analysis of Monte Carlo accelerated iterative meth.pdf:application/pdf},
}

@article{ji_reusing_2012,
	title = {Reusing {Random} {Walks} in {Monte} {Carlo} {Methods} for {Linear} {Systems}},
	volume = {9},
	issn = {18770509},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050912001627},
	doi = {10.1016/j.procs.2012.04.041},
	abstract = {In this paper, we present an approach of reusing random walks in Monte Carlo methods for linear systems. The fundamental idea is, during the Monte Carlo sampling process, the random walks generated to estimate one unknown element can also be effectively reused to estimate the other unknowns in the solution vector. As a result, when the random walks are reused, a single random walk can contribute samples for estimations of multiple unknowns in the solution simultaneously while ensuring that the samples for the same unknown element are statistically independent. Consequently, the total number of random walk transition steps needed for estimating the overall solution vector is reduced, which improves the performance of the Monte Carlo algorithm. We apply this approach to the Monte Carlo algorithm in two linear algebra applications, including solving a system of linear equations and approximating the inversion of a matrix. Our computational results show that compared to the conventional implementations of Monte Carlo algorithms for linear systems without random walk reusing, our approach can significantly improve the performance of Monte Carlo sampling process by reducing the overall number of transition steps in random walks to obtain the entire solution within desired precision.},
	language = {en},
	urldate = {2022-09-17},
	journal = {Procedia Computer Science},
	author = {Ji, Hao and Li, Yaohang},
	year = {2012},
	keywords = {monte carlo, linear systems},
	pages = {383--392},
	file = {Ji en Li - 2012 - Reusing Random Walks in Monte Carlo Methods for Li.pdf:C\:\\Users\\Admin\\Zotero\\storage\\G5YWGZPN\\Ji en Li - 2012 - Reusing Random Walks in Monte Carlo Methods for Li.pdf:application/pdf},
}

@article{wu_multiway_2019,
	title = {Multiway {Monte} {Carlo} {Method} for {Linear} {Systems}},
	volume = {41},
	issn = {1064-8275, 1095-7197},
	url = {https://epubs.siam.org/doi/10.1137/18M121527X},
	doi = {10.1137/18M121527X},
	abstract = {We study a novel variation on the Ulam–von Neumann Monte Carlo method for solving a linear system. This is an old randomized procedure that results from using a random walk to stochastically evaluate terms in the Neumann series. In order to apply this procedure, the variance of the stochastic estimator needs to be bounded. The best known suﬃcient condition for bounding the variance is that the inﬁnity norm of the matrix in the Neumann series is smaller than one, which greatly limits the usability of this method. We improve this condition by proposing a new stochastic estimator based on a diﬀerent type of random walk. Our multiway walk and estimator is based on a time-inhomogeneous Markov process that iterates through a sequence of transition matrices built from the original linear system. For our new method, we prove that a necessary and suﬃcient condition for convergence is that the spectral radius of the elementwise absolute value of the matrix underlying the Neumann series is smaller than one. This is a strictly weaker condition than currently exists. In addition, our new method is often faster than the standard algorithm. Through experiments, we demonstrate the potential for our method to reduce the time needed to solve linear equations by incorporating it into an outer iterative method.},
	language = {en},
	number = {6},
	urldate = {2022-09-17},
	journal = {SIAM Journal on Scientific Computing},
	author = {Wu, Tao and Gleich, David F.},
	month = jan,
	year = {2019},
	keywords = {monte carlo, linear systems},
	pages = {A3449--A3475},
	file = {Wu en Gleich - 2019 - Multiway Monte Carlo Method for Linear Systems.pdf:C\:\\Users\\Admin\\Zotero\\storage\\UABEC4GQ\\Wu en Gleich - 2019 - Multiway Monte Carlo Method for Linear Systems.pdf:application/pdf},
}

@article{dick_higher_2019,
	title = {Higher order {Quasi}-{Monte} {Carlo} integration for {Bayesian} {PDE} {Inversion}},
	volume = {77},
	issn = {08981221},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0898122118305315},
	doi = {10.1016/j.camwa.2018.09.019},
	abstract = {We analyze combined Quasi-Monte Carlo quadrature and Finite Element approximations in Bayesian estimation of solutions to countably-parametric operator equations with holomorphic dependence on the parameters as considered in Schillings and Schwab (2014). Such problems arise in numerical uncertainty quantification and in Bayesian inversion of operator equations with distributed uncertain inputs, such as uncertain coefficients, uncertain domains or uncertain source terms and boundary data. We show that the parametric Bayesian posterior densities belong to a class of weighted Bochner spaces of functions of countably many variables, with a particular structure of the QMC quadrature weights: up to a (problem-dependent, and possibly large) finite dimension S product weights can be used, and beyond this dimension, weighted spaces with so-called SPOD weights, recently introduced in Dick et al. (2014), are used to describe the solution regularity. We establish error bounds for higher order Quasi-Monte Carlo quadrature for the Bayesian estimation based on Dick et al. (2016). It implies, in particular, regularity of the parametric solution and of the countably-parametric Bayesian posterior density in SPOD (‘‘Smoothness driven, Product and Order Dependent’’) weighted spaces of integrand functions. This, in turn, implies that the Quasi-Monte Carlo quadrature methods in Dick et al. (2014) are applicable to these problem classes, with dimension-independent convergence rates O(N−1/p) of N-point HoQMC approximated Bayesian estimates, where 0 {\textless} p {\textless} 1 depends only on the sparsity class of the uncertain input in the Bayesian estimation. Fast componentby-component (CBC for short) construction Gantner and Schwab (2016) allow efficient deterministic Bayesian estimation with up to 104 parameters.},
	language = {en},
	number = {1},
	urldate = {2022-09-17},
	journal = {Computers \& Mathematics with Applications},
	author = {Dick, Josef and Gantner, Robert N. and Le Gia, Quoc T. and Schwab, Christoph},
	month = jan,
	year = {2019},
	keywords = {monte carlo},
	pages = {144--172},
	file = {Dick e.a. - 2019 - Higher order Quasi-Monte Carlo integration for Bay.pdf:C\:\\Users\\Admin\\Zotero\\storage\\JNIFMW27\\Dick e.a. - 2019 - Higher order Quasi-Monte Carlo integration for Bay.pdf:application/pdf},
}

@misc{mayaki_autoregressive_2022,
	title = {Autoregressive based {Drift} {Detection} {Method}},
	url = {http://arxiv.org/abs/2203.04769},
	abstract = {In the classic machine learning framework, models are trained on historical data and used to predict future values. It is assumed that the data distribution does not change over time (stationarity). However, in real-world scenarios, the data generation process changes over time and the model has to adapt to the new incoming data. This phenomenon is known as concept drift and leads to a decrease in the predictive model’s performance. In this study, we propose a new concept drift detection method based on autoregressive models called ADDM. This method can be integrated into any machine learning algorithm from deep neural networks to simple linear regression model. Our results show that this new concept drift detection method outperforms the state-of-the-art drift detection methods, both on synthetic data sets and real-world data sets. Our approach is theoretically guaranteed as well as empirical and effective for the detection of various concept drifts. In addition to the drift detector, we proposed a new method of concept drift adaptation based on the severity of the drift.},
	language = {en},
	urldate = {2022-09-17},
	publisher = {arXiv},
	author = {Mayaki, Mansour Zoubeirou A. and Riveill, Michel},
	month = mar,
	year = {2022},
	note = {arXiv:2203.04769 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Mayaki en Riveill - 2022 - Autoregressive based Drift Detection Method.pdf:C\:\\Users\\Admin\\Zotero\\storage\\54YTNIWQ\\Mayaki en Riveill - 2022 - Autoregressive based Drift Detection Method.pdf:application/pdf},
}

@misc{baier_switching_2020,
	title = {Switching {Scheme}: {A} {Novel} {Approach} for {Handling} {Incremental} {Concept} {Drift} in {Real}-{World} {Data} {Sets}},
	shorttitle = {Switching {Scheme}},
	url = {http://arxiv.org/abs/2011.02738},
	abstract = {Machine learning models nowadays play a crucial role for many applications in business and industry. However, models only start adding value as soon as they are deployed into production. One challenge of deployed models is the effect of changing data over time, which is often described with the term concept drift. Due to their nature, concept drifts can severely affect the prediction performance of a machine learning system. In this work, we analyze the effects of concept drift in the context of a real-world data set. For efﬁcient concept drift handling, we introduce the switching scheme which combines the two principles of retraining and updating of a machine learning model. Furthermore, we systematically analyze existing regular adaptation as well as triggered adaptation strategies. The switching scheme is instantiated on New York City taxi data, which is heavily inﬂuenced by changing demand patterns over time. We can show that the switching scheme outperforms all other baselines and delivers promising prediction results.},
	language = {en},
	urldate = {2022-09-17},
	publisher = {arXiv},
	author = {Baier, Lucas and Kellner, Vincent and Kühl, Niklas and Satzger, Gerhard},
	month = nov,
	year = {2020},
	note = {arXiv:2011.02738 [cs]},
	keywords = {Computer Science - Machine Learning, active learning},
	annote = {Comment: 54th Annual Hawaii International Conference on System Sciences (HICSS-54)},
	file = {Baier e.a. - 2020 - Switching Scheme A Novel Approach for Handling In.pdf:C\:\\Users\\Admin\\Zotero\\storage\\4SZGPPN7\\Baier e.a. - 2020 - Switching Scheme A Novel Approach for Handling In.pdf:application/pdf},
}

@techreport{settles_active_2009,
	type = {Technical {Report}},
	title = {Active {Learning} {Literature} {Survey}},
	url = {https://minds.wisconsin.edu/handle/1793/60660},
	abstract = {The key idea behind active learning is that a machine learning algorithm can achieve greater accuracy with fewer labeled training instances if it is allowed to choose the training data from which is learns. An active learner may ask queries in the form of unlabeled instances to be labeled by an oracle (e.g., a human annotator). Active learning is well-motivated in many modern machine learning problems, where unlabeled data may be abundant but labels are difficult, time-consuming, or expensive to obtain. 
 
This report provides a general introduction to active learning and a survey of the literature. This includes a discussion of the scenarios in which queries can be formulated, and an overview of the query strategy frameworks proposed in the literature to date. An analysis of the empirical and theoretical evidence for active learning, a summary of several problem setting variants, and a discussion of related topics in machine learning research are also presented.},
	language = {en},
	urldate = {2022-09-17},
	institution = {University of Wisconsin-Madison Department of Computer Sciences},
	author = {Settles, Burr},
	year = {2009},
	note = {Accepted: 2012-03-15T17:23:56Z},
	keywords = {Computer Science - Machine Learning, active learning},
	file = {Settles - 2009 - Active Learning Literature Survey.pdf:C\:\\Users\\Admin\\Zotero\\storage\\XZAZ8M6G\\Settles - 2009 - Active Learning Literature Survey.pdf:application/pdf;Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\A9QXPGLH\\60660.html:text/html},
}

@misc{noauthor_wayback_2011,
	title = {Wayback {Machine}},
	url = {https://web.archive.org/web/20110903171132/http://www.alexschiller.com/media/Thesis.pdf},
	urldate = {2023-02-20},
	month = sep,
	year = {2011},
	file = {PDF Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\STAQQ2FN\\2011 - Wayback Machine.pdf:application/pdf},
}

@misc{noauthor_malliavin_2022,
	title = {Malliavin calculus},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Malliavin_calculus&oldid=1115107254},
	abstract = {In probability theory and related fields, Malliavin calculus is a set of mathematical techniques and ideas that extend the mathematical field of calculus of variations from  deterministic functions to stochastic processes. In particular, it allows the computation of derivatives of random variables. Malliavin calculus is also called the stochastic calculus of variations. P. Malliavin first initiated the calculus on infinite dimensional space. Then, the significant contributors such as S. Kusuoka, D. Stroock, Bismut, S. Watanabe, I. Shigekawa, and so on finally completed the foundations.
Malliavin calculus is named after Paul Malliavin whose ideas led to a proof that Hörmander's condition implies the existence and smoothness of a density for the solution of a stochastic differential equation; Hörmander's original proof was based on the theory of  partial differential equations. The calculus has been applied to stochastic partial differential equations as well.
The calculus allows integration by parts with random variables; this operation is used in mathematical finance to compute the sensitivities of financial derivatives. The calculus has applications in, for example, stochastic filtering.},
	language = {en},
	urldate = {2023-02-20},
	journal = {Wikipedia},
	month = oct,
	year = {2022},
	note = {Page Version ID: 1115107254},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\SJFH7GTJ\\Malliavin_calculus.html:text/html},
}

@misc{jacquier_stacked_2019,
	title = {Stacked {Monte} {Carlo} for option pricing},
	url = {http://arxiv.org/abs/1903.10795},
	abstract = {We introduce a stacking version of the Monte Carlo algorithm in the context of option pricing. Introduced recently for aeronautic computations, this simple technique, in the spirit of current machine learning ideas, learns control variates by approximating Monte Carlo draws with some speciﬁed function. We describe the method from ﬁrst principles and suggest appropriate ﬁts, and show its eﬃciency to evaluate European and Asian Call options in constant and stochastic volatility models.},
	language = {en},
	urldate = {2023-02-18},
	publisher = {arXiv},
	author = {Jacquier, Antoine and Malone, Emma R. and Oumgari, Mugad},
	month = mar,
	year = {2019},
	note = {arXiv:1903.10795 [math, q-fin]},
	keywords = {Mathematics - Probability, Quantitative Finance - Computational Finance, 65C05, 91B28 65C50},
	annote = {Comment: 12 pages, 13 Figures},
	file = {Jacquier e.a. - 2019 - Stacked Monte Carlo for option pricing.pdf:C\:\\Users\\Admin\\Zotero\\storage\\XMLJ4K7G\\Jacquier e.a. - 2019 - Stacked Monte Carlo for option pricing.pdf:application/pdf},
}

@misc{beck_nonlinear_2020,
	title = {Nonlinear {Monte} {Carlo} methods with polynomial runtime for high-dimensional iterated nested expectations},
	url = {http://arxiv.org/abs/2009.13989},
	abstract = {The approximative calculation of iterated nested expectations is a recurring challenging problem in applications. Nested expectations appear, for example, in the numerical approximation of solutions of backward stochastic diﬀerential equations (BSDEs), in the numerical approximation of solutions of semilinear parabolic partial diﬀerential equations (PDEs), in statistical physics, in optimal stopping problems such as the approximative pricing of American or Bermudan options, in risk measure estimation in mathematical ﬁnance, or in decisionmaking under uncertainty. Nested expectations which arise in the above named applications often consist of a large number of nestings. However, the computational eﬀort of standard nested Monte Carlo approximations for iterated nested expectations grows exponentially in the number of nestings and it remained an open question whether it is possible to approximately calculate multiply iterated high-dimensional nested expectations in polynomial time. In this article we tackle this problem by proposing and studying a new class of full-history recursive multilevel Picard (MLP) approximation schemes for iterated nested expectations. In particular, we prove under suitable assumptions that these MLP approximation schemes can approximately calculate multiply iterated nested expectations with a computational effort growing at most polynomially in the number of nestings K P N “ t1, 2, 3, . . .u, in the problem dimension d P N, and in the reciprocal 1\{\vphantom{\}}ε of the desired approximation accuracy ε P p0, 8q.},
	language = {en},
	urldate = {2023-02-18},
	publisher = {arXiv},
	author = {Beck, Christian and Jentzen, Arnulf and Kruse, Thomas},
	month = sep,
	year = {2020},
	note = {arXiv:2009.13989 [cs, math]},
	keywords = {Mathematics - Probability, Mathematics - Numerical Analysis, 65C05 (Primary) 65M75, 68Q25 (Secondary), Computer Science - Computational Complexity},
	annote = {Comment: 47 pages},
	file = {Beck e.a. - 2020 - Nonlinear Monte Carlo methods with polynomial runt.pdf:C\:\\Users\\Admin\\Zotero\\storage\\DERMR4VB\\Beck e.a. - 2020 - Nonlinear Monte Carlo methods with polynomial runt.pdf:application/pdf},
}

@misc{sinha_multilevel_2022,
	title = {Multilevel {Monte} {Carlo} and its {Applications} in {Financial} {Engineering}},
	url = {http://arxiv.org/abs/2209.14549},
	abstract = {In this article, we present a review of the recent developments on the topic of Multilevel Monte Carlo (MLMC) algorithm, in the paradigm of applications in ﬁnancial engineering. We speciﬁcally focus on the recent studies conducted in two subareas, namely, option pricing and ﬁnancial risk management. For the former, the discussion involves incorporation of the importance sampling algorithm, in conjunction with the MLMC estimator, thereby constructing a hybrid algorithm in order to achieve reduction for the overall variance of the estimator. In case of the latter, we discuss the studies carried out in order to construct an efﬁcient algorithm in order to estimate the risk measures of Value-at-Risk (VaR) and Conditional Var (CVaR), in an efﬁcient manner. In this regard, we brieﬂy discuss the motivation and the construction of an adaptive sampling algorithm with an aim to efﬁciently estimate the nested expectation, which, in general is computationally expensive.},
	language = {en},
	urldate = {2023-02-18},
	publisher = {arXiv},
	author = {Sinha, Devang and Chakrabarty, Siddhartha P.},
	month = sep,
	year = {2022},
	note = {arXiv:2209.14549 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance},
	file = {Sinha en Chakrabarty - 2022 - Multilevel Monte Carlo and its Applications in Fin.pdf:C\:\\Users\\Admin\\Zotero\\storage\\YZXZQ439\\Sinha en Chakrabarty - 2022 - Multilevel Monte Carlo and its Applications in Fin.pdf:application/pdf},
}

@article{vicini_path_2021,
	title = {Path replay backpropagation: differentiating light paths using constant memory and linear time},
	volume = {40},
	issn = {0730-0301, 1557-7368},
	shorttitle = {Path replay backpropagation},
	url = {https://dl.acm.org/doi/10.1145/3450626.3459804},
	doi = {10.1145/3450626.3459804},
	abstract = {Differentiable physically-based rendering has become an indispensable tool for solving inverse problems involving light. Most applications in this area jointly optimize a large set of scene parameters to minimize an objective function, in which case reverse-mode differentiation is the method of choice for obtaining parameter gradients.
            However, existing techniques that perform the necessary differentiation step suffer from either statistical bias or a prohibitive cost in terms of memory and computation time. For example, standard techniques for automatic differentiation based on program transformation or Wengert tapes lead to impracticably large memory usage when applied to physically-based rendering algorithms. A recently proposed adjoint method by Nimier-David et al. [2020] reduces this to a constant memory footprint, but the computation time for unbiased gradient estimates then becomes quadratic in the number of scattering events along a light path. This is problematic when the scene contains highly scattering materials like participating media.
            In this paper, we propose a new unbiased backpropagation algorithm for rendering that only requires constant memory, and whose computation time is linear in the number of scattering events (i.e., just like path tracing). Our approach builds on the invertibility of the local Jacobian at scattering interactions to recover the various quantities needed for reverse-mode differentiation. Our method also extends to specular materials such as smooth dielectrics and conductors that cannot be handled by prior work.},
	language = {en},
	number = {4},
	urldate = {2023-02-17},
	journal = {ACM Transactions on Graphics},
	author = {Vicini, Delio and Speierer, Sébastien and Jakob, Wenzel},
	month = aug,
	year = {2021},
	pages = {1--14},
	file = {Vicini e.a. - 2021 - Path replay backpropagation differentiating light.pdf:C\:\\Users\\Admin\\Zotero\\storage\\CYDBTJMN\\Vicini e.a. - 2021 - Path replay backpropagation differentiating light.pdf:application/pdf},
}

@book{wesseling_introduction_1992,
	address = {Chichester ; New York},
	series = {Pure and applied mathematics},
	title = {An introduction to multigrid methods},
	isbn = {978-0-471-93083-9},
	language = {en},
	publisher = {Wiley},
	author = {Wesseling, Pieter},
	year = {1992},
	keywords = {Multigrid methods (Numerical analysis)},
	file = {Wesseling - 1992 - An introduction to multigrid methods.pdf:C\:\\Users\\Admin\\Zotero\\storage\\J3WZP5VH\\Wesseling - 1992 - An introduction to multigrid methods.pdf:application/pdf},
}

@article{anikin_efficient_2022,
	title = {Efficient {Numerical} {Methods} to {Solve} {Sparse} {Linear} {Equations} with {Application} to {PageRank}},
	volume = {37},
	issn = {1055-6788, 1029-4937},
	url = {http://arxiv.org/abs/1508.07607},
	doi = {10.1080/10556788.2020.1858297},
	abstract = {Over the last two decades, the PageRank problem has received increased interest from the academic community as an efficient tool to estimate web-page importance in information retrieval. Despite numerous developments, the design of efficient optimization algorithms for the PageRank problem is still a challenge. This paper proposes three new algorithms with a linear-time complexity for solving the problem over a bounded-degree graph. The idea behind them is to set up the PageRank as a convex minimization problem over a unit simplex, and then solve it using iterative methods with small iteration complexity. Our theoretical results are supported by an extensive empirical justification using real-world and simulated data.},
	language = {en},
	number = {3},
	urldate = {2023-02-14},
	journal = {Optimization Methods and Software},
	author = {Anikin, Anton and Gasnikov, Alexander and Gornov, Alexander and Kamzolov, Dmitry and Maximov, Yury and Nesterov, Yurii},
	month = may,
	year = {2022},
	note = {arXiv:1508.07607 [math]},
	keywords = {Mathematics - Optimization and Control},
	pages = {907--935},
	annote = {Comment: 26 pages; Accepted to Optimization Methods and Software},
	file = {Anikin e.a. - 2022 - Efficient Numerical Methods to Solve Sparse Linear.pdf:C\:\\Users\\Admin\\Zotero\\storage\\7AQ4PXSZ\\Anikin e.a. - 2022 - Efficient Numerical Methods to Solve Sparse Linear.pdf:application/pdf},
}

@article{nesterov_gradient_2022,
	title = {Gradient {Methods} with {Memory}},
	volume = {37},
	issn = {1055-6788, 1029-4937},
	url = {http://arxiv.org/abs/2105.09241},
	doi = {10.1080/10556788.2020.1858831},
	abstract = {In this paper, we consider gradient methods for minimizing smooth convex functions, which employ the information obtained at the previous iterations in order to accelerate the convergence towards the optimal solution. This information is used in the form of a piece-wise linear model of the objective function, which provides us with much better prediction abilities as compared with the standard linear model. To the best of our knowledge, this approach was never really applied in Convex Minimization to diﬀerentiable functions in view of the high complexity of the corresponding auxiliary problems. However, we show that all necessary computations can be done very eﬃciently. Consequently, we get new optimization methods, which are better than the usual Gradient Methods both in the number of oracle calls and in the computational time. Our theoretical conclusions are conﬁrmed by preliminary computational experiments.},
	language = {en},
	number = {3},
	urldate = {2023-02-14},
	journal = {Optimization Methods and Software},
	author = {Nesterov, Yurii and Florea, Mihai I.},
	month = may,
	year = {2022},
	note = {arXiv:2105.09241 [math]},
	keywords = {Mathematics - Optimization and Control, 68Q25, 65Y20, 90C25},
	pages = {936--953},
	annote = {Comment: This is an Accepted Manuscript of an article published by Taylor {\textbackslash}\& Francis in Optimization Methods and Software on 13 Jan 2021, available at https://www.tandfonline.com/doi/10.1080/10556788.2020.1858831},
	file = {Nesterov en Florea - 2022 - Gradient Methods with Memory.pdf:C\:\\Users\\Admin\\Zotero\\storage\\EZKMSTTQ\\Nesterov en Florea - 2022 - Gradient Methods with Memory.pdf:application/pdf},
}

@misc{glau_new_2018,
	title = {A new approach for {American} option pricing: {The} {Dynamic} {Chebyshev} method},
	shorttitle = {A new approach for {American} option pricing},
	url = {http://arxiv.org/abs/1806.05579},
	abstract = {We introduce a new method to price American options based on Chebyshev interpolation. In each step of a dynamic programming time-stepping we approximate the value function with Chebyshev polynomials. The key advantage of this approach is that it allows to shift the model-dependent computations into an oﬄine phase prior to the time-stepping. In the oﬄine part a family of generalised (conditional) moments is computed by an appropriate numerical technique such as a Monte Carlo, PDE or Fourier transform based method. Thanks to this methodological ﬂexibility the approach applies to a large variety of models. Online, the backward induction is solved on a discrete Chebyshev grid, and no (conditional) expectations need to be computed. For each time step the method delivers a closed form approximation of the price function along with the options’ delta and gamma. Moreover, the same family of (conditional) moments yield multiple outputs including the option prices for diﬀerent strikes, maturities and diﬀerent payoﬀ proﬁles. We provide a theoretical error analysis and ﬁnd conditions that imply explicit error bounds for a variety of stock price models. Numerical experiments conﬁrm the fast convergence of prices and sensitivities. An empirical investigation of accuracy and runtime also shows an eﬃciency gain compared with the least-square Monte-Carlo method introduced by Longstaﬀ and Schwartz (2001).},
	language = {en},
	urldate = {2023-02-13},
	publisher = {arXiv},
	author = {Glau, Kathrin and Mahlstedt, Mirco and Pötz, Christian},
	month = jun,
	year = {2018},
	note = {arXiv:1806.05579 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance, 91G60, 41A10},
	file = {Glau e.a. - 2018 - A new approach for American option pricing The Dy.pdf:C\:\\Users\\Admin\\Zotero\\storage\\5CD69T7N\\Glau e.a. - 2018 - A new approach for American option pricing The Dy.pdf:application/pdf},
}

@misc{glau_speed-up_2019,
	title = {Speed-up credit exposure calculations for pricing and risk management},
	url = {http://arxiv.org/abs/1912.01280},
	abstract = {We introduce a new method to calculate the credit exposure of European and path-dependent options. The proposed method is able to calculate accurate expected exposure and potential future exposure proﬁles under the riskneutral and the real-world measure. Key advantage of is that it delivers an accuracy comparable to a full re-evaluation and at the same time it is faster than a regression-based method. Core of the approach is solving a dynamic programming problem by function approximation. This yields a closed form approximation along the paths together with the option’s delta and gamma. The simple structure allows for highly eﬃcient evaluation of the exposures, even for a large number of simulated paths. The approach is ﬂexible in the model choice, payoﬀ proﬁles and asset classes. We validate the accuracy of the method numerically for three diﬀerent equity products and a Bermudan interest rate swaption. Benchmarking against the popular least-squares Monte Carlo approach shows that our method is able to deliver a higher accuracy in a faster runtime.},
	language = {en},
	urldate = {2023-02-13},
	publisher = {arXiv},
	author = {Glau, Kathrin and Pachon, Ricardo and Pötz, Christian},
	month = dec,
	year = {2019},
	note = {arXiv:1912.01280 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance, Quantitative Finance - Risk Management},
	annote = {Comment: arXiv admin note: substantial text overlap with arXiv:1905.00238},
	file = {Glau e.a. - 2019 - Speed-up credit exposure calculations for pricing .pdf:C\:\\Users\\Admin\\Zotero\\storage\\5CIFA7XE\\Glau e.a. - 2019 - Speed-up credit exposure calculations for pricing .pdf:application/pdf},
}

@misc{glau_low-rank_2019,
	title = {Low-rank tensor approximation for {Chebyshev} interpolation in parametric option pricing},
	url = {http://arxiv.org/abs/1902.04367},
	abstract = {Treating high dimensionality is one of the main challenges in the development of computational methods for solving problems arising in ﬁnance, where tasks such as pricing, calibration, and risk assessment need to be performed accurately and in real-time. Among the growing literature addressing this problem, Gass et al. [14] propose a complexity reduction technique for parametric option pricing based on Chebyshev interpolation. As the number of parameters increases, however, this method is aﬀected by the curse of dimensionality. In this article, we extend this approach to treat high-dimensional problems: Additionally exploiting low-rank structures allows us to consider parameter spaces of high dimensions. The core of our method is to express the tensorized interpolation in tensor train (TT) format and to develop an eﬃcient way, based on tensor completion, to approximate the interpolation coeﬃcients. We apply the new method to two model problems: American option pricing in the Heston model and European basket option pricing in the multi-dimensional Black-Scholes model. In these examples we treat parameter spaces of dimensions up to 25. The numerical results conﬁrm the low-rank structure of these problems and the eﬀectiveness of our method compared to advanced techniques.},
	language = {en},
	urldate = {2023-02-13},
	publisher = {arXiv},
	author = {Glau, Kathrin and Kressner, Daniel and Statti, Francesco},
	month = feb,
	year = {2019},
	note = {arXiv:1902.04367 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance},
	file = {Glau e.a. - 2019 - Low-rank tensor approximation for Chebyshev interp.pdf:C\:\\Users\\Admin\\Zotero\\storage\\5FSQELEL\\Glau e.a. - 2019 - Low-rank tensor approximation for Chebyshev interp.pdf:application/pdf},
}

@misc{glau_deep_2020,
	title = {The {Deep} {Parametric} {PDE} {Method}: {Application} to {Option} {Pricing}},
	shorttitle = {The {Deep} {Parametric} {PDE} {Method}},
	url = {http://arxiv.org/abs/2012.06211},
	abstract = {We propose the deep parametric PDE method to solve high-dimensional parametric partial diﬀerential equations. A single neural network approximates the solution of a whole family of PDEs after being trained without the need of sample solutions. As a practical application, we compute option prices in the multivariate Black-Scholes model. After a single training phase, the prices for diﬀerent time, state and model parameters are available in milliseconds. We evaluate the accuracy in the price and a generalisation of the implied volatility with examples of up to 25 dimensions. A comparison with alternative machine learning approaches, conﬁrms the eﬀectiveness of the approach.},
	language = {en},
	urldate = {2023-02-13},
	publisher = {arXiv},
	author = {Glau, Kathrin and Wunderlich, Linus},
	month = dec,
	year = {2020},
	note = {arXiv:2012.06211 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance},
	annote = {Comment: Some examples can be reproduced in our Jupyter Notebook: https://github.com/LWunderlich/DeepPDE/blob/main/TwoAssetsExample/DeepParametricPDEExample.ipynb},
	file = {Glau en Wunderlich - 2020 - The Deep Parametric PDE Method Application to Opt.pdf:C\:\\Users\\Admin\\Zotero\\storage\\3AXRVL4J\\Glau en Wunderlich - 2020 - The Deep Parametric PDE Method Application to Opt.pdf:application/pdf},
}

@misc{glau_chebyshev_2017,
	title = {The {Chebyshev} method for the implied volatility},
	url = {http://arxiv.org/abs/1710.01797},
	abstract = {The implied volatility is a crucial element of any ﬁnancial toolbox, since it is used for quoting and the hedging of options as well as for model calibration. In contrast to the BlackScholes formula its inverse, the implied volatility, is not explicitly available and numerical approximation is required. We propose a bivariate interpolation of the implied volatility surface based on Chebyshev polynomials. This yields a closed-form approximation of the implied volatility, which is easy to implement and to maintain. We prove a subexponential error decay. This allows us to obtain an accuracy close to machine precision with polynomials of a low degree. We compare the performance of the method in terms of runtime and accuracy to the most common reference methods. In contrast to existing interpolation methods, the proposed method is able to compute the implied volatility for all relevant option data. In this context, numerical experiments conﬁrm a considerable increase in eﬃciency, especially for large data sets.},
	language = {en},
	urldate = {2023-02-13},
	publisher = {arXiv},
	author = {Glau, Kathrin and Herold, Paul and Madan, Dilip B. and Pötz, Christian},
	month = oct,
	year = {2017},
	note = {arXiv:1710.01797 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance, 91G60, 90-08, 65D05},
	file = {Glau e.a. - 2017 - The Chebyshev method for the implied volatility.pdf:C\:\\Users\\Admin\\Zotero\\storage\\3VZDVADR\\Glau e.a. - 2017 - The Chebyshev method for the implied volatility.pdf:application/pdf},
}

@misc{gas_chebyshev_2016,
	title = {Chebyshev {Interpolation} for {Parametric} {Option} {Pricing}},
	url = {http://arxiv.org/abs/1505.04648},
	abstract = {Recurrent tasks such as pricing, calibration and risk assessment need to be executed accurately and in real-time. Simultaneously we observe an increase in model sophistication on the one hand and growing demands on the quality of risk management on the other. To address the resulting computational challenges, it is natural to exploit the recurrent nature of these tasks. We concentrate on Parametric Option Pricing (POP) and show that polynomial interpolation in the parameter space promises to reduce run-times while maintaining accuracy. The attractive properties of Chebyshev interpolation and its tensorized extension enable us to identify criteria for (sub)exponential convergence and explicit error bounds. We show that these results apply to a variety of European (basket) options and aﬃne asset models. Numerical experiments conﬁrm our ﬁndings. Exploring the potential of the method further, we empirically investigate the eﬃciency of the Chebyshev method for multivariate and path-dependent options.},
	language = {en},
	urldate = {2023-02-13},
	publisher = {arXiv},
	author = {Gaß, Maximilian and Glau, Kathrin and Mahlstedt, Mirco and Mair, Maximilian},
	month = jul,
	year = {2016},
	note = {arXiv:1505.04648 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance, 91G60, 41A10},
	annote = {Comment: Multivariate Option Pricing, Complexity Reduction, (Tensorized) Chebyshev Polynomials, Polynomial Interpolation, Fourier Transform Methods, Monte Carlo, Affine Processes},
	file = {Gaß e.a. - 2016 - Chebyshev Interpolation for Parametric Option Pric.pdf:C\:\\Users\\Admin\\Zotero\\storage\\3RRJ3YJB\\Gaß e.a. - 2016 - Chebyshev Interpolation for Parametric Option Pric.pdf:application/pdf},
}

@misc{steffes-lai_interpolation_2013,
	title = {Interpolation methods to compute statistics of a stochastic partial differential equation},
	url = {http://arxiv.org/abs/1309.3853},
	abstract = {This paper considers the analysis of partial diﬀerential equations (PDE) containing multiple random variables. Recently developed collocation methods enable the construction of high-order stochastic solutions by converting a stochastic PDE into a system of deterministic PDEs. This interpolation method requires that the probability distribution of all random input variables is known a priori, which is often not the case in industrially relevant applications. Additionally, this method suﬀers from a curse of dimensionality, i.e., the number of deterministic PDEs to be solved grows exponentially with respect to the number of random variables. This paper presents an alternative interpolation method, based on a radial basis function (RBF) metamodel, to compute statistics of the stochastic PDE. The RBF metamodel can be constructed even if the probability distribution of all random variables is not known. Then, a lot of statistic scenarios with diﬀerent probability distributions of the random variables can be computed with this single metamodel. In order to reduce the model complexity, we present a parameter screening technique which can be combined with an interpolation method to solve a reduced stochastic model. Numerical results of a model problem demonstrate that the RBF metamodel is as fast as a low order collocation approach and achieves a good accuracy. The parameter screening is able to reduce the dimension and, thus, to accelerate the computation of the stochastic solution.},
	language = {en},
	urldate = {2023-02-13},
	publisher = {arXiv},
	author = {Steffes-lai, Daniela and Rosseel, Eveline and Clees, Tanja},
	month = sep,
	year = {2013},
	note = {arXiv:1309.3853 [math]},
	keywords = {Mathematics - Numerical Analysis, 35R60, 62H25, 93B35, 65N22},
	annote = {Comment: 26 pages},
	file = {Steffes-lai e.a. - 2013 - Interpolation methods to compute statistics of a s.pdf:C\:\\Users\\Admin\\Zotero\\storage\\DUFXWZYZ\\Steffes-lai e.a. - 2013 - Interpolation methods to compute statistics of a s.pdf:application/pdf},
}

@misc{deelstra_accelerated_2022,
	title = {Accelerated {Computations} of {Sensitivities} for {xVA}},
	url = {http://arxiv.org/abs/2211.17026},
	abstract = {Exposure simulations are fundamental to many xVA calculations and are a nested expectation problem where repeated portfolio valuations create a signiﬁcant computational expense. Sensitivity calculations which require shocked and unshocked valuations in bump-and-revalue schemes exacerbate the computational load. A known reduction of the portfolio valuation cost is understood to be found in polynomial approximations, which we apply in this article to interest rate sensitivities of expected exposures. We consider a method based on the approximation of the shocked and unshocked valuation functions, as well as a novel approach in which the diﬀerence between these functions is approximated. Convergence results are shown, and we study the choice of interpolation nodes. Numerical experiments with interest rate derivatives are conducted to demonstrate the high accuracy and remarkable computational cost reduction. We further illustrate how the method can be extended to more general xVA models using the example of CVA with wrong-way risk.},
	language = {en},
	urldate = {2023-02-13},
	publisher = {arXiv},
	author = {Deelstra, Griselda and Grzelak, Lech A. and Wolf, Felix},
	month = nov,
	year = {2022},
	note = {arXiv:2211.17026 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance, Quantitative Finance - Risk Management, 91G20, 91G30},
	file = {Deelstra e.a. - 2022 - Accelerated Computations of Sensitivities for xVA.pdf:C\:\\Users\\Admin\\Zotero\\storage\\GCGYS354\\Deelstra e.a. - 2022 - Accelerated Computations of Sensitivities for xVA.pdf:application/pdf},
}

@misc{teckentrup_multilevel_2014,
	title = {A {Multilevel} {Stochastic} {Collocation} {Method} for {Partial} {Differential} {Equations} with {Random} {Input} {Data}},
	url = {http://arxiv.org/abs/1404.2647},
	abstract = {Stochastic collocation methods for approximating the solution of partial diﬀerential equations with random input data (e.g., coeﬃcients and forcing terms) suﬀer from the curse of dimensionality whereby increases in the stochastic dimension cause an explosion of the computational eﬀort. We propose and analyze a multilevel version of the stochastic collocation method that, as is the case for multilevel Monte Carlo (MLMC) methods, uses hierarchies of spatial approximations to reduce the overall computational complexity. In addition, our proposed approach utilizes, for approximation in stochastic space, a sequence of multi-dimensional interpolants of increasing ﬁdelity which can then be used for approximating statistics of the solution as well as for building highorder surrogates featuring faster convergence rates. A rigorous convergence and computational cost analysis of the new multilevel stochastic collocation method is provided, demonstrating its advantages compared to standard single-level stochastic collocation approximations as well as MLMC methods. Numerical results are provided that illustrate the theory and the eﬀectiveness of the new multilevel method.},
	language = {en},
	urldate = {2023-02-13},
	publisher = {arXiv},
	author = {Teckentrup, Aretha L. and Jantsch, Peter and Webster, Clayton G. and Gunzburger, Max},
	month = may,
	year = {2014},
	note = {arXiv:1404.2647 [math]},
	keywords = {Mathematics - Numerical Analysis},
	file = {Teckentrup e.a. - 2014 - A Multilevel Stochastic Collocation Method for Par.pdf:C\:\\Users\\Admin\\Zotero\\storage\\R98M8FWQ\\Teckentrup e.a. - 2014 - A Multilevel Stochastic Collocation Method for Par.pdf:application/pdf},
}

@article{xiu_high-order_2005,
	title = {High-{Order} {Collocation} {Methods} for {Differential} {Equations} with {Random} {Inputs}},
	volume = {27},
	issn = {1064-8275, 1095-7197},
	url = {http://epubs.siam.org/doi/10.1137/040615201},
	doi = {10.1137/040615201},
	abstract = {Recently there has been a growing interest in designing eﬃcient methods for the solution of ordinary/partial diﬀerential equations with random inputs. To this end, stochastic Galerkin methods appear to be superior to other nonsampling methods and, in many cases, to several sampling methods. However, when the governing equations take complicated forms, numerical implementations of stochastic Galerkin methods can become nontrivial and care is needed to design robust and eﬃcient solvers for the resulting equations. On the other hand, the traditional sampling methods, e.g., Monte Carlo methods, are straightforward to implement, but they do not oﬀer convergence as fast as stochastic Galerkin methods. In this paper, a high-order stochastic collocation approach is proposed. Similar to stochastic Galerkin methods, the collocation methods take advantage of an assumption of smoothness of the solution in random space to achieve fast convergence. However, the numerical implementation of stochastic collocation is trivial, as it requires only repetitive runs of an existing deterministic solver, similar to Monte Carlo methods. The computational cost of the collocation methods depends on the choice of the collocation points, and we present several feasible constructions. One particular choice, based on sparse grids, depends weakly on the dimensionality of the random space and is more suitable for highly accurate computations of practical applications with large dimensional random inputs. Numerical examples are presented to demonstrate the accuracy and eﬃciency of the stochastic collocation methods.},
	language = {en},
	number = {3},
	urldate = {2023-02-13},
	journal = {SIAM Journal on Scientific Computing},
	author = {Xiu, Dongbin and Hesthaven, Jan S.},
	month = jan,
	year = {2005},
	pages = {1118--1139},
	file = {Xiu en Hesthaven - 2005 - High-Order Collocation Methods for Differential Eq.pdf:C\:\\Users\\Admin\\Zotero\\storage\\PJ6XFAQG\\Xiu en Hesthaven - 2005 - High-Order Collocation Methods for Differential Eq.pdf:application/pdf},
}

@misc{stein_multilevel_2023,
	title = {Multilevel {Markov} {Chain} {Monte} {Carlo} for {Bayesian} {Elliptic} {Inverse} {Problems} with {Besov} {Random} {Tree} {Priors}},
	url = {http://arxiv.org/abs/2302.00678},
	abstract = {We propose a multilevel Markov chain Monte Carlo -FEM algorithm to solve elliptic Bayesian inverse problems with ”Besov random tree prior”. These priors are given by a wavelet series with stochastic coeﬃcients, and certain terms in the expansion vanishing at random, according to the law of so-called Galton-Watson trees. This allows to incorporate random fractal structures and large deviations in the log-diﬀusion, which occur naturally in many applications from geophysics or medical imaging. This framework entails two main diﬃculties: First, the associated diﬀusion coeﬃcient does not satisfy a uniform ellipticity condition, which leads to non-integrable terms and thus divergence of standard multilevel estimators. Secondly, the associated space of parameters is Polish, but not a normed linear space. We address the ﬁrst point by introducing cut-oﬀ functions in the estimator to compensate for the non-integrable terms, while the second issue is resolved by employing an independence Metropolis-Hastings sampler. The resulting algorithm converges in the mean-square sense with essentially optimal asymptotic complexity, and dimension-independent acceptance probabilities.},
	language = {en},
	urldate = {2023-02-13},
	publisher = {arXiv},
	author = {Stein, Andreas and Hoang, Viet Ha},
	month = feb,
	year = {2023},
	note = {arXiv:2302.00678 [cs, math]},
	keywords = {Mathematics - Probability, Mathematics - Numerical Analysis, 35R30, 65C05, 65C40, 65N12, 65N15, 65N30, 60G60},
	annote = {Comment: 31 pages. arXiv admin note: text overlap with arXiv:2302.00522},
	file = {Stein en Hoang - 2023 - Multilevel Markov Chain Monte Carlo for Bayesian E.pdf:C\:\\Users\\Admin\\Zotero\\storage\\8HQLRDI8\\Stein en Hoang - 2023 - Multilevel Markov Chain Monte Carlo for Bayesian E.pdf:application/pdf},
}

@misc{dashti_bayesian_2015,
	title = {The {Bayesian} {Approach} {To} {Inverse} {Problems}},
	url = {http://arxiv.org/abs/1302.6989},
	abstract = {These lecture notes highlight the mathematical and computational structure relating to the formulation of, and development of algorithms for, the Bayesian approach to inverse problems in diﬀerential equations. This approach is fundamental in the quantiﬁcation of uncertainty within applications involving the blending of mathematical models with data. The ﬁnite dimensional situation is described ﬁrst, along with some motivational examples. Then the development of probability measures on separable Banach space is undertaken, using a random series over an inﬁnite set of functions to construct draws; these probability measures are used as priors in the Bayesian approach to inverse problems. Regularity of draws from the priors is studied in the natural Sobolev or Besov spaces implied by the choice of functions in the random series construction, and the Kolmogorov continuity theorem is used to extend regularity considerations to the space of H¨older continuous functions. Bayes’ theorem is derived in this prior setting, and here interpreted as ﬁnding conditions under which the posterior is absolutely continuous with respect to the prior, and determining a formula for the Radon-Nikodym derivative in terms of the likelihood of the data. Having established the form of the posterior, we then describe various properties common to it in the inﬁnite dimensional setting. These properties include well-posedness, approximation theory, and the existence of maximum a posteriori estimators. We then describe measure-preserving dynamics, again on the inﬁnite dimensional space, including Markov chain-Monte Carlo and sequential Monte Carlo methods, and measure-preserving reversible stochastic diﬀerential equations. By formulating the theory and algorithms on the underlying inﬁnite dimensional space, we obtain a framework suitable for rigorous analysis of the accuracy of reconstructions, of computational complexity, as well as naturally constructing algorithms which perform well under mesh reﬁnement, since they are inherently well-deﬁned in inﬁnite dimensions.},
	language = {en},
	urldate = {2023-02-13},
	publisher = {arXiv},
	author = {Dashti, Masoumeh and Stuart, Andrew M.},
	month = jul,
	year = {2015},
	note = {arXiv:1302.6989 [math]},
	keywords = {Mathematics - Probability},
	annote = {Comment: Lecture notes to appear in Handbook of Uncertainty Quantification, Editors R. Ghanem, D. Higdon and H. Owhadi, Springer, 2016},
	file = {Dashti en Stuart - 2015 - The Bayesian Approach To Inverse Problems.pdf:C\:\\Users\\Admin\\Zotero\\storage\\L5WQXGWS\\Dashti en Stuart - 2015 - The Bayesian Approach To Inverse Problems.pdf:application/pdf},
}

@article{kekkonen_bayesian_nodate,
	title = {Bayesian inverse problems},
	language = {en},
	author = {Kekkonen, Hanne},
	file = {Kekkonen - Bayesian inverse problems.pdf:C\:\\Users\\Admin\\Zotero\\storage\\FC5CGCB4\\Kekkonen - Bayesian inverse problems.pdf:application/pdf},
}

@article{rath_variance-aware_2020,
	title = {Variance-aware path guiding},
	volume = {39},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/3386569.3392441},
	doi = {10.1145/3386569.3392441},
	abstract = {Path guiding is a promising tool to improve the performance of path tracing algorithms. However, not much research has investigated what target densities a guiding method should strive to learn for optimal performance. Instead, most previous work pursues the zero-variance goal: The local decisions are guided under the assumption that all other decisions along the random walk will be sampled perfectly. In practice, however, many decisions are poorly guided, or not guided at all. Furthermore, learned distributions are often marginalized, e.g., by neglecting the BSDF. We present a generic procedure to derive theoretically optimal target densities for local path guiding. These densities account for variance in nested estimators, and marginalize provably well over, e.g., the BSDF. We apply our theory in two state-of-the-art rendering applications: a path guiding solution for unidirectional path tracing [Müller et al. 2017] and a guiding method for light source selection for the many lights problem [Vévoda et al. 2018]. In both cases, we observe significant improvements, especially on glossy surfaces. The implementations for both applications consist of trivial modifications to the original code base, without introducing any additional overhead.},
	language = {en},
	number = {4},
	urldate = {2023-02-11},
	journal = {ACM Transactions on Graphics},
	author = {Rath, Alexander and Grittmann, Pascal and Herholz, Sebastian and Vévoda, Petr and Slusallek, Philipp and Křivánek, Jaroslav},
	month = aug,
	year = {2020},
	file = {Rath e.a. - 2020 - Variance-aware path guiding.pdf:C\:\\Users\\Admin\\Zotero\\storage\\X79P4T7Y\\Rath e.a. - 2020 - Variance-aware path guiding.pdf:application/pdf},
}

@misc{toulis_asymptotic_2016,
	title = {Asymptotic and finite-sample properties of estimators based on stochastic gradients},
	url = {http://arxiv.org/abs/1408.2923},
	abstract = {Stochastic optimization procedures, such as stochastic gradient descent, have gained popularity for parameter estimation from large data sets. However, standard stochastic optimization procedures cannot eﬀectively combine numerical stability with statistical and computational eﬃciency. Here, we introduce an implicit stochastic gradient descent procedure, the iterates of which are implicitly deﬁned. Intuitively, implicit iterates shrink the standard iterates. The amount of shrinkage depends on the observed Fisher information matrix, which does not need to be explicitly computed in practice, thus increasing stability without increasing the computational burden. When combined with averaging, the proposed procedure achieves statistical eﬃciency as well. We derive non-asymptotic bounds and characterize the asymptotic distribution of implicit procedures. Our analysis also reveals the asymptotic variance of a number of existing procedures. We demonstrate implicit stochastic gradient descent by further developing theory for generalized linear models, Cox proportional hazards, and M-estimation problems, and by carrying out extensive experiments. Our results suggest that the implicit stochastic gradient descent procedure is poised to become the workhorse of estimation with large data sets.},
	language = {en},
	urldate = {2023-02-11},
	publisher = {arXiv},
	author = {Toulis, Panos and Airoldi, Edoardo M.},
	month = sep,
	year = {2016},
	note = {arXiv:1408.2923 [stat]},
	keywords = {Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology, 62L20, 62L12, 65L20},
	annote = {Comment: Annals of Statistics, 2016, forthcoming; 71 pages, 37-page main body; 9 figures; 6 tables},
	file = {Toulis en Airoldi - 2016 - Asymptotic and finite-sample properties of estimat.pdf:C\:\\Users\\Admin\\Zotero\\storage\\IUAWENHV\\Toulis en Airoldi - 2016 - Asymptotic and finite-sample properties of estimat.pdf:application/pdf},
}

@inproceedings{unser_ten_1997,
	address = {San Diego, CA},
	title = {Ten good reasons for using spline wavelets},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=930676},
	doi = {10.1117/12.292801},
	abstract = {The purpose of this note is to highlight some of the unique properties of spline wavelets. These wavelets can be classified in four categories: othogonal (Battle-Lemarié), semi-orthogonal (e.g., B-spline), shift-orthogonal, and biorthogonal (Cohen-DaubechiesFeauveau). Unlike most other wavelet bases, splines have explicit formulae in both the time and frequency domain, which greatly facilitates their manipulation. They allow for a progressive transition between the two extreme cases of a multiresolution: Haar's piecewise constant representation (spline of degree zero) versus Shannon's bandlimited model (which corresponds to a spline of infinite order). Spline wavelets are extremely regular and usually symmetric or anti-symmetric. They can be designed to have compact support and to achieve optimal time-frequency localization (B-spline wavelets). The underlying scaling functions are the B-splines, which are the shortest and most regular scaling functions of order L. Finally, splines have the best approximation properties among all known wavelets of a given order L. In other words, they are the best for approximating smooth functions.},
	language = {en},
	urldate = {2023-02-11},
	author = {Unser, Michael A.},
	editor = {Aldroubi, Akram and Laine, Andrew F. and Unser, Michael A.},
	month = oct,
	year = {1997},
	pages = {422--431},
	file = {Unser - 1997 - Ten good reasons for using spline wavelets.pdf:C\:\\Users\\Admin\\Zotero\\storage\\CQW7SJ6F\\Unser - 1997 - Ten good reasons for using spline wavelets.pdf:application/pdf},
}

@misc{the_abel_prize_ingrid_2020,
	title = {Ingrid {Daubechies}: {Wavelet} bases: roots, surprises and applications},
	shorttitle = {Ingrid {Daubechies}},
	url = {https://www.youtube.com/watch?v=tMV61BZCrhk},
	urldate = {2023-02-11},
	author = {{The Abel Prize}},
	month = feb,
	year = {2020},
}

@misc{noauthor_fast_nodate,
	title = {Fast {Wavelet} {Transform} ({FWT}) {Algorithm} - {MATLAB} \& {Simulink}},
	url = {https://www.mathworks.com/help/wavelet/ug/fast-wavelet-transform-fwt-algorithm.html?ue},
	urldate = {2023-02-11},
	file = {Fast Wavelet Transform (FWT) Algorithm - MATLAB & Simulink:C\:\\Users\\Admin\\Zotero\\storage\\IZRA3VBE\\fast-wavelet-transform-fwt-algorithm.html:text/html},
}

@article{lfant_numerical_nodate,
	title = {Numerical integration in complex interval arithmetic},
	language = {en},
	author = {Lfant, Fredrik Johansson and Bordeaux, Inria},
	file = {Lfant en Bordeaux - Numerical integration in complex interval arithmet.pdf:C\:\\Users\\Admin\\Zotero\\storage\\WGXY3GTI\\Lfant en Bordeaux - Numerical integration in complex interval arithmet.pdf:application/pdf},
}

@misc{crespo_primary-space_2020,
	title = {Primary-{Space} {Adaptive} {Control} {Variates} using {Piecewise}-{Polynomial} {Approximations}},
	url = {http://arxiv.org/abs/2008.06722},
	abstract = {We present an unbiased numerical integration algorithm that handles both low-frequency regions and high frequency details of multidimensional integrals. It combines quadrature and Monte Carlo integration, by using a quadrature-base approximation as a control variate of the signal. We adaptively build the control variate constructed as a piecewise polynomial, which can be analytically integrated, and accurately reconstructs the low frequency regions of the integrand. We then recover the high-frequency details missed by the control variate by using Monte Carlo integration of the residual. Our work leverages importance sampling techniques by working in primary space, allowing the combination of multiple mappings; this enables multiple importance sampling in quadrature-based integration. Our algorithm is generic, and can be applied to any complex multidimensional integral. We demonstrate its effectiveness with four applications with low dimensionality: transmittance estimation in heterogeneous participating media, low-order scattering in homogeneous media, direct illumination computation, and rendering of distributed effects. Finally, we show how our technique is extensible to integrands of higher dimensionality, by computing the control variate on Monte Carlo estimates of the high-dimensional signal, and accounting for such additional dimensionality on the residual as well. In all cases, we show accurate results and faster convergence compared to previous approaches.},
	language = {en},
	urldate = {2023-02-10},
	publisher = {arXiv},
	author = {Crespo, Miguel and Bernal, Felix and Jarabo, Adrian and Muñoz, Adolfo},
	month = aug,
	year = {2020},
	note = {arXiv:2008.06722 [cs]},
	keywords = {Computer Science - Graphics},
	annote = {Comment: 14 pages, 18 figures},
	file = {Crespo e.a. - 2020 - Primary-Space Adaptive Control Variates using Piec.pdf:C\:\\Users\\Admin\\Zotero\\storage\\UYAUD2N9\\Crespo e.a. - 2020 - Primary-Space Adaptive Control Variates using Piec.pdf:application/pdf},
}

@inproceedings{west_marginal_2022,
	address = {Daegu Republic of Korea},
	title = {Marginal {Multiple} {Importance} {Sampling}},
	isbn = {978-1-4503-9470-3},
	url = {https://dl.acm.org/doi/10.1145/3550469.3555388},
	doi = {10.1145/3550469.3555388},
	abstract = {Multiple importance sampling (MIS) is a powerful tool to combine different sampling techniques in a provably good manner. MIS requires that the techniques’ probability density functions (PDFs) are readily evaluable point-wise. However, this requirement may not be satisfied when (some of) those PDFs are marginals, i.e., integrals of other PDFs. We generalize MIS to combine samples from such marginal PDFs. The key idea is to consider each marginalization domain as a continuous space of sampling techniques with readily evaluable (conditional) PDFs. We stochastically select techniques from these spaces and combine the samples drawn from them into an unbiased estimator. Prior work has dealt with the special cases of multiple classical techniques or a single marginal one. Our formulation can handle mixtures of those. We apply our marginal MIS formulation to light-transport simulation to demonstrate its utility. We devise a marginal path sampling framework that makes previously intractable sampling techniques practical and significantly broadens the path-sampling choices beyond what is presently possible. We highlight results from two algorithms based on marginal MIS: a novel formulation of path-space filtering at multiple vertices along a camera path and a similar filtering method for photon-density estimation. CCS Concepts: • Computing methodologies → Rendering; Ray tracing.},
	language = {en},
	urldate = {2023-02-10},
	booktitle = {{SIGGRAPH} {Asia} 2022 {Conference} {Papers}},
	publisher = {ACM},
	author = {West, Rex and Georgiev, Iliyan and Hachisuka, Toshiya},
	month = nov,
	year = {2022},
	pages = {1--8},
	file = {West e.a. - 2022 - Marginal Multiple Importance Sampling.pdf:C\:\\Users\\Admin\\Zotero\\storage\\HGCCANTP\\West e.a. - 2022 - Marginal Multiple Importance Sampling.pdf:application/pdf},
}

@misc{he_adaptive_2021,
	title = {Adaptive {Importance} {Sampling} for {Efficient} {Stochastic} {Root} {Finding} and {Quantile} {Estimation}},
	url = {http://arxiv.org/abs/2102.10631},
	abstract = {In solving simulation-based stochastic root-ﬁnding or optimization problems that involve rare events, such as in extreme quantile estimation, running crude Monte Carlo can be prohibitively ineﬃcient. To address this issue, importance sampling can be employed to drive down the sampling error to a desirable level. However, selecting a good importance sampler requires knowledge of the solution to the problem at hand, which is the goal to begin with and thus forms a circular challenge. We investigate the use of adaptive importance sampling to untie this circularity. Our procedure sequentially updates the importance sampler to reach the optimal sampler and the optimal solution simultaneously, and can be embedded in both sample average approximation and stochastic approximation-type algorithms. Our theoretical analysis establishes strong consistency and asymptotic normality of the resulting estimators. We also demonstrate, via a minimax perspective, the key role of using adaptivity in controlling asymptotic errors. Finally, we illustrate the eﬀectiveness of our approach via numerical experiments.},
	language = {en},
	urldate = {2023-02-10},
	publisher = {arXiv},
	author = {He, Shengyi and Jiang, Guangxin and Lam, Henry and Fu, Michael C.},
	month = feb,
	year = {2021},
	note = {arXiv:2102.10631 [math, stat]},
	keywords = {Mathematics - Probability, Statistics - Methodology, Mathematics - Optimization and Control},
	file = {He e.a. - 2021 - Adaptive Importance Sampling for Efficient Stochas.pdf:C\:\\Users\\Admin\\Zotero\\storage\\AJ5J334J\\He e.a. - 2021 - Adaptive Importance Sampling for Efficient Stochas.pdf:application/pdf},
}

@article{west_continuous_2020,
	title = {Continuous multiple importance sampling},
	volume = {39},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/3386569.3392436},
	doi = {10.1145/3386569.3392436},
	abstract = {Multiple importance sampling (MIS) is a provably good way to combine a finite set of sampling techniques to reduce variance in Monte Carlo integral estimation. However, there exist integration problems for which a continuum of sampling techniques is available. To handle such cases we establish a continuous MIS (CMIS) formulation as a generalization of MIS to uncountably infinite sets of techniques. Our formulation is equipped with a base estimator that is coupled with a provably optimal balance heuristic and a practical stochastic MIS (SMIS) estimator that makes CMIS accessible to a broad range of problems. To illustrate the effectiveness and utility of our framework, we apply it to three different light transport applications, showing improved performance over the prior state-of-the-art techniques.},
	language = {en},
	number = {4},
	urldate = {2023-02-10},
	journal = {ACM Transactions on Graphics},
	author = {West, Rex and Georgiev, Iliyan and Gruson, Adrien and Hachisuka, Toshiya},
	month = aug,
	year = {2020},
	file = {West e.a. - 2020 - Continuous multiple importance sampling.pdf:C\:\\Users\\Admin\\Zotero\\storage\\T968PF33\\West e.a. - 2020 - Continuous multiple importance sampling.pdf:application/pdf},
}

@article{rath_ears_2022,
	title = {{EARS}: efficiency-aware russian roulette and splitting},
	volume = {41},
	issn = {0730-0301, 1557-7368},
	shorttitle = {{EARS}},
	url = {https://dl.acm.org/doi/10.1145/3528223.3530168},
	doi = {10.1145/3528223.3530168},
	abstract = {Russian roulette and splitting are widely used techniques to increase the efficiency of Monte Carlo estimators. But, despite their popularity, there is little work on how to best apply them. Most existing approaches rely on simple heuristics based on, e.g., surface albedo and roughness. Their efficiency often hinges on user-controlled parameters. We instead iteratively learn optimal Russian roulette and splitting factors during rendering, using a simple and lightweight data structure. Given perfect estimates of variance and cost, our fixed-point iteration provably converges to the optimal Russian roulette and splitting factors that maximize the rendering efficiency. In our application to unidirectional path tracing, we achieve consistent and significant speed-ups over the state of the art.},
	language = {en},
	number = {4},
	urldate = {2023-02-10},
	journal = {ACM Transactions on Graphics},
	author = {Rath, Alexander and Grittmann, Pascal and Herholz, Sebastian and Weier, Philippe and Slusallek, Philipp},
	month = jul,
	year = {2022},
	pages = {1--14},
	annote = {has a youtube video
},
	file = {Rath e.a. - 2022 - EARS efficiency-aware russian roulette and splitt.pdf:C\:\\Users\\Admin\\Zotero\\storage\\SX8TXAMP\\Rath e.a. - 2022 - EARS efficiency-aware russian roulette and splitt.pdf:application/pdf},
}

@article{barnett_greens_nodate,
	title = {Greens {Functions} for the {Wave} {Equation}},
	abstract = {I gather together known results on fundamental solutions to the wave equation in free space, and Greens functions in tori, boxes, and other domains. From this the corresponding fundamental solutions for the Helmholtz equation are derived, and, for the 2D case the semiclassical approximation interpreted back in the time-domain. Utility: scarring via time-dependent propagation in cavities; Math 46 course ideas.},
	language = {en},
	author = {Barnett, Alex H},
	file = {Barnett - Greens Functions for the Wave Equation.pdf:C\:\\Users\\Admin\\Zotero\\storage\\P38YMD3D\\Barnett - Greens Functions for the Wave Equation.pdf:application/pdf},
}

@article{chatterjee_monte_nodate,
	title = {A {Monte} {Carlo} {Algorithm} for the {Solution} of the {One}-{Dimensional} {Wave} {Equation}},
	abstract = {This paper presents a 1D Monte Carlo (MC) algorithm for the solution of the wave equation. Historically, the MC method has not been applied successfully to the solution of wave problems. This can primarily be attributed to the problem of resonance in the frequency-domain Green’s function for finite geometries at length scales greater than half a wavelength. In our previously published work, we have been successful in obtaining a frequency-domain solution at multiple-wavelength length scales through the use of infinite-domain Green’s functions. In this work, we extend the algorithm to problems in the time-domain. The MC method does not require any discretization, and hence the memory requirements are lower than approaches based on discretization. Another advantage of the MC method is that the computational procedure is inherently parallelizable and an almost linear increase in computational speed can be obtained with an increase in the number of processors. The application area of our interest is in the full-wave analysis of IC interconnect structures at multi-GHz frequencies.},
	language = {en},
	author = {Chatterjee, K and Yu, C},
	file = {Chatterjee en Yu - A Monte Carlo Algorithm for the Solution of the On.pdf:C\:\\Users\\Admin\\Zotero\\storage\\Z59LHDC5\\Chatterjee en Yu - A Monte Carlo Algorithm for the Solution of the On.pdf:application/pdf},
}

@misc{noauthor_finite_nodate,
	title = {{FINITE} {DIFFERENCE} {AND} {SPECTRAL} {METHODS} {FOR} {ORDINARY} {AND} {PARTIAL} {DIFFERENTIAL} {EQUATIONS}},
	url = {https://www.math.hmc.edu/~dyong/math165/trefethenbook.pdf},
	urldate = {2023-02-08},
	file = {trefethenbook.pdf:C\:\\Users\\Admin\\Zotero\\storage\\GEQEN89I\\trefethenbook.pdf:application/pdf},
}

@article{e_multilevel_2019,
	title = {On multilevel {Picard} numerical approximations for high-dimensional nonlinear parabolic partial differential equations and high-dimensional nonlinear backward stochastic differential equations},
	volume = {79},
	issn = {0885-7474, 1573-7691},
	url = {http://arxiv.org/abs/1708.03223},
	doi = {10.1007/s10915-018-00903-0},
	abstract = {Parabolic partial diﬀerential equations (PDEs) and backward stochastic diﬀerential equations (BSDEs) are key ingredients in a number of models in physics and ﬁnancial engineering. In particular, parabolic PDEs and BSDEs are fundamental tools in the state-of-the-art pricing and hedging of ﬁnancial derivatives. The PDEs and BSDEs appearing in such applications are often high-dimensional and nonlinear. Since explicit solutions of such PDEs and BSDEs are typically not available, it is a very active topic of research to solve such PDEs and BSDEs approximately. In the recent article [E, W., Hutzenthaler, M., Jentzen, A., \& Kruse, T. Linear scaling algorithms for solving high-dimensional nonlinear parabolic diﬀerential equations. arXiv:1607.03295 (2017)] we proposed a family of approximation methods based on Picard approximations and multilevel Monte Carlo methods and showed under suitable regularity assumptions on the exact solution for semilinear heat equations that the computational complexity is bounded by O(d ε−(4+δ)) for any δ ∈ (0, ∞), where d is the dimensionality of the problem and ε ∈ (0, ∞) is the prescribed accuracy. In this paper, we test the applicability of this algorithm on a variety of 100-dimensional nonlinear PDEs that arise in physics and ﬁnance by means of numerical simulations presenting approximation accuracy against runtime. The simulation results for these 100-dimensional example PDEs are very satisfactory in terms of accuracy and speed. In addition, we also provide a review of other approximation methods for nonlinear PDEs and BSDEs from the literature.},
	language = {en},
	number = {3},
	urldate = {2023-02-02},
	journal = {Journal of Scientific Computing},
	author = {E, Weinan and Hutzenthaler, Martin and Jentzen, Arnulf and Kruse, Thomas},
	month = jun,
	year = {2019},
	note = {arXiv:1708.03223 [math]},
	keywords = {Mathematics - Numerical Analysis},
	pages = {1534--1571},
	file = {E e.a. - 2019 - On multilevel Picard numerical approximations for .pdf:C\:\\Users\\Admin\\Zotero\\storage\\DRCCMHJB\\E e.a. - 2019 - On multilevel Picard numerical approximations for .pdf:application/pdf},
}

@misc{noauthor_spectral_2023,
	title = {Spectral density estimation},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Spectral_density_estimation&oldid=1136326946},
	abstract = {In statistical signal processing, the goal of spectral density estimation (SDE) or simply spectral estimation  is to estimate the spectral density (also known as the power spectral density) of a signal from a sequence of time samples of the signal. Intuitively speaking, the spectral density characterizes the frequency content of the signal. One purpose of estimating the spectral density is to detect any periodicities in the data, by observing peaks at the frequencies corresponding to these periodicities.
Some SDE techniques assume that a signal is composed of a limited (usually small) number of generating frequencies plus noise and seek to find the location and intensity of the generated frequencies.  Others make no assumption on the number of components and seek to estimate the whole generating spectrum.},
	language = {en},
	urldate = {2023-02-02},
	journal = {Wikipedia},
	month = jan,
	year = {2023},
	note = {Page Version ID: 1136326946},
}

@misc{noauthor_fredholm_nodate,
	title = {fredholm theory of elliptic problems},
	file = {[Monographs in Mathematics №101] Vitaly Volpert (auth.) - Elliptic Partial Differential Equations_ Volume 1_ Fredholm Theory of Elliptic Problems in Unbounded Domains (2011, Birkhäuser) [10.1007_978-3-0346-0537-3] - libge.pdf:C\:\\Users\\Admin\\Zotero\\storage\\78DYTQZ7\\[Monographs in Mathematics №101] Vitaly Volpert (auth.) - Elliptic Partial Differential Equations_ Volume 1_ Fredholm Theory of Elliptic Problems in Unbounded Domains (2011, Birkhäuser) [10.1007_978-3-0346-0.pdf:application/pdf},
}

@article{almousa_cme_2022,
	title = {The {CME} method: {Efficient} numerical inverse {Laplace} transformation with {Concentrated} {Matrix} {Exponential} distribution},
	volume = {49},
	issn = {0163-5999},
	shorttitle = {The {CME} method},
	url = {https://dl.acm.org/doi/10.1145/3543146.3543155},
	doi = {10.1145/3543146.3543155},
	abstract = {Numerical inverse Laplace transformation (NILT) is an important tool in the ﬁeld of system modelling and performance analysis. The recently introduced CME method has many important advantages over the alternative numerical inverse Laplace transformation (NILT) methods. It avoids Gibbs oscillation (i.e., does not generate overshoot and undershoot), preserves the monotonicity of functions, its accuracy is gradually improving with the order, and it is numerically more stable than the alternative methods. In this paper we demonstrate these advantages and introduce our tool which implements the CME method and other popular NILT methods.},
	language = {en},
	number = {4},
	urldate = {2023-02-02},
	journal = {ACM SIGMETRICS Performance Evaluation Review},
	author = {Almousa, Salah Al-Deen and Horv´ath, G´abor and Horv´ath, Ill ´es and M´esz´aros, Andr´as and Telek, Mikl ´os},
	month = jun,
	year = {2022},
	pages = {29--34},
	file = {Almousa e.a. - 2022 - The CME method Efficient numerical inverse Laplac.pdf:C\:\\Users\\Admin\\Zotero\\storage\\BXPJ7LAI\\Almousa e.a. - 2022 - The CME method Efficient numerical inverse Laplac.pdf:application/pdf},
}

@article{zergainoh_construction_2007,
	title = {Construction of {Orthonormal} {Piecewise} {Polynomial} {Scaling} and {Wavelet} {Bases} on {Non}-{Equally} {Spaced} {Knots}},
	volume = {2007},
	issn = {1687-6180},
	url = {https://asp-eurasipjournals.springeropen.com/articles/10.1155/2007/27427},
	doi = {10.1155/2007/27427},
	language = {en},
	number = {1},
	urldate = {2023-02-01},
	journal = {EURASIP Journal on Advances in Signal Processing},
	author = {Zergaïnoh, Anissa and Chihab, Najat and Astruc, Jean Pierre},
	month = dec,
	year = {2007},
	pages = {027427},
	file = {Zergaïnoh e.a. - 2007 - Construction of Orthonormal Piecewise Polynomial S.pdf:C\:\\Users\\Admin\\Zotero\\storage\\AALIDUH4\\Zergaïnoh e.a. - 2007 - Construction of Orthonormal Piecewise Polynomial S.pdf:application/pdf},
}

@article{yuan_overview_2019,
	title = {An overview of numerical methods for the first kind {Fredholm} integral equation},
	volume = {1},
	issn = {2523-3963, 2523-3971},
	url = {http://link.springer.com/10.1007/s42452-019-1228-3},
	doi = {10.1007/s42452-019-1228-3},
	abstract = {In the field of engineering technology, many problems can be transformed into the first kind Fredholm integral equation, which has a prominent feature called “ill-posedness”. This property makes it difficult to find the analytical solution of first kind Fredholm integral equation. Therefore, how to find the numerical solution of first kind Fredholm integral equation has been a common concern of domestic and overseas scholars in recent years. In this article, various numerical solution methods of first kind Fredholm integral equation are introduced in detail. First, the existence and convergence of the solution of the integral equation are given. Second, the current mainstream numerical methods, such as regularization method, wavelet analysis method and multilevel iteration method are introduced in detail. Finally, we presented a concise overview of the numerical method of first kind Fredholm integral equation.},
	language = {en},
	number = {10},
	urldate = {2023-02-01},
	journal = {SN Applied Sciences},
	author = {Yuan, Di and Zhang, Xinming},
	month = oct,
	year = {2019},
	pages = {1178},
	file = {Yuan en Zhang - 2019 - An overview of numerical methods for the first kin.pdf:C\:\\Users\\Admin\\Zotero\\storage\\FTSQCFRP\\Yuan en Zhang - 2019 - An overview of numerical methods for the first kin.pdf:application/pdf},
}

@misc{noauthor_augmented_2022,
	title = {Augmented {Lagrangian} method},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Augmented_Lagrangian_method&oldid=1130093461#Alternating_direction_method_of_multipliers},
	abstract = {Augmented Lagrangian methods are a certain class of algorithms for solving constrained optimization problems.  They have similarities to penalty methods in that they replace a constrained optimization problem by a series of unconstrained problems and add a penalty term to the objective; the difference is that the augmented Lagrangian method adds yet another term, designed to mimic a Lagrange multiplier.  The augmented Lagrangian is related to, but not identical with the method of Lagrange multipliers.
Viewed differently, the unconstrained objective is the Lagrangian of the constrained problem, with an additional penalty term (the augmentation).
The method was originally known as the method of multipliers, and was studied much in the 1970 and 1980s as a good alternative to penalty methods. It was first discussed by Magnus Hestenes, and by Michael Powell in 1969. The method was studied by R. Tyrrell Rockafellar in relation to Fenchel duality, particularly in relation to proximal-point methods, Moreau–Yosida regularization, and maximal monotone operators: These methods were used in structural optimization.  The method was also studied by Dimitri Bertsekas, notably in his 1982 book, together with extensions involving nonquadratic regularization functions, such as entropic regularization, which gives rise to the "exponential method of multipliers," a method that handles inequality constraints with a twice differentiable augmented Lagrangian function.
Since the 1970s, sequential quadratic programming (SQP) and interior point methods (IPM) have had increasing attention, in part because they more easily use sparse matrix subroutines from numerical software libraries, and in part because IPMs have proven complexity results via the theory of self-concordant functions. The augmented Lagrangian method was rejuvenated by the optimization systems LANCELOT, ALGENCAN and AMPL, which allowed sparse matrix techniques to be used on seemingly dense but "partially separable" problems. The method is still useful for some problems.
Around 2007, there was a resurgence of augmented Lagrangian methods in fields such as total-variation denoising and compressed sensing. In particular, a variant of the standard augmented Lagrangian method that uses partial updates (similar to the Gauss–Seidel method for solving linear equations) known as the alternating direction method of multipliers or ADMM gained some attention.},
	language = {en},
	urldate = {2023-02-01},
	journal = {Wikipedia},
	month = dec,
	year = {2022},
	note = {Page Version ID: 1130093461},
}

@misc{noauthor_stochastic_2023,
	title = {Stochastic gradient descent},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Stochastic_gradient_descent&oldid=1136419553},
	abstract = {Stochastic gradient descent (often abbreviated SGD) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Especially in high-dimensional optimization problems this reduces the very high computational burden, achieving faster iterations in exchange for a lower convergence rate.While the basic idea behind stochastic approximation can be traced back to the Robbins–Monro algorithm of the 1950s, stochastic gradient descent has become an important optimization method in machine learning.},
	language = {en},
	urldate = {2023-02-01},
	journal = {Wikipedia},
	month = jan,
	year = {2023},
	note = {Page Version ID: 1136419553},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\C8B3CMLS\\Stochastic_gradient_descent.html:text/html},
}

@misc{dumas_fast_2016,
	title = {Fast {Matrix} {Multiplication} and {Symbolic} {Computation}},
	url = {http://arxiv.org/abs/1612.05766},
	abstract = {The complexity of matrix multiplication (hereafter MM) has been intensively studied since 1969, when Strassen surprisingly decreased the exponent 3 in the cubic cost of the straightforward classical MM to log2(7) ≈ 2.8074. Applications to some fundamental problems of Linear Algebra and Computer Science have been immediately recognized, but the researchers in Computer Algebra keep discovering more and more applications even today, with no sign of slowdown. We survey the unﬁnished history of decreasing the exponent towards its information lower bound 2, recall some important techniques discovered in this process and linked to other ﬁelds of computing, reveal sample surprising applications to fast computation of the inner products of two vectors and summation of integers, and discuss the curse of recursion, which separates the progress in fast MM into its most acclaimed and purely theoretical part and into valuable acceleration of MM of feasible sizes. Then, in the second part of our paper, we cover fast MM in realistic symbolic computations and discuss applications and implementation of fast exact matrix multiplication. We ﬁrst review how most of exact linear algebra can be reduced to matrix multiplication over small ﬁnite ﬁelds. Then we highlight the diﬀerences in the design of approximate and exact implementations of fast MM, taking into account nowadays processor and memory hierarchies. In the concluding section we comment on current perspectives of the study of fast MM.},
	language = {en},
	urldate = {2023-02-01},
	publisher = {arXiv},
	author = {Dumas, Jean-Guillaume and Pan, Victor},
	month = dec,
	year = {2016},
	note = {arXiv:1612.05766 [cs]},
	keywords = {Computer Science - Symbolic Computation},
	file = {Dumas en Pan - 2016 - Fast Matrix Multiplication and Symbolic Computatio.pdf:C\:\\Users\\Admin\\Zotero\\storage\\SJLTRMVL\\Dumas en Pan - 2016 - Fast Matrix Multiplication and Symbolic Computatio.pdf:application/pdf},
}

@misc{pan_fast_2022,
	title = {Fast {Approximation} of {Polynomial} {Zeros} and {Matrix} {Eigenvalues}},
	url = {http://arxiv.org/abs/2301.11268},
	abstract = {Given a black box (oracle) for the evaluation of a univariate polynomial p(x) of a degree d, we seek its zeros, that is, the roots of the equation p(x)=0. At FOCS 2016 Louis and Vempala approximated a largest zero of such a real-rooted polynomial within \$1/2{\textasciicircum}b\$, by performing at NR cost of the evaluation of Newton's ratio p(x)/p'(x) at O(b{\textbackslash}log(d)) points x. They readily extended this root-finder to record fast approximation of a largest eigenvalue of a symmetric matrix under the Boolean complexity model. We apply distinct approach and techniques to obtain more general results at the same computational cost.},
	language = {en},
	urldate = {2023-02-01},
	publisher = {arXiv},
	author = {Pan, Victor Y. and Go, Soo and Luan, Qi and Zhao, Liang},
	month = dec,
	year = {2022},
	note = {arXiv:2301.11268 [cs, math]},
	keywords = {Mathematics - Numerical Analysis, Computer Science - Symbolic Computation},
	annote = {Comment: 19 pages, 5 figures},
	file = {Pan e.a. - 2022 - Fast Approximation of Polynomial Zeros and Matrix .pdf:C\:\\Users\\Admin\\Zotero\\storage\\WNNTR8QA\\Pan e.a. - 2022 - Fast Approximation of Polynomial Zeros and Matrix .pdf:application/pdf},
}

@misc{pedro_answer_2012,
	title = {Answer to "{Fast} (approximate) evaluation of {Chebyshev} polynomial"},
	url = {https://scicomp.stackexchange.com/a/3416},
	urldate = {2023-01-31},
	journal = {Computational Science Stack Exchange},
	author = {Pedro},
	month = oct,
	year = {2012},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\FX7IQLE7\\fast-approximate-evaluation-of-chebyshev-polynomial.html:text/html},
}

@misc{kirill_answer_2017,
	title = {Answer to "{Clenshaw}-type recurrence for derivative of {Chebyshev} series"},
	url = {https://scicomp.stackexchange.com/a/27866},
	urldate = {2023-01-31},
	journal = {Computational Science Stack Exchange},
	author = {Kirill},
	month = sep,
	year = {2017},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\PMJIJDW5\\clenshaw-type-recurrence-for-derivative-of-chebyshev-series.html:text/html},
}

@misc{noauthor_clenshaw_2022,
	title = {Clenshaw algorithm},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Clenshaw_algorithm&oldid=1089015914},
	abstract = {In numerical analysis, the Clenshaw algorithm, also called Clenshaw summation, is a recursive method to evaluate a linear combination of Chebyshev polynomials.  The method was published by Charles William Clenshaw in 1955. It is a generalization of Horner's method for evaluating a linear combination of monomials.
It generalizes to more than just Chebyshev polynomials; it applies to any class of functions that can be defined by a three-term recurrence relation.},
	language = {en},
	urldate = {2023-01-31},
	journal = {Wikipedia},
	month = may,
	year = {2022},
	note = {Page Version ID: 1089015914},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\HTUIQKE9\\Clenshaw_algorithm.html:text/html},
}

@article{sajikumar_image_nodate,
	title = {{IMAGE} {COMPRESSION} {USING} {CHEBYSHEV} {POLYNOMIAL} {SURFACE} {FIT}},
	abstract = {A lossy image compression method based on block-by-block surface fit using bivariate polynomial is proposed. Chebyshev polynomials of first kind are used to generate the surface for each block. Data compression is achieved by representing the gray level variations across any block by the parameters of the fitted surface and these parameters are stored instead of the pixel values. Compression with three coefficients and four coefficients in the fit model is proposed. In standard lossy compression techniques compression is achieved by exploiting spatial redundancies of the input data. In this proposed method compression does not depends on redundant information but depends on the block size that can be predefined. The method is best suited for high compression with reasonable reconstructed image quality. Performance was tested on number of test images using Chebyshev polynomials of different orders.},
	language = {en},
	author = {Sajikumar, S},
	file = {Sajikumar - IMAGE COMPRESSION USING CHEBYSHEV POLYNOMIAL SURFA.pdf:C\:\\Users\\Admin\\Zotero\\storage\\Z7XR22R5\\Sajikumar - IMAGE COMPRESSION USING CHEBYSHEV POLYNOMIAL SURFA.pdf:application/pdf},
}

@article{rivaz_two-dimensional_2015,
	title = {Two-dimensional {Chebyshev} {Polynomials} for {Solving} {Two}-dimensional {Integro}-{Differential} {Equations}},
	abstract = {In this paper, we present a new approach to obtain the numerical solution of the linear twodimensional Fredholm and Volterra integro-differential equations (2D-FIDE and 2D-VIDE). First, we introduce the two-dimensional Chebyshev polynomials and construct their operational matrices of integration. Then, both of them, two-dimensional Chebyshev polynomials and their operational matrix of integration, are used to represent the matrix form of 2D-FIDE and 2D-VIDE. The main characteristic of this approach is that it reduces 2D-FIDE and 2D-VIDE to a system of linear algebraic equations. Illustrative examples are included to demonstrate the validity and applicability of the presented technique.},
	language = {en},
	number = {2},
	author = {Rivaz, Azim},
	year = {2015},
	file = {Rivaz - 2015 - Two-dimensional Chebyshev Polynomials for Solving .pdf:C\:\\Users\\Admin\\Zotero\\storage\\SPZJSJ2L\\Rivaz - 2015 - Two-dimensional Chebyshev Polynomials for Solving .pdf:application/pdf},
}

@article{townsend_extension_2013,
	title = {An {Extension} of {Chebfun} to {Two} {Dimensions}},
	volume = {35},
	issn = {1064-8275, 1095-7197},
	url = {http://epubs.siam.org/doi/10.1137/130908002},
	doi = {10.1137/130908002},
	abstract = {An object-oriented Matlab system is described that extends the capabilities of Chebfun to smooth functions of two variables deﬁned on rectangles. Functions are approximated to essentially machine precision by using iterative Gaussian elimination with complete pivoting to form “chebfun2” objects representing low rank approximations. Operations such as integration, diﬀerentiation, function evaluation, and transforms are particularly eﬃcient. Global optimization, the singular value decomposition, and rootﬁnding are also extended to chebfun2 objects. Numerical applications are presented.},
	language = {en},
	number = {6},
	urldate = {2023-01-31},
	journal = {SIAM Journal on Scientific Computing},
	author = {Townsend, Alex and Trefethen, Lloyd N.},
	month = jan,
	year = {2013},
	pages = {C495--C518},
	file = {Townsend en Trefethen - 2013 - An Extension of Chebfun to Two Dimensions.pdf:C\:\\Users\\Admin\\Zotero\\storage\\X7345UNU\\Townsend en Trefethen - 2013 - An Extension of Chebfun to Two Dimensions.pdf:application/pdf},
}

@misc{noauthor_continuous_nodate,
	title = {Continuous analogues of matrix factorizations},
	url = {https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.2014.0585},
	language = {en},
	urldate = {2023-01-31},
	doi = {10.1098/rspa.2014.0585},
	file = {Volledige Tekst:C\:\\Users\\Admin\\Zotero\\storage\\24VM589B\\Continuous analogues of matrix factorizations.pdf:application/pdf},
}

@article{wright_extension_2015,
	title = {Extension of {Chebfun} to periodic functions},
	volume = {37},
	issn = {1064-8275, 1095-7197},
	url = {http://arxiv.org/abs/1511.00166},
	doi = {10.1137/141001007},
	abstract = {Algorithms and underlying mathematics are presented for numerical computation with periodic functions via approximations to machine precision by trigonometric polynomials, including the solution of linear and nonlinear periodic ordinary diﬀerential equations. Diﬀerences from the nonperiodic Chebyshev case are highlighted.},
	language = {en},
	number = {5},
	urldate = {2023-01-31},
	journal = {SIAM Journal on Scientific Computing},
	author = {Wright, Grady B. and Javed, Mohsin and Montanelli, Hadrien and Trefethen, Lloyd N.},
	month = jan,
	year = {2015},
	note = {arXiv:1511.00166 [math]},
	keywords = {Mathematics - Numerical Analysis, 42A10, 42A15, 65T40},
	pages = {C554--C573},
	annote = {Comment: 20 pages},
	file = {Wright e.a. - 2015 - Extension of Chebfun to periodic functions.pdf:C\:\\Users\\Admin\\Zotero\\storage\\UEQFA5S5\\Wright e.a. - 2015 - Extension of Chebfun to periodic functions.pdf:application/pdf},
}

@misc{aurentz_chopping_2015,
	title = {Chopping a {Chebyshev} {Series}},
	url = {http://arxiv.org/abs/1512.01803},
	abstract = {Chebfun and related software projects for numerical computing with functions are based on the idea that at each step of a computation, a function f (x) deﬁned on an interval [a, b] is “rounded” to a prescribed precision by constructing a Chebyshev series and chopping it at an appropriate point. Designing a chopping algorithm with the right properties proves to be a surprisingly complex and interesting problem. We describe the chopping algorithm introduced in Chebfun Version 5.3 in 2015 after many years of discussion and the considerations that led to this design.},
	language = {en},
	urldate = {2023-01-31},
	publisher = {arXiv},
	author = {Aurentz, Jared L. and Trefethen, Lloyd N.},
	month = dec,
	year = {2015},
	note = {arXiv:1512.01803 [math]},
	keywords = {Mathematics - Numerical Analysis},
	file = {Aurentz en Trefethen - 2015 - Chopping a Chebyshev Series.pdf:C\:\\Users\\Admin\\Zotero\\storage\\Q3HLDCCX\\Aurentz en Trefethen - 2015 - Chopping a Chebyshev Series.pdf:application/pdf},
}

@misc{trefethen_multivariate_2016,
	title = {Multivariate polynomial approximation in the hypercube},
	url = {http://arxiv.org/abs/1608.02216},
	abstract = {A theorem is proved concerning approximation of analytic functions by multivariate polynomials in the s-dimensional hypercube. The geometric convergence rate is determined not by the usual notion of degree of a multivariate polynomial, but by the Euclidean degree, deﬁned in terms of the 2-norm rather than the 1-norm of the exponent vector k of a monomial xk11 · · · xkss .},
	language = {en},
	urldate = {2023-01-31},
	publisher = {arXiv},
	author = {Trefethen, Lloyd N.},
	month = aug,
	year = {2016},
	note = {arXiv:1608.02216 [math]},
	keywords = {Mathematics - Numerical Analysis, 41A63},
	file = {Trefethen - 2016 - Multivariate polynomial approximation in the hyper.pdf:C\:\\Users\\Admin\\Zotero\\storage\\HSBRRHS8\\Trefethen - 2016 - Multivariate polynomial approximation in the hyper.pdf:application/pdf},
}

@misc{nakatsukasa_algorithm_2019,
	title = {An algorithm for real and complex rational minimax approximation},
	url = {http://arxiv.org/abs/1908.06001},
	abstract = {Rational minimax approximation of real functions on real intervals is an established topic, but when it comes to complex functions or domains, there appear to be no algorithms currently in use. Such a method is introduced here, the AAA-Lawson algorithm, available in Chebfun. The new algorithm solves a wide range of problems on arbitrary domains in a fraction of a second of laptop time by a procedure consisting of two steps. First, the standard AAA algorithm is run to obtain a near-best approximation and a set of support points for a barycentric representation of the rational approximant. Then a “Lawson phase” of iteratively reweighted least-squares adjustment of the barycentric coeﬃcients is carried out to improve the approximation to minimax.},
	language = {en},
	urldate = {2023-01-31},
	publisher = {arXiv},
	author = {Nakatsukasa, Yuji and Trefethen, Lloyd N.},
	month = aug,
	year = {2019},
	note = {arXiv:1908.06001 [cs, math]},
	keywords = {Mathematics - Numerical Analysis, 41A20, 65D15},
	file = {Nakatsukasa en Trefethen - 2019 - An algorithm for real and complex rational minimax.pdf:C\:\\Users\\Admin\\Zotero\\storage\\M6YJ3J87\\Nakatsukasa en Trefethen - 2019 - An algorithm for real and complex rational minimax.pdf:application/pdf},
}

@misc{trefethen_exactness_2021,
	title = {Exactness of quadrature formulas},
	url = {http://arxiv.org/abs/2101.09501},
	abstract = {The standard design principle for quadrature formulas is that they should be exact for integrands of a given class, such as polynomials of a ﬁxed degree. We show how this principle fails to predict the actual behavior in four cases: Newton–Cotes, Clenshaw–Curtis, Gauss–Legendre, and Gauss–Hermite quadrature. Three further examples are mentioned more brieﬂy.},
	language = {en},
	urldate = {2023-01-31},
	publisher = {arXiv},
	author = {Trefethen, Lloyd N.},
	month = jan,
	year = {2021},
	note = {arXiv:2101.09501 [cs, math]},
	keywords = {Mathematics - Numerical Analysis, 41A55, 65D32},
	file = {Trefethen - 2021 - Exactness of quadrature formulas.pdf:C\:\\Users\\Admin\\Zotero\\storage\\UVIPUHJ5\\Trefethen - 2021 - Exactness of quadrature formulas.pdf:application/pdf},
}

@misc{hashemi_rectangular_2021,
	title = {Rectangular eigenvalue problems},
	url = {http://arxiv.org/abs/2112.13698},
	abstract = {Often the easiest way to discretize an ordinary or partial diﬀerential equation is by a rectangular numerical method, in which n basis functions are sampled at m ≫ n collocation points. We show how eigenvalue problems can be solved in this setting by QR reduction to square matrix generalized eigenvalue problems. The method applies equally in the limit “m = ∞” of eigenvalue problems for quasimatrices. Numerical examples are presented as well as pointers to some related literature.},
	language = {en},
	urldate = {2023-01-31},
	publisher = {arXiv},
	author = {Hashemi, Behnam and Nakatsukasa, Yuji and Trefethen, Lloyd N.},
	month = dec,
	year = {2021},
	note = {arXiv:2112.13698 [cs, math]},
	keywords = {Mathematics - Numerical Analysis, 47A75, 65F15, 65N35},
	file = {Hashemi e.a. - 2021 - Rectangular eigenvalue problems.pdf:C\:\\Users\\Admin\\Zotero\\storage\\MWM8W82T\\Hashemi e.a. - 2021 - Rectangular eigenvalue problems.pdf:application/pdf},
}

@article{christara_option_nodate,
	title = {Option pricing in jump diffusion models with quadratic spline collocation},
	abstract = {In this paper, we develop a robust numerical method in pricing options, when the underlying asset follows a jump diffusion model. We demonstrate that, with the quadratic spline collocation method, the integral approximation in the pricing PIDE is intuitively simple, and comes down to the evaluation of the probabilistic moments of the jump density. When combined with a Picard iteration scheme, the pricing problem can be solved efﬁciently. We present the method and the numerical results from pricing European and American options with Merton’s and Kou’s models.},
	language = {en},
	author = {Christara, Christina C and Leung, Nat Chun-Ho},
	file = {Christara en Leung - Option pricing in jump diffusion models with quadr.pdf:C\:\\Users\\Admin\\Zotero\\storage\\Z8AA6EGL\\Christara en Leung - Option pricing in jump diffusion models with quadr.pdf:application/pdf},
}

@misc{bilokon_quasi-monte_2022,
	title = {Quasi-{Monte} {Carlo} methods for calculating derivatives sensitivities on the {GPU}},
	url = {http://arxiv.org/abs/2209.11337},
	abstract = {The calculation of option Greeks is vital for risk management. Traditional pathwise and ﬁnitedifference methods work poorly for higher-order Greeks and options with discontinuous payoff functions. The Quasi-Monte Carlo-based conditional pathwise method (QMC-CPW) for options Greeks allows the payoff function of options to be effectively smoothed, allowing for increased efﬁciency when calculating sensitivities. Also demonstrated in literature is the increased computational speed gained by applying GPUs to highly parallelisable ﬁnance problems such as calculating Greeks. We pair QMC-CPW with simulation on the GPU using the CUDA platform. We estimate the delta, vega and gamma Greeks of three exotic options: arithmetic Asian, binary Asian, and lookback. Not only are the beneﬁts of QMC-CPW shown through variance reduction factors of up to 1.0 × 1018, but the increased computational speed through usage of the GPU is shown as we achieve speedups over sequential CPU implementations of more than 200x for our most accurate method.},
	language = {en},
	urldate = {2023-01-30},
	publisher = {arXiv},
	author = {Bilokon, Paul and Kucherenko, Sergei and Williams, Casey},
	month = sep,
	year = {2022},
	note = {arXiv:2209.11337 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance},
	annote = {Comment: 26 pages, 12 figures},
	file = {Bilokon e.a. - 2022 - Quasi-Monte Carlo methods for calculating derivati.pdf:C\:\\Users\\Admin\\Zotero\\storage\\6BCIKW77\\Bilokon e.a. - 2022 - Quasi-Monte Carlo methods for calculating derivati.pdf:application/pdf},
}

@misc{maran_chebyshev_2021,
	title = {Chebyshev {Greeks}: {Smoothing} {Gamma} without {Bias}},
	shorttitle = {Chebyshev {Greeks}},
	url = {http://arxiv.org/abs/2106.12431},
	abstract = {The computation of Greeks is a fundamental task for risk managing of ﬁnancial instruments. The standard approach to their numerical evaluation is via ﬁnite diﬀerences. Most exotic derivatives are priced via Monte Carlo simulation: in these cases, it is hard to ﬁnd a fast and accurate approximation of Greeks, mainly because of the need of a tradeoﬀ between bias and variance. Recent improvements in Greeks computation, such as Adjoint Algorithmic Diﬀerentiation, are unfortunately uneﬀective on second order Greeks (such as Gamma), which are plagued by the most signiﬁcant instabilities, so that a viable alternative to standard ﬁnite diﬀerences is still lacking. We apply Chebyshev interpolation techniques to the computation of spot Greeks, showing how to improve the stability of ﬁnite diﬀerence Greeks of arbitrary order, in a simple and general way. The increased performance of the proposed technique is analyzed for a number of real payoﬀs commonly traded by ﬁnancial institutions.},
	language = {en},
	urldate = {2023-01-30},
	publisher = {arXiv},
	author = {Maran, Andrea and Pallavicini, Andrea and Scoleri, Stefano},
	month = jun,
	year = {2021},
	note = {arXiv:2106.12431 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance, Quantitative Finance - Pricing of Securities, Quantitative Finance - Mathematical Finance, Quantitative Finance - Risk Management},
	annote = {Comment: 15 pages, 4 figures},
	file = {Maran e.a. - 2021 - Chebyshev Greeks Smoothing Gamma without Bias.pdf:C\:\\Users\\Admin\\Zotero\\storage\\VH2C5Q2G\\Maran e.a. - 2021 - Chebyshev Greeks Smoothing Gamma without Bias.pdf:application/pdf},
}

@misc{lavagnini_pricing_2021,
	title = {Pricing {Asian} {Options} with {Correlators}},
	url = {http://arxiv.org/abs/2104.11684},
	abstract = {We derive a series expansion by Hermite polynomials for the price of an arithmetic Asian option. This series requires the computation of moments and correlators of the underlying price process, but for a polynomial jump-diﬀusion, these are given in closed form, hence no numerical simulation is required to evaluate the series. This allows, for example, for the explicit computation of Greeks. The weight function deﬁning the Hermite polynomials is a Gaussian density with scale b. We ﬁnd that the rate of convergence for the series depends on b, for which we prove a lower bound to guarantee convergence. Numerical examples show that the series expansion is accurate but unstable for initial values of the underlying process far from zero, mainly due to rounding errors.},
	language = {en},
	urldate = {2023-01-30},
	publisher = {arXiv},
	author = {Lavagnini, Silvia},
	month = apr,
	year = {2021},
	note = {arXiv:2104.11684 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance, Quantitative Finance - Pricing of Securities},
	file = {Lavagnini - 2021 - Pricing Asian Options with Correlators.pdf:C\:\\Users\\Admin\\Zotero\\storage\\AJNEHDQB\\Lavagnini - 2021 - Pricing Asian Options with Correlators.pdf:application/pdf},
}

@misc{noauthor_brownian_nodate,
	title = {Brownian paths and random polynomials » {Chebfun}},
	url = {https://www.chebfun.org/examples/stats/RandomPolynomials.html},
	urldate = {2023-01-30},
	file = {Brownian paths and random polynomials » Chebfun:C\:\\Users\\Admin\\Zotero\\storage\\SPBD8LDT\\RandomPolynomials.html:text/html},
}

@misc{noauthor_geometric_nodate,
	title = {Geometric {Brownian} motion » {Chebfun}},
	url = {https://www.chebfun.org/examples/ode-random/GBM.html},
	urldate = {2023-01-30},
}

@misc{noauthor_white_nodate,
	title = {The white noise paradox » {Chebfun}},
	url = {https://www.chebfun.org/examples/ode-random/WhiteNoiseParadox.html},
	urldate = {2023-01-30},
	file = {The white noise paradox » Chebfun:C\:\\Users\\Admin\\Zotero\\storage\\JEPR2VXQ\\WhiteNoiseParadox.html:text/html},
}

@misc{noauthor_integrating_nodate,
	title = {Integrating {Tj}(x)*{Tk}(y) over the unit disk » {Chebfun}},
	url = {https://www.chebfun.org/examples/quad/TjTkDisk.html},
	urldate = {2023-01-30},
	file = {Integrating Tj(x)*Tk(y) over the unit disk » Chebfun:C\:\\Users\\Admin\\Zotero\\storage\\L63WYHKI\\TjTkDisk.html:text/html},
}

@misc{noauthor_tricky_nodate,
	title = {Some tricky integrals » {Chebfun}},
	url = {https://www.chebfun.org/examples/quad/Tricky.html},
	urldate = {2023-01-30},
	file = {Some tricky integrals » Chebfun:C\:\\Users\\Admin\\Zotero\\storage\\WBGFR5FD\\Tricky.html:text/html},
}

@misc{noauthor_black-scholes_nodate,
	title = {Black-{Scholes} {PDE} using operator exponential » {Chebfun}},
	url = {https://www.chebfun.org/examples/pde/BSExponential.html},
	urldate = {2023-01-30},
	file = {Black-Scholes PDE using operator exponential » Chebfun:C\:\\Users\\Admin\\Zotero\\storage\\F23C3NDI\\BSExponential.html:text/html},
}

@misc{noauthor_constrained_nodate,
	title = {Constrained optimization in {Chebfun} » {Chebfun}},
	url = {https://www.chebfun.org/examples/opt/ConstrainedOptimization.html},
	urldate = {2023-01-30},
	file = {Constrained optimization in Chebfun » Chebfun:C\:\\Users\\Admin\\Zotero\\storage\\QIPJE4L9\\ConstrainedOptimization.html:text/html},
}

@misc{gilles_continuous_2018,
	title = {Continuous analogues of {Krylov} methods for differential operators},
	url = {http://arxiv.org/abs/1803.11049},
	abstract = {Analogues of the conjugate gradient method, MINRES, and GMRES are derived for solving boundary value problems (BVPs) involving second-order diﬀerential operators. Two challenges arise: imposing the boundary conditions on the solution while building up a Krylov subspace, and guaranteeing convergence of the Krylov-based method on unbounded operators. Our approach employs projection operators to guarantee that the boundary conditions are satisﬁed, and we develop an operator preconditioner that ensures that an approximate solution is computed after a ﬁnite number of iterations. The developed Krylov methods are practical iterative BVP solvers that are particularly eﬃcient when a fast operator-function product is available.},
	language = {en},
	urldate = {2023-01-30},
	publisher = {arXiv},
	author = {Gilles, Marc Aurèle and Townsend, Alex},
	month = apr,
	year = {2018},
	note = {arXiv:1803.11049 [math]},
	keywords = {Mathematics - Numerical Analysis, 65F10, 65N35, 47E05},
	file = {Gilles en Townsend - 2018 - Continuous analogues of Krylov methods for differe.pdf:C\:\\Users\\Admin\\Zotero\\storage\\K2ZL49ZL\\Gilles en Townsend - 2018 - Continuous analogues of Krylov methods for differe.pdf:application/pdf},
}

@misc{noauthor_continuous_nodate-1,
	title = {A continuous analogue of {Krylov} subspace methods for {ODEs} » {Chebfun}},
	url = {https://www.chebfun.org/examples/ode-linear/Krylov.html},
	urldate = {2023-01-30},
	file = {A continuous analogue of Krylov subspace methods for ODEs » Chebfun:C\:\\Users\\Admin\\Zotero\\storage\\DRV7T8ZF\\Krylov.html:text/html},
}

@article{trefethen_approximation_nodate,
	title = {Approximation {Theory} and {Approximation} {Practice}},
	language = {en},
	author = {Trefethen, Lloyd N},
	file = {Trefethen - Approximation Theory and Approximation Practice.pdf:C\:\\Users\\Admin\\Zotero\\storage\\MREQLLLP\\Trefethen - Approximation Theory and Approximation Practice.pdf:application/pdf},
}

@misc{maran_chebyshev_2021-1,
	title = {Chebyshev {Greeks}: {Smoothing} {Gamma} without {Bias}},
	shorttitle = {Chebyshev {Greeks}},
	url = {http://arxiv.org/abs/2106.12431},
	abstract = {The computation of Greeks is a fundamental task for risk managing of ﬁnancial instruments. The standard approach to their numerical evaluation is via ﬁnite diﬀerences. Most exotic derivatives are priced via Monte Carlo simulation: in these cases, it is hard to ﬁnd a fast and accurate approximation of Greeks, mainly because of the need of a tradeoﬀ between bias and variance. Recent improvements in Greeks computation, such as Adjoint Algorithmic Diﬀerentiation, are unfortunately uneﬀective on second order Greeks (such as Gamma), which are plagued by the most signiﬁcant instabilities, so that a viable alternative to standard ﬁnite diﬀerences is still lacking. We apply Chebyshev interpolation techniques to the computation of spot Greeks, showing how to improve the stability of ﬁnite diﬀerence Greeks of arbitrary order, in a simple and general way. The increased performance of the proposed technique is analyzed for a number of real payoﬀs commonly traded by ﬁnancial institutions.},
	language = {en},
	urldate = {2023-01-30},
	publisher = {arXiv},
	author = {Maran, Andrea and Pallavicini, Andrea and Scoleri, Stefano},
	month = jun,
	year = {2021},
	note = {arXiv:2106.12431 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance, Quantitative Finance - Pricing of Securities, Quantitative Finance - Mathematical Finance, Quantitative Finance - Risk Management},
	annote = {Comment: 15 pages, 4 figures},
	file = {Maran e.a. - 2021 - Chebyshev Greeks Smoothing Gamma without Bias.pdf:C\:\\Users\\Admin\\Zotero\\storage\\NAD6EA6C\\Maran e.a. - 2021 - Chebyshev Greeks Smoothing Gamma without Bias.pdf:application/pdf},
}

@article{giles_smoking_nodate,
	title = {Smoking adjoints, part {II}: fast {Monte} {Carlo} {Greeks}},
	language = {en},
	author = {Giles, Mike},
	file = {Giles - Smoking adjoints, part II fast Monte Carlo Greeks.pdf:C\:\\Users\\Admin\\Zotero\\storage\\D4MR342G\\Giles - Smoking adjoints, part II fast Monte Carlo Greeks.pdf:application/pdf},
}

@misc{hout_application_2015,
	title = {Application of {Operator} {Splitting} {Methods} in {Finance}},
	url = {http://arxiv.org/abs/1504.01022},
	abstract = {Financial derivatives pricing aims to ﬁnd the fair value of a ﬁnancial contract on an underlying asset. Here we consider option pricing in the partial differential equations framework. The contemporary models lead to one-dimensional or multidimensional parabolic problems of the convection-diffusion type and generalizations thereof. An overview of various operator splitting methods is presented for the efﬁcient numerical solution of these problems.},
	language = {en},
	urldate = {2023-01-30},
	publisher = {arXiv},
	author = {Hout, Karel in 't and Toivanen, Jari},
	month = apr,
	year = {2015},
	note = {arXiv:1504.01022 [q-fin]},
	keywords = {Quantitative Finance - Computational Finance},
	file = {Hout en Toivanen - 2015 - Application of Operator Splitting Methods in Finan.pdf:C\:\\Users\\Admin\\Zotero\\storage\\P4MV65GF\\Hout en Toivanen - 2015 - Application of Operator Splitting Methods in Finan.pdf:application/pdf},
}

@misc{noauthor_eigenfunction_2022,
	title = {Eigenfunction},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Eigenfunction&oldid=1115272845},
	abstract = {In mathematics, an eigenfunction of a linear operator D defined on some function space is any non-zero function 
  
    
      
        f
      
    
    \{{\textbackslash}displaystyle f\}
   in that space that, when acted upon by D, is only multiplied by some scaling factor called an eigenvalue. As an equation, this condition can be written as

for some scalar eigenvalue 
  
    
      
        λ
        .
      
    
    \{{\textbackslash}displaystyle {\textbackslash}lambda .\}
   The solutions to this equation may also be subject to boundary conditions that limit the allowable eigenvalues and eigenfunctions.
An eigenfunction is a type of eigenvector.},
	language = {en},
	urldate = {2023-01-30},
	journal = {Wikipedia},
	month = oct,
	year = {2022},
	note = {Page Version ID: 1115272845},
}

@article{lidebrandt_variance_nodate,
	title = {Variance {Reduction} {Three} {Approaches} to {Control} {Variates}},
	abstract = {In option price simulations, simulation-time is of great importance. Control variates is a variance reduction technique that can reduce simulation-time. Three approaches to the use of control variates in Monte Carlo option pricing are presented and evaluated. Employed methods include ordinary control variate implementation, a replicating delta hedge and re-simulation. Ordinary control variates uses a highly correlated random variable with known mean to reduce variance. The delta hedge tries to replicate the option and is constructed with an approximative delta formula, which is new to stock markets. The third method evaluated, called re-simulation, is a new method which use an earlier simulated option price as control variate. Applying an earlier option price as control variate results in a more generic method, since earlier simulated prices often exists. The three models are evaluated on Asian and Cliquet options, either in the standard Black and Scholes model or in Merton’s jump diﬀusion model. Presented results show that the re-simulation method almost always yield a more efﬁcient simulation procedure compared with the other methods. For some Cliquet options the simulation speed up over crude Monte Carlo is remarkable.},
	language = {en},
	author = {Lidebrandt, Thomas},
	file = {Lidebrandt - Variance Reduction Three Approaches to Control Var.pdf:C\:\\Users\\Admin\\Zotero\\storage\\4EHT2Z4Z\\Lidebrandt - Variance Reduction Three Approaches to Control Var.pdf:application/pdf},
}

@article{gobet_new_nodate,
	title = {A new sequential algorithm for {L2}-approximation and application to {Monte}-{Carlo} integration},
	abstract = {We design a new stochastic algorithm (called SALT) that sequentially approximates a given function in L2 w.r.t. a probability measure, using a ﬁnite sample of the distribution. By increasing the sets of approximating functions and the simulation eﬀort, we compute a L2-approximation with higher and higher accuracy. The simulation eﬀort is tuned in a robust way that ensures the convergence under rather general conditions. Then, we apply SALT to build eﬃcient control variates for accurate numerical integration. Examples and numerical experiments support the mathematical analysis.},
	language = {en},
	author = {Gobet, Emmanuel and Surana, Khushboo},
	file = {Gobet en Surana - A new sequential algorithm for L2-approximation an.pdf:C\:\\Users\\Admin\\Zotero\\storage\\MFJ99N7L\\Gobet en Surana - A new sequential algorithm for L2-approximation an.pdf:application/pdf},
}

@misc{meester_exponential_2018,
	title = {Exponential convergence of adaptive importance sampling estimators for {Markov} chain expectations},
	url = {http://arxiv.org/abs/1806.03029},
	abstract = {In this paper it is shown that adaptive importance sampling algorithms converge at exponential rate for Markov chain expectation problems that admit a combination of a ﬁltered estimator and a Markov zero-variance measure. It extends a chain of results—special purpose proofs were already known for several cases [8, 2, 6]. A recent paper [1] provides a complete description of the class of combinations of Markov process expectations of path functionals and ﬁltered estimators that admit zero-variance importance measures that retain the Markov property. In a way, this is the maximal class for which adaptive importance sampling algorithms might exhibit exponential convergence. The main purpose of this paper is to prove that this is the case: for (most of) those combinations the natural adaptive importance sampling algorithm converges at exponential rate. In addition, the applicability of general Markov chain theory for this purpose is discussed through the analysis of a counterexample presented in [7].},
	language = {en},
	urldate = {2023-01-25},
	publisher = {arXiv},
	author = {Meester, Ludolf E.},
	month = jul,
	year = {2018},
	note = {arXiv:1806.03029 [math]},
	keywords = {Mathematics - Probability},
	file = {Meester - 2018 - Exponential convergence of adaptive importance sam.pdf:C\:\\Users\\Admin\\Zotero\\storage\\8BJ5II9Q\\Meester - 2018 - Exponential convergence of adaptive importance sam.pdf:application/pdf},
}

@article{maire_new_2008,
	title = {Some new simulations schemes for the evaluation of {Feynman}–{Kac} representations},
	volume = {14},
	issn = {0929-9629, 1569-3961},
	url = {https://www.degruyter.com/document/doi/10.1515/MCMA.2008.002/html},
	doi = {10.1515/MCMA.2008.002},
	abstract = {We describe new variants of the Euler scheme and of the walk on spheres method for the Monte Carlo computation of Feynman-Kac representations. We optimize these variants using quantization for both source and boundary terms. Numerical tests are given on basic examples and on Monte Carlo versions of spectral methods for the Poisson equation. We especially introduce a new stochastic spectral formulation with very good properties in terms of conditioning.},
	language = {en},
	number = {1},
	urldate = {2023-01-25},
	journal = {Monte Carlo Methods and Applications},
	author = {Maire, Sylvain and Tanré, Etienne},
	month = jan,
	year = {2008},
	file = {Maire en Tanré - 2008 - Some new simulations schemes for the evaluation of.pdf:C\:\\Users\\Admin\\Zotero\\storage\\P47ARGF3\\Maire en Tanré - 2008 - Some new simulations schemes for the evaluation of.pdf:application/pdf},
}

@incollection{l_ecuyer_stochastic_2009,
	address = {Berlin, Heidelberg},
	title = {Stochastic {Spectral} {Formulations} for {Elliptic} {Problems}},
	isbn = {978-3-642-04106-8 978-3-642-04107-5},
	url = {http://link.springer.com/10.1007/978-3-642-04107-5_33},
	abstract = {We describe new stochastic spectral formulations with very good properties in terms of conditioning. These formulations are built by combining Monte Carlo approximations of the Feynman-Kac formula and standard deterministic approximations on basis functions. We give error bounds on the solutions obtained using these formulations in the case of linear approximations. Some numerical tests are made on an anisotropic diﬀusion equation using a tensor product Tchebychef polynomial basis and one random point schemes quantiﬁed or not.},
	language = {en},
	urldate = {2023-01-25},
	booktitle = {Monte {Carlo} and {Quasi}-{Monte} {Carlo} {Methods} 2008},
	publisher = {Springer Berlin Heidelberg},
	author = {Maire, Sylvain and Tanré, Etienne},
	editor = {L' Ecuyer, Pierre and Owen, Art B.},
	year = {2009},
	doi = {10.1007/978-3-642-04107-5_33},
	pages = {513--528},
	file = {Maire en Tanré - 2009 - Stochastic Spectral Formulations for Elliptic Prob.pdf:C\:\\Users\\Admin\\Zotero\\storage\\N6IB2UR9\\Maire en Tanré - 2009 - Stochastic Spectral Formulations for Elliptic Prob.pdf:application/pdf},
}

@misc{maire_monte_2013,
	title = {Monte {Carlo} approximations of the {Neumann} problem},
	url = {http://arxiv.org/abs/1203.4910},
	abstract = {We introduce Monte Carlo methods to compute the solution of elliptic equations with pure Neumann boundary conditions. We ﬁrst prove that the solution obtained by the stochastic representation has a zero mean value with respect to the invariant measure of the stochastic process associated to the equation. Pointwise approximations are computed by means of standard and new simulation schemes especially devised for local time approximation on the boundary of the domain. Global approximations are computed thanks to a stochastic spectral formulation taking into account the property of zero mean value of the solution. This stochastic formulation is asymptotically perfect in terms of conditioning. Numerical examples are given on the Laplace operator on a square domain with both pure Neumann and mixed Dirichlet-Neumann boundary conditions. A more general convection-diﬀusion equation is also numerically studied.},
	language = {en},
	urldate = {2023-01-25},
	publisher = {arXiv},
	author = {Maire, Sylvain and Tanré, Etienne},
	month = aug,
	year = {2013},
	note = {arXiv:1203.4910 [math]},
	keywords = {Mathematics - Probability},
	file = {Maire en Tanré - 2013 - Monte Carlo approximations of the Neumann problem.pdf:C\:\\Users\\Admin\\Zotero\\storage\\IAB5W5EV\\Maire en Tanré - 2013 - Monte Carlo approximations of the Neumann problem.pdf:application/pdf},
}

@article{gobet_spectral_2004,
	title = {A spectral {Monte} {Carlo} method for the {Poisson} equation},
	volume = {10},
	issn = {1569-3961, 0929-9629},
	url = {https://www.degruyter.com/document/doi/10.1515/mcma.2004.10.3-4.275/html},
	doi = {10.1515/mcma.2004.10.3-4.275},
	abstract = {Using a sequential Monte Carlo algorithm, we compute a spectral approximation of the solution of the Poisson equation in dimension 1 and 2. The Feyman-Kac computation of the pointwise solution is achieved using either an integral representation or a modiﬁed walk on spheres method. The variances decrease geometrically with the number of steps. A global solution is obtained, accurate up to the interpolation error. Surprisingly, the accuracy depends very little on the absorption layer thickness of the walk on spheres.},
	language = {en},
	number = {3-4},
	urldate = {2023-01-25},
	journal = {Monte Carlo Methods and Applications},
	author = {Gobet, Emmanuel and Maire, Sylvain},
	month = jan,
	year = {2004},
	file = {Gobet en Maire - 2004 - A spectral Monte Carlo method for the Poisson equa.pdf:C\:\\Users\\Admin\\Zotero\\storage\\I5NQN5MH\\Gobet en Maire - 2004 - A spectral Monte Carlo method for the Poisson equa.pdf:application/pdf},
}

@misc{noauthor_collocation_2022,
	title = {Collocation method},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Collocation_method&oldid=1101629556},
	abstract = {In mathematics, a collocation method is a method for the numerical solution of ordinary differential equations, partial differential equations and integral equations. The idea is to choose a finite-dimensional space of candidate solutions (usually polynomials up to a certain degree) and a number of points in the domain (called collocation points), and to select that solution which satisfies the given equation at the collocation points.},
	language = {en},
	urldate = {2023-01-25},
	journal = {Wikipedia},
	month = aug,
	year = {2022},
	note = {Page Version ID: 1101629556},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\GENR5CET\\Collocation_method.html:text/html},
}

@misc{noauthor_galerkin_2023,
	title = {Galerkin method},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Galerkin_method&oldid=1130900253},
	abstract = {In mathematics, in the area of numerical analysis, Galerkin methods, named after the Russian mathematician Boris Galerkin, convert a continuous operator problem, such as a differential equation, commonly in a weak formulation, to a discrete problem by applying linear constraints determined by finite sets of basis functions.
Often when referring to a Galerkin method, one also gives the name along with typical assumptions and approximation methods used:

 Ritz–Galerkin method (after Walther Ritz) typically assumes symmetric and positive definite bilinear form in the weak formulation, where the differential equation for a physical system can be formulated via minimization of a quadratic function representing the system energy and the approximate solution is a linear combination of the given set of the basis functions.
Bubnov–Galerkin method (after Ivan Bubnov) does not require the bilinear form to be symmetric and substitutes the energy minimization with orthogonality constraints determined by the same basis functions that are used to approximate the solution. In an operator formulation of the differential equation, Bubnov–Galerkin method can be viewed as applying an orthogonal projection to the operator.
Petrov–Galerkin method (after Georgii I. Petrov) allows using basis functions for orthogonality constraints (called test basis functions) that are different from the basis functions used to approximate the solution. Petrov–Galerkin method can be viewed as an extension of Bubnov–Galerkin method, applying a projection that is not necessarily orthogonal in the operator formulation of the differential equation.Examples of Galerkin methods are:

the Galerkin method of weighted residuals, the most common method of calculating the global stiffness matrix in the finite element method,
the boundary element method for solving integral equations,
Krylov subspace methods.},
	language = {en},
	urldate = {2023-01-25},
	journal = {Wikipedia},
	month = jan,
	year = {2023},
	note = {Page Version ID: 1130900253},
}

@misc{noauthor_spectral_2023-1,
	title = {Spectral method},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Spectral_method&oldid=1134134983},
	abstract = {Spectral methods are a class of techniques used in applied mathematics and scientific computing to numerically solve certain differential equations. The idea is to write the solution of the differential equation as a sum of certain "basis functions" (for example, as a Fourier series which is a sum of sinusoids) and then to choose the coefficients in the sum in order to satisfy the differential equation as well as possible.
Spectral methods and finite element methods are closely related and built on the same ideas; the main difference between them is that spectral methods use basis functions that are generally nonzero over the whole domain, while finite element methods use basis functions that are nonzero only on small subdomains (compact support). Consequently, spectral methods connect variables globally while finite elements do so locally. Partially for this reason, spectral methods have excellent error properties, with the so-called "exponential convergence" being the fastest possible, when the solution is smooth. However, there are no known three-dimensional single domain spectral shock capturing results (shock waves are not smooth). In the finite element community, a method where the degree of the elements is very high or increases as the grid parameter h increases is sometimes called a spectral element method.
Spectral methods can be used to solve differential equations (PDEs, ODEs, eigenvalue, etc) and optimization problems. When applying spectral methods to time-dependent PDEs, the solution is typically written as a sum of basis functions with time-dependent coefficients; substituting this in the PDE yields a system of ODEs in the coefficients which can be solved using any numerical method for ODEs. Eigenvalue problems for ODEs are similarly converted to matrix eigenvalue problems.
Spectral methods were developed in a long series of papers by Steven Orszag starting in 1969 including, but not limited to, Fourier series methods for periodic geometry problems, polynomial spectral methods for finite and unbounded geometry problems, pseudospectral methods for highly nonlinear problems, and spectral iteration methods for fast solution of steady-state problems. The implementation of the spectral method is normally accomplished either with collocation or a Galerkin or a Tau approach . For very small problems, the spectral method is unique in that solutions may be written out symbolically, yielding a practical alternative to series solutions for differential equations.
Spectral methods can be computationally less expensive and easier to implement than finite element methods; they shine best when high accuracy is sought in simple domains with smooth solutions. However, because of their global nature, the matrices associated with step computation are dense and computational efficiency will quickly suffer when there are many degrees of freedom (with some exceptions, for example if matrix applications can be written as Fourier transforms). For larger problems and nonsmooth solutions, finite elements will generally work better due to sparse matrices and better modelling of discontinuities and sharp bends.},
	language = {en},
	urldate = {2023-01-25},
	journal = {Wikipedia},
	month = jan,
	year = {2023},
	note = {Page Version ID: 1134134983},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\ZM4CLCDZ\\Spectral_method.html:text/html},
}

@misc{noauthor_predictorcorrector_2020,
	title = {Predictor–corrector method},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Predictor%E2%80%93corrector_method&oldid=955920527},
	abstract = {In numerical analysis, predictor–corrector methods belong to a class of algorithms designed to integrate ordinary differential equations – to find an unknown function that satisfies a given differential equation.  All such algorithms proceed in two steps: 

The initial, "prediction" step, starts from a function fitted to the function-values and derivative-values at a preceding set of points to extrapolate ("anticipate") this function's value at a subsequent, new point.
The next, "corrector" step refines the initial approximation by using the predicted value of the function and another method to interpolate that unknown function's value at the same subsequent point.},
	language = {en},
	urldate = {2023-01-25},
	journal = {Wikipedia},
	month = may,
	year = {2020},
	note = {Page Version ID: 955920527},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\8KLI757A\\Predictor–corrector_method.html:text/html},
}

@misc{agarwal_branching_2018,
	title = {Branching diffusion representation of semi-linear elliptic {PDEs} and estimation using {Monte} {Carlo} method},
	url = {http://arxiv.org/abs/1704.00328},
	abstract = {We study semi-linear elliptic PDEs with polynomial non-linearity and provide a probabilistic representation of their solution using branching diﬀusion processes. When the non-linearity involves the unknown function but not its derivatives, we extend previous results in the literature by showing that our probabilistic representation provides a solution to the PDE without assuming its existence. In the general case, we derive a new representation of the solution by using marked branching diﬀusion processes and automatic diﬀerentiation formulas to account for the non-linear gradient term. In both cases, we develop new theoretical tools to provide explicit suﬃcient conditions under which our probabilistic representations hold. As an application, we consider several examples including multi-dimensional semi-linear elliptic PDEs and estimate their solution by using the Monte Carlo method.},
	language = {en},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Agarwal, Ankush and Claisse, Julien},
	month = feb,
	year = {2018},
	note = {arXiv:1704.00328 [math]},
	keywords = {Mathematics - Probability, 35J61, 60H30, 60J85, 65C05},
	file = {Agarwal en Claisse - 2018 - Branching diffusion representation of semi-linear .pdf:C\:\\Users\\Admin\\Zotero\\storage\\A5D35SX4\\Agarwal en Claisse - 2018 - Branching diffusion representation of semi-linear .pdf:application/pdf},
}

@misc{warin_nesting_2018,
	title = {Nesting {Monte} {Carlo} for high-dimensional {Non} {Linear} {PDEs}},
	url = {http://arxiv.org/abs/1804.08432},
	abstract = {A new method based on nesting Monte Carlo is developed to solve highdimensional semi-linear PDEs. Convergence of the method is proved and its convergence rate studied. Results in high dimension for diﬀerent kind of non-linearities show its eﬃciency.},
	language = {en},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Warin, Xavier},
	month = may,
	year = {2018},
	note = {arXiv:1804.08432 [math]},
	keywords = {Mathematics - Probability, Primary 65C05, secondary 49L25},
	annote = {Comment: 35 pages},
	file = {Warin - 2018 - Nesting Monte Carlo for high-dimensional Non Linea.pdf:C\:\\Users\\Admin\\Zotero\\storage\\LV4I2MV7\\Warin - 2018 - Nesting Monte Carlo for high-dimensional Non Linea.pdf:application/pdf},
}

@misc{warin_variations_2017,
	title = {Variations on branching methods for non linear {PDEs}},
	url = {http://arxiv.org/abs/1701.07660},
	abstract = {The branching methods developed in [9], [11] are eﬀective methods to solve some semi linear PDEs and are shown numerically to be able to solve some full non linear PDEs. These methods are however restricted to some small coeﬃcients in the PDE and small maturities. This article shows numerically that these methods can be adapted to solve the problems with longer maturities in the semi-linear case by using a new derivation scheme and some nested method. As for the case of full non linear PDEs, we introduce new schemes and we show numerically that they provide an eﬀective alternative to the schemes previously developed.},
	language = {en},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Warin, Xavier},
	month = jan,
	year = {2017},
	note = {arXiv:1701.07660 [math]},
	keywords = {Mathematics - Probability, 65C05, 60J60, 60J85, 35K10},
	annote = {Comment: 25 pages},
	file = {Warin - 2017 - Variations on branching methods for non linear PDE.pdf:C\:\\Users\\Admin\\Zotero\\storage\\CK46H39I\\Warin - 2017 - Variations on branching methods for non linear PDE.pdf:application/pdf},
}

@article{e_multilevel_2019-1,
	title = {On multilevel {Picard} numerical approximations for high-dimensional nonlinear parabolic partial differential equations and high-dimensional nonlinear backward stochastic differential equations},
	volume = {79},
	issn = {0885-7474, 1573-7691},
	url = {http://arxiv.org/abs/1708.03223},
	doi = {10.1007/s10915-018-00903-0},
	abstract = {Parabolic partial diﬀerential equations (PDEs) and backward stochastic diﬀerential equations (BSDEs) are key ingredients in a number of models in physics and ﬁnancial engineering. In particular, parabolic PDEs and BSDEs are fundamental tools in the state-of-the-art pricing and hedging of ﬁnancial derivatives. The PDEs and BSDEs appearing in such applications are often high-dimensional and nonlinear. Since explicit solutions of such PDEs and BSDEs are typically not available, it is a very active topic of research to solve such PDEs and BSDEs approximately. In the recent article [E, W., Hutzenthaler, M., Jentzen, A., \& Kruse, T. Linear scaling algorithms for solving high-dimensional nonlinear parabolic diﬀerential equations. arXiv:1607.03295 (2017)] we proposed a family of approximation methods based on Picard approximations and multilevel Monte Carlo methods and showed under suitable regularity assumptions on the exact solution for semilinear heat equations that the computational complexity is bounded by O(d ε−(4+δ)) for any δ ∈ (0, ∞), where d is the dimensionality of the problem and ε ∈ (0, ∞) is the prescribed accuracy. In this paper, we test the applicability of this algorithm on a variety of 100-dimensional nonlinear PDEs that arise in physics and ﬁnance by means of numerical simulations presenting approximation accuracy against runtime. The simulation results for these 100-dimensional example PDEs are very satisfactory in terms of accuracy and speed. In addition, we also provide a review of other approximation methods for nonlinear PDEs and BSDEs from the literature.},
	language = {en},
	number = {3},
	urldate = {2023-01-24},
	journal = {Journal of Scientific Computing},
	author = {E, Weinan and Hutzenthaler, Martin and Jentzen, Arnulf and Kruse, Thomas},
	month = jun,
	year = {2019},
	note = {arXiv:1708.03223 [math]},
	keywords = {Mathematics - Numerical Analysis},
	pages = {1534--1571},
	file = {E e.a. - 2019 - On multilevel Picard numerical approximations for .pdf:C\:\\Users\\Admin\\Zotero\\storage\\GNSPNCPT\\E e.a. - 2019 - On multilevel Picard numerical approximations for .pdf:application/pdf},
}

@misc{blechschmidt_three_2021,
	title = {Three {Ways} to {Solve} {Partial} {Differential} {Equations} with {Neural} {Networks} -- {A} {Review}},
	url = {http://arxiv.org/abs/2102.11802},
	abstract = {Neural networks are increasingly used to construct numerical solution methods for partial diﬀerential equations. In this expository review, we introduce and contrast three important recent approaches attractive in their simplicity and their suitability for high-dimensional problems: physics-informed neural networks, methods based on the Feynman-Kac formula and methods based on the solution of backward stochastic diﬀerential equations. The article is accompanied by a suite of expository software in the form of Jupyter notebooks in which each basic methodology is explained step by step, allowing for a quick assimilation and experimentation. An extensive bibliography summarizes the state of the art.},
	language = {en},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Blechschmidt, Jan and Ernst, Oliver G.},
	month = apr,
	year = {2021},
	note = {arXiv:2102.11802 [cs, math]},
	keywords = {Mathematics - Numerical Analysis},
	annote = {Comment: 32 pages; for associated Jupyter notebooks, see https://github.com/janblechschmidt/PDEsByNNs},
	file = {Blechschmidt en Ernst - 2021 - Three Ways to Solve Partial Differential Equations.pdf:C\:\\Users\\Admin\\Zotero\\storage\\3CQBUAIB\\Blechschmidt en Ernst - 2021 - Three Ways to Solve Partial Differential Equations.pdf:application/pdf},
}

@article{cerny_simplified_2021,
	title = {Simplified stochastic calculus with applications in {Economics} and {Finance}},
	volume = {293},
	issn = {03772217},
	url = {http://arxiv.org/abs/1912.03651},
	doi = {10.1016/j.ejor.2020.12.037},
	abstract = {The paper introduces a simple way of recording and manipulating general stochastic processes without explicit reference to a probability measure. In the new calculus, operations traditionally presented in a measure-speciﬁc way are instead captured by tracing the behaviour of jumps (also when no jumps are physically present). The calculus is fail-safe in that, under minimal assumptions, all informal calculations yield mathematically well-deﬁned stochastic processes. The calculus is also intuitive as it allows the user to pretend all jumps are of compound Poisson type. The new calculus is very eﬀective when it comes to computing drifts and expected values that possibly involve a change of measure. Such drift calculations yield, for example, partial integro–diﬀerential equations, Hamilton–Jacobi–Bellman equations, Feynman–Kac formulae, or exponential moments needed in numerous applications. We provide several illustrations of the new technique, among them a novel result on the Margrabe option to exchange one defaultable asset for another.},
	language = {en},
	number = {2},
	urldate = {2023-01-24},
	journal = {European Journal of Operational Research},
	author = {Černý, Aleš and Ruf, Johannes},
	month = sep,
	year = {2021},
	note = {arXiv:1912.03651 [math, q-fin]},
	keywords = {Mathematics - Probability, Quantitative Finance - Mathematical Finance, (Primary) 60H05, 60H10, 60G44, 60G48, (Secondary) 91B02, 91B25, 91G10},
	pages = {547--560},
	file = {Černý en Ruf - 2021 - Simplified stochastic calculus with applications i.pdf:C\:\\Users\\Admin\\Zotero\\storage\\7NICUN3Z\\Černý en Ruf - 2021 - Simplified stochastic calculus with applications i.pdf:application/pdf},
}

@misc{hout_efficient_2022,
	title = {Efficient numerical valuation of {European} options under the two-asset {Kou} jump-diffusion model},
	url = {http://arxiv.org/abs/2207.10060},
	abstract = {This paper concerns the numerical solution of the two-dimensional time-dependent partial integro-diﬀerential equation (PIDE) that holds for the values of European-style options under the two-asset Kou jump-diﬀusion model. A main feature of this equation is the presence of a nonlocal double integral term. For its numerical evaluation, we extend a highly eﬃcient algorithm derived by Toivanen [30] in the case of the one-dimensional Kou integral. The acquired algorithm for the two-dimensional Kou integral has optimal computational cost: the number of basic arithmetic operations is directly proportional to the number of spatial grid points in the semidiscretization. For the eﬀective discretization in time, we study seven contemporary operator splitting schemes of the implicit-explicit (IMEX) and the alternating direction implicit (ADI) kind. All these schemes allow for a convenient, explicit treatment of the integral term. By ample numerical experiments for put-on-the-average option values, the stability and convergence behaviour as well as the mutual performance of the seven operator splitting schemes are investigated. Moreover, the Greeks Delta and Gamma are considered.},
	language = {en},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Hout, Karel in 't and Lamotte, Pieter},
	month = jul,
	year = {2022},
	note = {arXiv:2207.10060 [cs, math, q-fin]},
	keywords = {Mathematics - Numerical Analysis, Quantitative Finance - Computational Finance},
	annote = {Comment: arXiv admin note: text overlap with arXiv:1901.03839},
	file = {Hout en Lamotte - 2022 - Efficient numerical valuation of European options .pdf:C\:\\Users\\Admin\\Zotero\\storage\\65FUB6WN\\Hout en Lamotte - 2022 - Efficient numerical valuation of European options .pdf:application/pdf},
}

@misc{henry-labordere_branching_2016,
	title = {Branching diffusion representation of semilinear {PDEs} and {Monte} {Carlo} approximation},
	url = {http://arxiv.org/abs/1603.01727},
	abstract = {We provide a representation result of parabolic semi-linear PD-Es, with polynomial nonlinearity, by branching diﬀusion processes. We extend the classical representation for KPP equations, introduced by Skorokhod [23], Watanabe [27] and McKean [18], by allowing for polynomial nonlinearity in the pair (u, Du), where u is the solution of the PDE with space gradient Du. Similar to the previous literature, our result requires a non-explosion condition which restrict to “small maturity” or “small nonlinearity” of the PDE. Our main ingredient is the automatic diﬀerentiation technique as in [15], based on the Malliavin integration by parts, which allows to account for the nonlinearities in the gradient. As a consequence, the particles of our branching diﬀusion are marked by the nature of the nonlinearity. This new representation has very important numerical implications as it is suitable for Monte Carlo simulation. Indeed, this provides the ﬁrst numerical method for high dimensional nonlinear PDEs with error estimate induced by the dimension-free Central limit theorem. The complexity is also easily seen to be of the order of the squared dimension. The ﬁnal section of this paper illustrates the eﬃciency of the algorithm by some high dimensional numerical experiments.},
	language = {en},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Henry-Labordere, Pierre and Oudjane, Nadia and Tan, Xiaolu and Touzi, Nizar and Warin, Xavier},
	month = mar,
	year = {2016},
	note = {arXiv:1603.01727 [math]},
	keywords = {Mathematics - Probability, Mathematics - Numerical Analysis},
	file = {Henry-Labordere e.a. - 2016 - Branching diffusion representation of semilinear P.pdf:C\:\\Users\\Admin\\Zotero\\storage\\6HC4YVGI\\Henry-Labordere e.a. - 2016 - Branching diffusion representation of semilinear P.pdf:application/pdf},
}

@misc{noauthor_branching_2023,
	title = {Branching process},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Branching_process&oldid=1131945188},
	abstract = {In probability theory, a branching process is a type of mathematical object known as a stochastic process, which consists of collections of random variables. The random variables of a stochastic process are indexed by the natural numbers. The original purpose of branching processes was to serve as a mathematical model of a population in which each individual in generation 
  
    
      
        n
      
    
    \{{\textbackslash}displaystyle n\}
   produces some random number of individuals in generation 
  
    
      
        n
        +
        1
      
    
    \{{\textbackslash}displaystyle n+1\}
  , according, in the simplest case, to a fixed probability distribution that does not vary from individual to individual. Branching processes are used to model reproduction; for example, the individuals might correspond to bacteria, each of which generates 0, 1, or 2 offspring with some probability in a single time unit.  Branching processes can also be used to model other systems with similar dynamics, e.g., the spread of surnames in genealogy or the propagation of neutrons in a nuclear reactor.
A central question in the theory of branching processes is the probability of ultimate extinction, where no individuals exist after some finite number of generations.  Using Wald's equation, it can be shown that starting with one individual in generation zero, the expected size of generation n equals μn where μ is the expected number of children of each individual.  If μ {\textless} 1, then the expected number of individuals goes rapidly to zero, which implies ultimate extinction with probability 1 by Markov's inequality.  Alternatively, if μ {\textgreater} 1, then the probability of ultimate extinction is less than 1 (but not necessarily zero; consider a process where each individual either has 0 or 100 children with equal probability. In that case, μ = 50, but probability of ultimate extinction is greater than 0.5, since that's the probability that the first individual has 0 children).  If μ = 1, then ultimate extinction occurs with probability 1 unless each individual always has exactly one child.
In theoretical ecology, the parameter μ of a branching process is called the basic reproductive rate.},
	language = {en},
	urldate = {2023-01-24},
	journal = {Wikipedia},
	month = jan,
	year = {2023},
	note = {Page Version ID: 1131945188},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\NDK5UH98\\Branching_process.html:text/html},
}

@misc{nguwi_fully_2022,
	title = {A fully nonlinear {Feynman}-{Kac} formula with derivatives of arbitrary orders},
	url = {http://arxiv.org/abs/2201.03882},
	abstract = {We present an algorithm for the numerical solution of nonlinear parabolic partial diﬀerential equations. This algorithm extends the classical Feynman-Kac formula to fully nonlinear partial diﬀerential equations, by using random trees that carry information on nonlinearities on their branches. It applies to functional, non-polynomial nonlinearities that are not treated by standard branching arguments, and deals with derivative terms of arbitrary orders. A Monte Carlo numerical implementation is provided.},
	language = {en},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Nguwi, Jiang Yu and Penent, Guillaume and Privault, Nicolas},
	month = dec,
	year = {2022},
	note = {arXiv:2201.03882 [math]},
	keywords = {Mathematics - Analysis of PDEs, Mathematics - Probability, 35G20, 35K55, 35K58, 35B65, 60J85, 60G51, 65C05},
	file = {Nguwi e.a. - 2022 - A fully nonlinear Feynman-Kac formula with derivat.pdf:C\:\\Users\\Admin\\Zotero\\storage\\XRMIKRSC\\Nguwi e.a. - 2022 - A fully nonlinear Feynman-Kac formula with derivat.pdf:application/pdf},
}

@misc{becker_learning_2022,
	title = {Learning the random variables in {Monte} {Carlo} simulations with stochastic gradient descent: {Machine} learning for parametric {PDEs} and financial derivative pricing},
	shorttitle = {Learning the random variables in {Monte} {Carlo} simulations with stochastic gradient descent},
	url = {http://arxiv.org/abs/2202.02717},
	abstract = {In financial engineering, prices of financial products are computed approximately many times each trading day with (slightly) different parameters in each calculation. In many financial models such prices can be approximated by means of Monte Carlo (MC) simulations. To obtain a good approximation the MC sample size usually needs to be considerably large resulting in a long computing time to obtain a single approximation. In this paper we introduce a new approximation strategy for parametric approximation problems including the parametric financial pricing problems described above. A central aspect of the approximation strategy proposed in this article is to combine MC algorithms with machine learning techniques to, roughly speaking, learn the random variables (LRV) in MC simulations. In other words, we employ stochastic gradient descent (SGD) optimization methods not to train parameters of standard artificial neural networks (ANNs) but to learn random variables appearing in MC approximations. We numerically test the LRV strategy on various parametric problems with convincing results when compared with standard MC simulations, Quasi-Monte Carlo simulations, SGD-trained shallow ANNs, and SGD-trained deep ANNs. Our numerical simulations strongly indicate that the LRV strategy might be capable to overcome the curse of dimensionality in the \$L{\textasciicircum}{\textbackslash}infty\$-norm in several cases where the standard deep learning approach has been proven not to be able to do so. This is not a contradiction to lower bounds established in the scientific literature because this new LRV strategy is outside of the class of algorithms for which lower bounds have been established in the scientific literature. The proposed LRV strategy is of general nature and not only restricted to the parametric financial pricing problems described above, but applicable to a large class of approximation problems.},
	language = {en},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Becker, Sebastian and Jentzen, Arnulf and Müller, Marvin S. and von Wurstemberger, Philippe},
	month = feb,
	year = {2022},
	note = {arXiv:2202.02717 [cs, math]},
	keywords = {Mathematics - Analysis of PDEs, Mathematics - Probability, Mathematics - Numerical Analysis, 35K15, 65C05, 65M75, 68T99, 91G20},
	file = {Becker e.a. - 2022 - Learning the random variables in Monte Carlo simul.pdf:C\:\\Users\\Admin\\Zotero\\storage\\ZT28NZYQ\\Becker e.a. - 2022 - Learning the random variables in Monte Carlo simul.pdf:application/pdf},
}

@misc{noauthor_stochastic_2022,
	title = {Stochastic partial differential equation},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Stochastic_partial_differential_equation&oldid=1129102419},
	abstract = {Stochastic partial differential equations (SPDEs) generalize partial differential equations via random force terms and coefficients, in the same way ordinary stochastic differential equations generalize ordinary differential equations.
They have relevance to quantum field theory, statistical mechanics, and spatial modeling.},
	language = {en},
	urldate = {2023-01-24},
	journal = {Wikipedia},
	month = dec,
	year = {2022},
	note = {Page Version ID: 1129102419},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\KXX22C9Y\\Stochastic_partial_differential_equation.html:text/html},
}

@misc{li_quantum_2023,
	title = {Quantum {Monte} {Carlo} algorithm for solving {Black}-{Scholes} {PDEs} for high-dimensional option pricing in finance and its proof of overcoming the curse of dimensionality},
	url = {http://arxiv.org/abs/2301.09241},
	abstract = {In this paper we provide a quantum Monte Carlo algorithm to solve high-dimensional Black-Scholes PDEs with correlation for high-dimensional option pricing. The payoﬀ function of the option is of general form and is only required to be continuous and piece-wise aﬃne (CPWA), which covers most of the relevant payoﬀ functions used in ﬁnance. We provide a rigorous error analysis and complexity analysis of our algorithm. In particular, we prove that the computational complexity of our algorithm is bounded polynomially in the space dimension d of the PDE and the reciprocal of the prescribed accuracy ε and so demonstrate that our quantum Monte Carlo algorithm does not suﬀer from the curse of dimensionality.},
	language = {en},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Li, Yongming and Neufeld, Ariel},
	month = jan,
	year = {2023},
	note = {arXiv:2301.09241 [quant-ph, q-fin]},
	keywords = {Mathematics - Numerical Analysis, Quantitative Finance - Computational Finance, Quantitative Finance - Mathematical Finance, Quantum Physics},
	file = {Li en Neufeld - 2023 - Quantum Monte Carlo algorithm for solving Black-Sc.pdf:C\:\\Users\\Admin\\Zotero\\storage\\2UE3LKA6\\Li en Neufeld - 2023 - Quantum Monte Carlo algorithm for solving Black-Sc.pdf:application/pdf},
}

@article{ermakov_backward_2022,
	title = {Backward {Iterations} for {Solving} {Integral} {Equations} with {Polynomial} {Nonlinearity}},
	volume = {55},
	issn = {1063-4541, 1934-7855},
	url = {https://link.springer.com/10.1134/S1063454122010046},
	doi = {10.1134/S1063454122010046},
	abstract = {The theory of adjoint operators is widely used in solving applied multidimensional problems with the Monte Carlo method. Efficient algorithms are constructed using the duality principle for many problems described in linear integral equations of the second kind. On the other hand, important applications of adjoint equations for designing experiments were suggested by G.I. Marchuk and his colleagues in their respective works. Some results obtained in these fields are also generalized to the case of nonlinear operators. Linearization methods are mostly used for that purpose. The results for Lyapunov–Schmidt nonlinear polynomial equations are obtained in the theory of Monte Carlo methods. However, many interesting questions in this subject area remain open. New results about dual processes used for solving polynomial equations with the Monte Carlo method are presented. In particular, the adjoint Markov process for the branching process and corresponding unbiased estimate of the functional of the solution to the equation are constructed in the general form. The possibility of constructing an adjoint operator to a nonlinear one is discussed.},
	language = {en},
	number = {1},
	urldate = {2023-01-24},
	journal = {Vestnik St. Petersburg University, Mathematics},
	author = {Ermakov, S. M. and Surovikina, T. O.},
	month = mar,
	year = {2022},
	pages = {16--26},
	file = {Ermakov en Surovikina - 2022 - Backward Iterations for Solving Integral Equations.pdf:C\:\\Users\\Admin\\Zotero\\storage\\MGBUUSKA\\Ermakov en Surovikina - 2022 - Backward Iterations for Solving Integral Equations.pdf:application/pdf},
}

@misc{noauthor_matrix_2022,
	title = {Matrix exponential},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Matrix_exponential&oldid=1122134034},
	abstract = {In mathematics, the matrix exponential is a matrix function on square matrices analogous to the ordinary exponential function. It is used to solve systems of linear differential equations. In the theory of Lie groups, the matrix exponential gives the exponential map between a matrix Lie algebra and the corresponding Lie group.
Let X  be an n×n real or complex matrix. The exponential of X, denoted by eX or exp(X), is the n×n matrix given by the power series

where 
  
    
      
        
          X
          
            0
          
        
      
    
    \{{\textbackslash}displaystyle X{\textasciicircum}\{0\}\}
   is defined to be the identity matrix 
  
    
      
        I
      
    
    \{{\textbackslash}displaystyle I\}
   with the same dimensions as 
  
    
      
        X
      
    
    \{{\textbackslash}displaystyle X\}
  .The above series always converges, so the exponential of X is well-defined. If X is a 1×1 matrix the matrix exponential of X is a 1×1 matrix whose single element is the ordinary exponential of the single element of X.},
	language = {en},
	urldate = {2023-01-23},
	journal = {Wikipedia},
	month = nov,
	year = {2022},
	note = {Page Version ID: 1122134034},
}

@misc{noauthor_bakercampbellhausdorff_2022,
	title = {Baker–{Campbell}–{Hausdorff} formula},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Baker%E2%80%93Campbell%E2%80%93Hausdorff_formula&oldid=1115922051},
	abstract = {In mathematics, the Baker–Campbell–Hausdorff formula is the solution for 
  
    
      
        Z
      
    
    \{{\textbackslash}displaystyle Z\}
   to the equation

for possibly noncommutative X and Y in the Lie algebra of a Lie group. There are various ways of writing the formula, but all ultimately yield an expression for 
  
    
      
        Z
      
    
    \{{\textbackslash}displaystyle Z\}
   in Lie algebraic terms, that is, as a formal series (not necessarily convergent) in 
  
    
      
        X
      
    
    \{{\textbackslash}displaystyle X\}
   and 
  
    
      
        Y
      
    
    \{{\textbackslash}displaystyle Y\}
   and iterated commutators thereof. The first few terms of this series are:

where "
  
    
      
        ⋯
      
    
    \{{\textbackslash}displaystyle {\textbackslash}cdots \}
  " indicates terms involving higher commutators of 
  
    
      
        X
      
    
    \{{\textbackslash}displaystyle X\}
   and 
  
    
      
        Y
      
    
    \{{\textbackslash}displaystyle Y\}
  . If 
  
    
      
        X
      
    
    \{{\textbackslash}displaystyle X\}
   and 
  
    
      
        Y
      
    
    \{{\textbackslash}displaystyle Y\}
   are sufficiently small elements of the Lie algebra 
  
    
      
        
          
            g
          
        
      
    
    \{{\textbackslash}displaystyle \{{\textbackslash}mathfrak \{g\}\}\}
   of a Lie group 
  
    
      
        G
      
    
    \{{\textbackslash}displaystyle G\}
  , the series is convergent. Meanwhile, every element 
  
    
      
        g
      
    
    \{{\textbackslash}displaystyle g\}
   sufficiently close to the identity in 
  
    
      
        G
      
    
    \{{\textbackslash}displaystyle G\}
   can be expressed as 
  
    
      
        g
        =
        
          e
          
            X
          
        
      
    
    \{{\textbackslash}displaystyle g=e{\textasciicircum}\{X\}\}
   for a small 
  
    
      
        X
      
    
    \{{\textbackslash}displaystyle X\}
   in 
  
    
      
        
          
            g
          
        
      
    
    \{{\textbackslash}displaystyle \{{\textbackslash}mathfrak \{g\}\}\}
  . Thus, we can say that near the identity the group multiplication in 
  
    
      
        G
      
    
    \{{\textbackslash}displaystyle G\}
  —written as 
  
    
      
        
          e
          
            X
          
        
        
          e
          
            Y
          
        
        =
        
          e
          
            Z
          
        
      
    
    \{{\textbackslash}displaystyle e{\textasciicircum}\{X\}e{\textasciicircum}\{Y\}=e{\textasciicircum}\{Z\}\}
  —can be expressed in purely Lie algebraic terms. The Baker–Campbell–Hausdorff formula can be used to give comparatively simple proofs of deep results in the Lie group–Lie algebra correspondence.
If 
  
    
      
        X
      
    
    \{{\textbackslash}displaystyle X\}
   and 
  
    
      
        Y
      
    
    \{{\textbackslash}displaystyle Y\}
   are sufficiently small 
  
    
      
        n
        ×
        n
      
    
    \{{\textbackslash}displaystyle n{\textbackslash}times n\}
   matrices, then 
  
    
      
        Z
      
    
    \{{\textbackslash}displaystyle Z\}
   can be computed as the logarithm of 
  
    
      
        
          e
          
            X
          
        
        
          e
          
            Y
          
        
      
    
    \{{\textbackslash}displaystyle e{\textasciicircum}\{X\}e{\textasciicircum}\{Y\}\}
  , where the exponentials and the logarithm can be computed as power series. The point of the Baker–Campbell–Hausdorff formula is then the highly nonobvious claim that 
  
    
      
        Z
        :=
        log
        ⁡
        
          (
          
            
              e
              
                X
              
            
            
              e
              
                Y
              
            
          
          )
        
      
    
    \{{\textbackslash}displaystyle Z:={\textbackslash}log {\textbackslash}left(e{\textasciicircum}\{X\}e{\textasciicircum}\{Y\}{\textbackslash}right)\}
   can be expressed as a series in repeated commutators of 
  
    
      
        X
      
    
    \{{\textbackslash}displaystyle X\}
   and 
  
    
      
        Y
      
    
    \{{\textbackslash}displaystyle Y\}
  .
Modern expositions of the formula can be found in, among other places, the books of Rossmann and Hall.},
	language = {en},
	urldate = {2023-01-23},
	journal = {Wikipedia},
	month = oct,
	year = {2022},
	note = {Page Version ID: 1115922051},
}

@article{sastre_accurate_2014,
	title = {Accurate and efficient matrix exponential computation},
	volume = {91},
	issn = {0020-7160, 1029-0265},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00207160.2013.791392},
	doi = {10.1080/00207160.2013.791392},
	language = {en},
	number = {1},
	urldate = {2023-01-23},
	journal = {International Journal of Computer Mathematics},
	author = {Sastre, J. and Ibáñez, J. and Ruiz, P. and Defez, E.},
	month = jan,
	year = {2014},
	pages = {97--112},
	file = {Sastre e.a. - 2014 - Accurate and efficient matrix exponential computat.pdf:C\:\\Users\\Admin\\Zotero\\storage\\QEY4VDFZ\\Sastre e.a. - 2014 - Accurate and efficient matrix exponential computat.pdf:application/pdf},
}

@misc{noauthor_pade_2022,
	title = {Padé approximant},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Pad%C3%A9_approximant&oldid=1123396275},
	abstract = {In mathematics, a Padé approximant is the "best" approximation of a function near a specific point by a rational function of given order. Under this technique, the approximant's power series agrees with the power series of the function it is approximating.  The technique was developed around 1890 by Henri Padé, but goes back to Georg Frobenius, who introduced the idea and investigated the features of rational approximations of power series.
The Padé approximant often gives better approximation of the function than truncating its Taylor series, and it may still work where the Taylor series does not converge. For these reasons Padé approximants are used extensively in computer calculations. They have also been used as auxiliary functions in Diophantine approximation and transcendental number theory, though for sharp results ad hoc methods— in some sense inspired by the Padé theory— typically replace them. Since Padé approximant is a rational function, an artificial singular point may occur as an approximation, but this can be avoided by Borel–Padé analysis.
The reason why the Padé approximant tends to be a better approximation than a truncating Taylor series is clear from the viewpoint of the multi-point summation method. Since there are many cases in which the asymptotic expansion at infinity becomes 0 or a constant, it can be interpreted as the "incomplete two-point Padé approximation", in which the ordinary Padé approximation improves the method truncating a Taylor series.},
	language = {en},
	urldate = {2023-01-23},
	journal = {Wikipedia},
	month = nov,
	year = {2022},
	note = {Page Version ID: 1123396275},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\KVILJA4H\\Padé_approximant.html:text/html},
}

@article{bergamaschi_efficient_2000,
	title = {Efficient computation of the exponential operator for large, sparse, symmetric matrices},
	volume = {7},
	issn = {1070-5325, 1099-1506},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1099-1506(200001/02)7:1<27::AID-NLA185>3.0.CO;2-4},
	doi = {10.1002/(SICI)1099-1506(200001/02)7:1<27::AID-NLA185>3.0.CO;2-4},
	abstract = {In this paper we compare Krylov subspace methods with Chebyshev series expansion for approximating the matrix exponential operator on large, sparse, symmetric matrices. Experimental results upon negative-deﬁnite matrices with very large size, arising from (2D and 3D) FE and FD spatial discretization of linear parabolic PDEs, demonstrate that the Chebyshev method can be an effective alternative to Krylov techniques, especially when memory bounds do not allow the storage of all Ritz vectors. We discuss also sensitivity of Chebyshev convergence to extreme eigenvalue approximation, as well as reliability of various a priori and a posteriori error estimates for both methods.},
	language = {en},
	number = {1},
	urldate = {2023-01-23},
	journal = {Numerical Linear Algebra with Applications},
	author = {Bergamaschi, Luca and Vianello, Marco},
	month = jan,
	year = {2000},
	pages = {27--45},
	file = {Bergamaschi en Vianello - 2000 - Efficient computation of the exponential operator .pdf:C\:\\Users\\Admin\\Zotero\\storage\\5HP78YEJ\\Bergamaschi en Vianello - 2000 - Efficient computation of the exponential operator .pdf:application/pdf},
}

@article{hochbruck_exponential_2010,
	title = {Exponential integrators},
	volume = {19},
	issn = {0962-4929, 1474-0508},
	url = {https://www.cambridge.org/core/product/identifier/S0962492910000048/type/journal_article},
	doi = {10.1017/S0962492910000048},
	abstract = {In this paper we consider the construction, analysis, implementation and application of exponential integrators. The focus will be on two types of stiff problems. The first one is characterized by a Jacobian that possesses eigenvalues with large negative real parts. Parabolic partial differential equations and their spatial discretization are typical examples. The second class consists of highly oscillatory problems with purely imaginary eigenvalues of large modulus. Apart from motivating the construction of exponential integrators for various classes of problems, our main intention in this article is to present the mathematics behind these methods. We will derive error bounds that are independent of stiffness or highest frequencies in the system.
            Since the implementation of exponential integrators requires the evaluation of the product of a matrix function with a vector, we will briefly discuss some possible approaches as well. The paper concludes with some applications, in which exponential integrators are used.},
	language = {en},
	urldate = {2023-01-23},
	journal = {Acta Numerica},
	author = {Hochbruck, Marlis and Ostermann, Alexander},
	month = may,
	year = {2010},
	pages = {209--286},
	file = {Hochbruck en Ostermann - 2010 - Exponential integrators.pdf:C\:\\Users\\Admin\\Zotero\\storage\\C73HIPVU\\Hochbruck en Ostermann - 2010 - Exponential integrators.pdf:application/pdf},
}

@article{hochbruck_exponential_2005,
	title = {Exponential {Runge}–{Kutta} methods for parabolic problems},
	volume = {53},
	issn = {01689274},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0168927404001400},
	doi = {10.1016/j.apnum.2004.08.005},
	abstract = {The aim of this paper is to construct exponential Runge-Kutta methods of collocation type and to analyze their convergence properties for linear and semilinear parabolic problems. For the analysis, an abstract Banach space framework of sectorial operators and locally Lipschitz continuous nonlinearities is chosen. This framework includes interesting examples like reaction-diﬀusion equations. It is shown that the methods converge at least with their stage order, and that convergence of higher order (up to the classical order) occurs, if the problem has suﬃcient temporal and spatial smoothness. The latter, however, might require the source function to fulﬁl unnatural boundary conditions. Therefore, the classical order is not always obtained and an order reduction must be expected, in general.},
	language = {en},
	number = {2-4},
	urldate = {2023-01-22},
	journal = {Applied Numerical Mathematics},
	author = {Hochbruck, Marlis and Ostermann, Alexander},
	month = may,
	year = {2005},
	pages = {323--339},
	file = {Hochbruck en Ostermann - 2005 - Exponential Runge–Kutta methods for parabolic prob.pdf:C\:\\Users\\Admin\\Zotero\\storage\\NHR96XVY\\Hochbruck en Ostermann - 2005 - Exponential Runge–Kutta methods for parabolic prob.pdf:application/pdf},
}

@misc{noauthor_exponential_2022,
	title = {Exponential integrator},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Exponential_integrator&oldid=1123597413},
	abstract = {Exponential integrators are a class of numerical methods for the solution of ordinary differential equations, specifically initial value problems.  This large class of methods from numerical analysis is based on the exact integration of the linear part of the initial value problem. Because the linear part is integrated exactly, this can help to mitigate the stiffness of a differential equation. Exponential integrators can be constructed to be explicit or implicit for numerical ordinary differential equations or serve as the time integrator for numerical partial differential equations.},
	language = {en},
	urldate = {2023-01-22},
	journal = {Wikipedia},
	month = nov,
	year = {2022},
	note = {Page Version ID: 1123597413},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\XH6LIQZ3\\Exponential_integrator.html:text/html},
}

@article{simpson_techniques_nodate,
	title = {{TECHNIQUES} {FOR} {EFFICIENT} {MONTE} {CARLO} {SIMULATION}},
	language = {en},
	author = {Simpson, J R and McGrath, E J},
	file = {Simpson en McGrath - TECHNIQUES FOR EFFICIENT MONTE CARLO SIMULATION.pdf:C\:\\Users\\Admin\\Zotero\\storage\\5LGZDXLC\\Simpson en McGrath - TECHNIQUES FOR EFFICIENT MONTE CARLO SIMULATION.pdf:application/pdf},
}

@misc{noauthor_neyman-ulam_nodate,
	title = {{THE} {NEYMAN}-{ULAM} {SCHEME} {IN} {THE} {NON}-{LINEAR} {CASE}*},
	file = {1-s2.0-0041555373900980-main.pdf:C\:\\Users\\Admin\\Zotero\\storage\\SSN79QHC\\1-s2.0-0041555373900980-main.pdf:application/pdf},
}

@article{nekrutkin_direct_1974,
	title = {Direct and conjugate {Neumann}-{Ulam} schemes for solving non-linear integral equations},
	volume = {14},
	issn = {00415553},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0041555374901670},
	doi = {10.1016/0041-5553(74)90167-0},
	language = {en},
	number = {6},
	urldate = {2023-01-20},
	journal = {USSR Computational Mathematics and Mathematical Physics},
	author = {Nekrutkin, V.V.},
	month = jan,
	year = {1974},
	pages = {39--45},
	file = {Nekrutkin - 1974 - Direct and conjugate Neumann-Ulam schemes for solv.pdf:C\:\\Users\\Admin\\Zotero\\storage\\48XNIP74\\Nekrutkin - 1974 - Direct and conjugate Neumann-Ulam schemes for solv.pdf:application/pdf},
}

@article{halton_sequential_nodate,
	title = {Sequential {Monte} {Carlo} techniques for solving non-linear systems},
	abstract = {Given a system of m equations F(x ) = 0 (where m is large and x is an unknown m-vector), we seek to apply sequential Monte Carlo [SMC] methods to find solutions efficiently. This paper follows up on a previous paper by the same author, in which consideration was limited to linear systems of the form Ax = a (where, again, m is large, A is a known (m¥m) matrix, a is a known m-vector, and x is an unknown m-vector). It was shown there that effective techniques could reduce computation times dramatically (speed-up factors of 550 to 26,000 were obtained in sample calculations).},
	language = {en},
	journal = {Linear Systems},
	author = {Halton, John H},
	file = {Halton - Sequential Monte Carlo techniques for solving non-.pdf:C\:\\Users\\Admin\\Zotero\\storage\\GNEKPJHM\\Halton - Sequential Monte Carlo techniques for solving non-.pdf:application/pdf},
}

@article{ermakov_monte_2021,
	title = {The {Monte} {Carlo} {Method} for {Solving} {Large} {Systems} of {Linear} {Ordinary} {Differential} {Equations}},
	volume = {54},
	issn = {1063-4541, 1934-7855},
	url = {https://link.springer.com/10.1134/S1063454121010064},
	doi = {10.1134/S1063454121010064},
	abstract = {The Monte Carlo method to solve the Cauchy problem for large systems of linear differential equations is proposed in this paper. Firstly, a quick overview of previously obtained results from applying the approach towards the Fredholm-type integral equations is made. In the main part of the paper, the method is applied towards a linear ODE system that is transformed into an equivalent system of the Volterra-type integral equations, which makes it possible to remove the limitations due to the conditions of convergence of the majorant series. The following key theorems are stated. Theorem 1 provides the necessary compliance conditions that should be imposed upon the transition propability and initial distribution densities that initiate the corresponding Markov chain, for which equality between the mathematical expectation of the estimate and the functional of interest would hold. Theorem 2 formulates the equation that governs the estimate’s variance. Theorem 3 states the Markov chain parameters that minimize the variance of the estimate of the functional. Proofs are given for all three theorems. In the practical part of this paper, the proposed method is used to solve a linear ODE system that describes a closed queueing system of ten conventional machines and seven conventional service persons. The solutions are obtained for systems with both constant and time-dependent matrices of coefficients, where the machine breakdown intensity is time dependent. In addition, the solutions obtained by the Monte Carlo and Runge–Kutta methods are compared. The results are presented in the corresponding tables.},
	language = {en},
	number = {1},
	urldate = {2023-01-20},
	journal = {Vestnik St. Petersburg University, Mathematics},
	author = {Ermakov, S. M. and Smilovitskiy, M. G.},
	month = jan,
	year = {2021},
	pages = {28--38},
	file = {Ermakov en Smilovitskiy - 2021 - The Monte Carlo Method for Solving Large Systems o.pdf:C\:\\Users\\Admin\\Zotero\\storage\\EXRTHDXP\\Ermakov en Smilovitskiy - 2021 - The Monte Carlo Method for Solving Large Systems o.pdf:application/pdf},
}

@article{ermakov_monte_2019,
	title = {Monte {Carlo} {Method} for {Solving} {ODE} {Systems}},
	volume = {52},
	issn = {1063-4541, 1934-7855},
	url = {https://link.springer.com/10.1134/S1063454119030087},
	doi = {10.1134/S1063454119030087},
	abstract = {The Monte Carlo method is applied to solve Cauchy problems for a system of linear and 
	nonlinear ordinary differential equations. The Monte Carlo method is relevant for the solution of large systems of equations and in the case of small smoothness of initial functions. In this case, the system is reduced to an equivalent system of integral equations of the Volterra type. For linear systems, this transformation allows removing constraints connected with a convergence of a majorizing process. Examples of estimates of solution functionals are provided, and a behavior of their variances are discussed. In the general case, a solution interval is divided into finite subintervals, on which the nonlinear function is approximated by a polynomial. The obtained integral equation is solved by using branched Markov chains with absorption. Algorithm parallelization problems arising in this case are discussed in this paper. A one-dimensional cubic equation is considered as an example. A choice of transition densities of branching is discussed. A method of generations is described in detail. Numerical results are compared with a solution obtained by the Runge–Kutta method.},
	language = {en},
	number = {3},
	urldate = {2023-01-20},
	journal = {Vestnik St. Petersburg University, Mathematics},
	author = {Ermakov, S. M. and Tovstik, T. M.},
	month = jul,
	year = {2019},
	pages = {272--280},
	file = {Ermakov en Tovstik - 2019 - Monte Carlo Method for Solving ODE Systems.pdf:C\:\\Users\\Admin\\Zotero\\storage\\UM598GXH\\Ermakov en Tovstik - 2019 - Monte Carlo Method for Solving ODE Systems.pdf:application/pdf},
}

@article{mori_numerical_2006,
	title = {Numerical {Green}’s function method based on the {DE} transformation},
	volume = {23},
	issn = {0916-7005, 1868-937X},
	url = {http://link.springer.com/10.1007/BF03167550},
	doi = {10.1007/BF03167550},
	abstract = {A method for numerical solution of boundary value problems with ordinary diﬀerential equation based on the method of Green’s function incorporated with the double exponential transformation is presented. The method proposed does not require solving a system of linear equations and gives an approximate solution of very high accuracy with a small number of function evaluations. The error of the method is O (exp (−C1N/ log(C2N ))) where N is a parameter representing the number of function evaluations and C1 and C2 are some positive constants. Numerical examples also prove the high eﬃciency of the method. An alternative method via an integral equation is presented which can be used when the Green’s function corresponding to the given equation is not available.},
	language = {en},
	number = {2},
	urldate = {2023-01-20},
	journal = {Japan Journal of Industrial and Applied Mathematics},
	author = {Mori, Masatake and Echigo, Toshihiko},
	month = jun,
	year = {2006},
	pages = {193--205},
	file = {Mori en Echigo - 2006 - Numerical Green’s function method based on the DE .pdf:C\:\\Users\\Admin\\Zotero\\storage\\U5ZLG7FE\\Mori en Echigo - 2006 - Numerical Green’s function method based on the DE .pdf:application/pdf},
}

@misc{penent_numerical_2022,
	title = {Numerical evaluation of {ODE} solutions by {Monte} {Carlo} enumeration of {Butcher} series},
	url = {http://arxiv.org/abs/2201.05998},
	abstract = {We present an algorithm for the numerical solution of ordinary diﬀerential equations by random enumeration of the Butcher trees used in the implementation of the RungeKutta method. Our Monte Carlo scheme allows for the direct numerical evaluation of an ODE solution at any given time within a certain interval, without iteration through multiple time steps. In particular, this approach does not involve a discretization step size, and it does not require the truncation of Taylor series.},
	language = {en},
	urldate = {2023-01-20},
	publisher = {arXiv},
	author = {Penent, Guillaume and Privault, Nicolas},
	month = aug,
	year = {2022},
	note = {arXiv:2201.05998 [cs, math]},
	keywords = {Mathematics - Probability, Mathematics - Numerical Analysis, 65L06, 34A25, 34-04, 05C05, 65C05},
	file = {Penent en Privault - 2022 - Numerical evaluation of ODE solutions by Monte Car.pdf:C\:\\Users\\Admin\\Zotero\\storage\\UXRFJ68P\\Penent en Privault - 2022 - Numerical evaluation of ODE solutions by Monte Car.pdf:application/pdf},
}

@misc{noauthor_gibbs_2022,
	title = {Gibbs phenomenon},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Gibbs_phenomenon&oldid=1120811333},
	abstract = {In mathematics, the Gibbs phenomenon, discovered by Henry Wilbraham (1848)  and rediscovered by J. Willard Gibbs (1899), is the oscillatory behavior of the Fourier series of a piecewise continuously differentiable periodic function around a jump discontinuity. The function's 
  
    
      
        N
      
    
    \{{\textbackslash}displaystyle N\}
  th partial Fourier series (formed by summing its 
  
    
      
        N
      
    
    \{{\textbackslash}displaystyle N\}
   lowest constituent sinusoids) produces large peaks around the jump which overshoot and undershoot the function's actual values. This approximation error approaches a limit of about 9\% of the jump as more sinusoids are used, though the infinite Fourier series sum does eventually converge almost everywhere except the point of discontinuity.The Gibbs phenomenon was observed by experimental physicists, but was believed to be due to imperfections in the measuring apparatus, and it is one cause of ringing artifacts in signal processing.},
	language = {en},
	urldate = {2023-01-18},
	journal = {Wikipedia},
	month = nov,
	year = {2022},
	note = {Page Version ID: 1120811333},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\H38JL4E9\\Gibbs_phenomenon.html:text/html},
}

@misc{noauthor_runges_2022,
	title = {Runge's phenomenon},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Runge%27s_phenomenon&oldid=1127648067},
	abstract = {In the mathematical field of numerical analysis, Runge's phenomenon (German: [ˈʁʊŋə]) is a problem of oscillation at the edges of an interval that occurs when using polynomial interpolation with polynomials of high degree over a set of equispaced interpolation points. It was discovered by Carl David Tolmé Runge (1901) when exploring the behavior of errors when using polynomial interpolation to approximate certain functions.
The discovery was important because it shows that going to higher degrees does not always improve accuracy. The phenomenon is similar to the Gibbs phenomenon in Fourier series approximations.},
	language = {en},
	urldate = {2023-01-18},
	journal = {Wikipedia},
	month = dec,
	year = {2022},
	note = {Page Version ID: 1127648067},
}

@misc{noauthor_aitkens_2022,
	title = {Aitken's delta-squared process},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Aitken%27s_delta-squared_process&oldid=1115576594},
	abstract = {In numerical analysis, Aitken's delta-squared process or Aitken extrapolation is a series acceleration method, used for accelerating the rate of convergence of a sequence. It is named after Alexander Aitken, who introduced this method in 1926. Its early form was known to Seki Kōwa (end of 17th century) and was found for rectification of the circle, i.e. the calculation of π. It is most useful for accelerating the convergence of a sequence that is converging linearly.},
	language = {en},
	urldate = {2023-01-16},
	journal = {Wikipedia},
	month = oct,
	year = {2022},
	note = {Page Version ID: 1115576594},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\QPP3CBBR\\Aitken's_delta-squared_process.html:text/html},
}

@misc{stand-up_maths_how_2021,
	title = {How does {Dobble} ({Spot} {It}) work?},
	url = {https://www.youtube.com/watch?v=VTDKqW_GLkw},
	urldate = {2023-01-16},
	author = {{Stand-up Maths}},
	month = apr,
	year = {2021},
}

@article{chauhan_stochastic_2020,
	title = {Stochastic {Trust} {Region} {Inexact} {Newton} {Method} for {Large}-scale {Machine} {Learning}},
	volume = {11},
	issn = {1868-8071, 1868-808X},
	url = {http://arxiv.org/abs/1812.10426},
	doi = {10.1007/s13042-019-01055-9},
	abstract = {Nowadays stochastic approximation methods are one of the major research direction to deal with the large-scale machine learning problems. From stochastic ﬁrst order methods, now the focus is shifting to stochastic second order methods due to their faster convergence and availability of computing resources. In this paper, we have proposed a novel Stochastic Trust RegiOn Inexact Newton method, called as STRON, to solve large-scale learning problems which uses conjugate gradient (CG) to inexactly solve trust region subproblem. The method uses progressive subsampling in the calculation of gradient and Hessian values to take the advantage of both, stochastic and full-batch regimes. We have extended STRON using existing variance reduction techniques to deal with the noisy gradients and using preconditioned conjugate gradient (PCG) as subproblem solver, and empirically proved that they do not work as expected, for the large-scale learning problems. Finally, our empirical results prove eﬃcacy of the proposed method against existing methods with bench marked datasets.},
	language = {en},
	number = {7},
	urldate = {2023-01-15},
	journal = {International Journal of Machine Learning and Cybernetics},
	author = {Chauhan, Vinod Kumar and Sharma, Anuj and Dahiya, Kalpana},
	month = jul,
	year = {2020},
	note = {arXiv:1812.10426 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {1541--1555},
	annote = {Comment: 32 figures, accepted in International Journal of Machine Learning and Cybernetics},
	file = {Chauhan e.a. - 2020 - Stochastic Trust Region Inexact Newton Method for .pdf:C\:\\Users\\Admin\\Zotero\\storage\\7YWNREP2\\Chauhan e.a. - 2020 - Stochastic Trust Region Inexact Newton Method for .pdf:application/pdf},
}

@misc{curtis_fully_2019,
	title = {A {Fully} {Stochastic} {Second}-{Order} {Trust} {Region} {Method}},
	url = {http://arxiv.org/abs/1911.06920},
	abstract = {A stochastic second-order trust region method is proposed, which can be viewed as a second-order extension of the trust-region-ish (TRish) algorithm proposed by Curtis et al. [INFORMS J. Optim. 1(3) 200–220, 2019]. In each iteration, a search direction is computed by (approximately) solving a trust region subproblem deﬁned by stochastic gradient and Hessian estimates. The algorithm has convergence guarantees for stochastic minimization in the fully stochastic regime, meaning that guarantees hold when each stochastic gradient is required merely to be an unbiased estimate of the true gradient with bounded variance and when the stochastic Hessian estimates are bounded uniformly in norm. The algorithm is also equipped with a worst-case complexity guarantee in the nearly deterministic regime, i.e., when the stochastic gradient and Hessian estimates are very close in expectation to the true gradients and Hessians. The results of numerical experiments for training convolutional neural networks for image classiﬁcation and training a recurrent neural network for time series forecasting are presented. These results show that the algorithm can outperform a stochastic gradient approach and the ﬁrst-order TRish algorithm in practice.},
	language = {en},
	urldate = {2023-01-15},
	publisher = {arXiv},
	author = {Curtis, Frank E. and Shi, Rui},
	month = nov,
	year = {2019},
	note = {arXiv:1911.06920 [math]},
	keywords = {Mathematics - Optimization and Control},
	file = {Curtis en Shi - 2019 - A Fully Stochastic Second-Order Trust Region Metho.pdf:C\:\\Users\\Admin\\Zotero\\storage\\3QTRRJEB\\Curtis en Shi - 2019 - A Fully Stochastic Second-Order Trust Region Metho.pdf:application/pdf},
}

@misc{fang_fully_2022,
	title = {Fully {Stochastic} {Trust}-{Region} {Sequential} {Quadratic} {Programming} for {Equality}-{Constrained} {Optimization} {Problems}},
	url = {http://arxiv.org/abs/2211.15943},
	abstract = {We propose a trust-region stochastic sequential quadratic programming algorithm (TR-StoSQP) to solve nonlinear optimization problems with stochastic objectives and deterministic equality constraints. We consider a fully stochastic setting, where in each iteration a single sample is generated to estimate the objective gradient. The algorithm adaptively selects the trust-region radius and, compared to the existing line-search StoSQP schemes, allows us to employ indeﬁnite Hessian matrices (i.e., Hessians without modiﬁcation) in SQP subproblems. As a trust-region method for constrained optimization, our algorithm needs to address an infeasibility issue—the linearized equality constraints and trust-region constraints might lead to infeasible SQP subproblems. In this regard, we propose an adaptive relaxation technique to compute the trial step that consists of a normal step and a tangential step. To control the lengths of the two steps, we adaptively decompose the trust-region radius into two segments based on the proportions of the feasibility and optimality residuals to the full KKT residual. The normal step has a closed form, while the tangential step is solved from a trust-region subproblem, to which a solution ensuring the Cauchy reduction is suﬃcient for our study. We establish the global almost sure convergence guarantee for TR-StoSQP, and illustrate its empirical performance on both a subset of problems in the CUTEst test set and constrained logistic regression problems using data from the LIBSVM collection.},
	language = {en},
	urldate = {2023-01-15},
	publisher = {arXiv},
	author = {Fang, Yuchen and Na, Sen and Mahoney, Michael W. and Kolar, Mladen},
	month = nov,
	year = {2022},
	note = {arXiv:2211.15943 [math, stat]},
	keywords = {Statistics - Computation, Statistics - Machine Learning, Mathematics - Optimization and Control},
	annote = {Comment: 6 figures, 28 pages},
	file = {Fang e.a. - 2022 - Fully Stochastic Trust-Region Sequential Quadratic.pdf:C\:\\Users\\Admin\\Zotero\\storage\\HIZ86IVL\\Fang e.a. - 2022 - Fully Stochastic Trust-Region Sequential Quadratic.pdf:application/pdf},
}

@article{wang_stochastic_2022,
	title = {Stochastic {Trust} {Region} {Methods} with {Trust} {Region} {Radius} {Depending} on {Probabilistic} {Models}},
	volume = {40},
	issn = {0254-9409, 1991-7139},
	url = {http://arxiv.org/abs/1904.03342},
	doi = {10.4208/jcm.2012-m2020-0144},
	abstract = {We present a stochastic trust-region model-based framework in which its radius is related to the probabilistic models. Especially, we propose a speciﬁc algorithm, termed STRME, in which the trust-region radius depends linearly on the latest model gradient. The complexity of STRME method in non-convex, convex and strongly convex settings has all been analyzed, which matches the existing algorithms based on probabilistic properties. In addition, several numerical experiments are carried out to reveal the beneﬁts of the proposed methods compared to the existing stochastic trust-region methods and other relevant stochastic gradient methods.},
	language = {en},
	number = {2},
	urldate = {2023-01-15},
	journal = {Journal of Computational Mathematics},
	author = {Wang, Xiaoyu and Yuan, Ya-xiang},
	month = jun,
	year = {2022},
	note = {arXiv:1904.03342 [math]},
	keywords = {Mathematics - Optimization and Control, 65K05, 65K10, 90C60},
	pages = {295--336},
	file = {Wang en Yuan - 2022 - Stochastic Trust Region Methods with Trust Region .pdf:C\:\\Users\\Admin\\Zotero\\storage\\78W97RZH\\Wang en Yuan - 2022 - Stochastic Trust Region Methods with Trust Region .pdf:application/pdf},
}

@misc{fu_convergence_2022,
	title = {Convergence analysis of a quasi-{Monte} {Carlo}-based deep learning algorithm for solving partial differential equations},
	url = {http://arxiv.org/abs/2210.16196},
	abstract = {Deep learning methods have achieved great success in solving partial diﬀerential equations (PDEs), where the loss is often deﬁned as an integral. The accuracy and eﬃciency of these algorithms depend greatly on the quadrature method. We propose to apply quasi-Monte Carlo (QMC) methods to the Deep Ritz Method (DRM) for solving the Neumann problems for the Poisson equation and the static Schr¨odinger equation. For error estimation, we decompose the error of using the deep learning algorithm to solve PDEs into the generalization error, the approximation error and the training error. We establish the upper bounds and prove that QMC-based DRM achieves an asymptotically smaller error bound than DRM. Numerical experiments show that the proposed method converges faster in all cases and the variances of the gradient estimators of randomized QMC-based DRM are much smaller than those of DRM, which illustrates the superiority of QMC in deep learning over MC.},
	language = {en},
	urldate = {2023-01-14},
	publisher = {arXiv},
	author = {Fu, Fengjiang and Wang, Xiaoqun},
	month = oct,
	year = {2022},
	note = {arXiv:2210.16196 [cs, math]},
	keywords = {Mathematics - Numerical Analysis, Computer Science - Machine Learning, 35J20, 35Q68, 65D30, 65N15, 68T07},
	annote = {Comment: 27 pages, 4 figures, 2 tables},
	file = {Fu en Wang - 2022 - Convergence analysis of a quasi-Monte Carlo-based .pdf:C\:\\Users\\Admin\\Zotero\\storage\\SAFYTMXD\\Fu en Wang - 2022 - Convergence analysis of a quasi-Monte Carlo-based .pdf:application/pdf},
}

@misc{leluc_quadrature_2022,
	title = {A {Quadrature} {Rule} combining {Control} {Variates} and {Adaptive} {Importance} {Sampling}},
	url = {http://arxiv.org/abs/2205.11890},
	abstract = {Driven by several successful applications such as in stochastic gradient descent or in Bayesian computation, control variates have become a major tool for Monte Carlo integration. However, standard methods do not allow the distribution of the particles to evolve during the algorithm, as is the case in sequential simulation methods. Within the standard adaptive importance sampling framework, a simple weighted least squares approach is proposed to improve the procedure with control variates. The procedure takes the form of a quadrature rule with adapted quadrature weights to reﬂect the information brought in by the control variates. The quadrature points and weights do not depend on the integrand, a computational advantage in case of multiple integrands. Moreover, the target density needs to be known only up to a multiplicative constant. Our main result is a non-asymptotic bound on the probabilistic error of the procedure. The bound proves that for improving the estimate’s accuracy, the beneﬁts from adaptive importance sampling and control variates can be combined. The good behavior of the method is illustrated empirically on synthetic examples and real-world data for Bayesian linear regression.},
	language = {en},
	urldate = {2023-01-14},
	publisher = {arXiv},
	author = {Leluc, Rémi and Portier, François and Segers, Johan and Zhuman, Aigerim},
	month = oct,
	year = {2022},
	note = {arXiv:2205.11890 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Statistics Theory},
	file = {Leluc e.a. - 2022 - A Quadrature Rule combining Control Variates and A.pdf:C\:\\Users\\Admin\\Zotero\\storage\\BVHY6BXX\\Leluc e.a. - 2022 - A Quadrature Rule combining Control Variates and A.pdf:application/pdf},
}

@incollection{billaud-friess_stochastic_2020,
	title = {Stochastic methods for solving high-dimensional partial differential equations},
	volume = {324},
	url = {http://arxiv.org/abs/1905.05423},
	abstract = {We propose algorithms for solving high-dimensional Partial Diﬀerential Equations (PDEs) that combine a probabilistic interpretation of PDEs, through Feynman-Kac representation, with sparse interpolation. Monte-Carlo methods and time-integration schemes are used to estimate pointwise evaluations of the solution of a PDE. We use a sequential control variates algorithm, where control variates are constructed based on successive approximations of the solution of the PDE. Two diﬀerent algorithms are proposed, combining in diﬀerent ways the sequential control variates algorithm and adaptive sparse interpolation. Numerical examples will illustrate the behavior of these algorithms.},
	language = {en},
	urldate = {2023-01-14},
	author = {Billaud-Friess, Marie and Macherey, Arthur and Nouy, Anthony and Prieur, Clémentine},
	year = {2020},
	doi = {10.1007/978-3-030-43465-6_6},
	note = {arXiv:1905.05423 [math]},
	keywords = {Mathematics - Numerical Analysis},
	pages = {125--141},
	file = {Billaud-Friess e.a. - 2020 - Stochastic methods for solving high-dimensional pa.pdf:C\:\\Users\\Admin\\Zotero\\storage\\9PRXYL9X\\Billaud-Friess e.a. - 2020 - Stochastic methods for solving high-dimensional pa.pdf:application/pdf},
}

@article{kutz_spectral_2017,
	title = {Spectral and decomposition tracking for rendering heterogeneous volumes},
	volume = {36},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/3072959.3073665},
	doi = {10.1145/3072959.3073665},
	abstract = {We present two novel unbiased techniques for sampling free paths in heterogeneous participating media. Our
              decomposition tracking
              accelerates free-path construction by splitting the medium into a control component and a residual component and sampling each of them separately. To minimize expensive evaluations of spatially varying collision coefficients, we define the control component to allow constructing free paths in closed form. The residual heterogeneous component is then homogenized by adding a fictitious medium and handled using weighted delta tracking, which removes the need for computing strict bounds of the extinction function. Our second contribution,
              spectral tracking
              , enables efficient light transport simulation in chromatic media. We modify free-path distributions to minimize the fluctuation of path throughputs and thereby reduce the estimation variance. To demonstrate the correctness of our algorithms, we derive them
              directly
              from the radiative transfer equation by extending the integral formulation of null-collision algorithms recently developed in reactor physics. This mathematical framework, which we thoroughly review, encompasses existing trackers and postulates an entire family of new estimators for solving transport problems; our algorithms are examples of such. We analyze the proposed methods in canonical settings and on production scenes, and compare to the current state of the art in simulating light transport in heterogeneous participating media.},
	language = {en},
	number = {4},
	urldate = {2023-01-12},
	journal = {ACM Transactions on Graphics},
	author = {Kutz, Peter and Habel, Ralf and Li, Yining Karl and Novák, Jan},
	month = aug,
	year = {2017},
	pages = {1--16},
	file = {Kutz e.a. - 2017 - Spectral and decomposition tracking for rendering .pdf:C\:\\Users\\Admin\\Zotero\\storage\\49PCP84W\\Kutz e.a. - 2017 - Spectral and decomposition tracking for rendering .pdf:application/pdf},
}

@article{galtier_integral_2013,
	title = {Integral formulation of null-collision {Monte} {Carlo} algorithms},
	volume = {125},
	issn = {00224073},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022407313001350},
	doi = {10.1016/j.jqsrt.2013.04.001},
	abstract = {At the kinetic level, the meaning of null-collisions is straightforward: they correspond to pureforward scattering events. We here discuss their technical signiﬁcance in integral terms. We ﬁrst consider a most standard null-collision Monte Carlo algorithm and show how it can be rigorously justiﬁed starting from a Fredholm equivalent to the radiative transfer equation. Doing so, we also prove that null-collision algorithms can be slightly modiﬁed so that they deal with unexpected occurrences of negative values of the null-collision coeﬃcient (when the upper bound of the heterogeneous extinction coeﬃcient is nonstrict). We then describe technically, in full details, the resulting algorithm, when applied to the evaluation of the local net-power density within a bounded, heterogeneous, multiple scattering and emitting/absorbing medium. The corresponding integral formulation is then explored theoretically in order to distinguish the statistical signiﬁcance of introducing null-collisions from that of the integral-structure underlying modiﬁcation.},
	language = {en},
	urldate = {2023-01-12},
	journal = {Journal of Quantitative Spectroscopy and Radiative Transfer},
	author = {Galtier, M. and Blanco, S. and Caliot, C. and Coustet, C. and Dauchet, J. and El Hafi, M. and Eymet, V. and Fournier, R. and Gautrais, J. and Khuong, A. and Piaud, B. and Terrée, G.},
	month = aug,
	year = {2013},
	pages = {57--68},
	file = {Galtier e.a. - 2013 - Integral formulation of null-collision Monte Carlo.pdf:C\:\\Users\\Admin\\Zotero\\storage\\7WE6YFYN\\Galtier e.a. - 2013 - Integral formulation of null-collision Monte Carlo.pdf:application/pdf},
}

@misc{noauthor_bakercampbellhausdorff_2022-1,
	title = {Baker–{Campbell}–{Hausdorff} formula},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Baker%E2%80%93Campbell%E2%80%93Hausdorff_formula&oldid=1115922051},
	abstract = {In mathematics, the Baker–Campbell–Hausdorff formula is the solution for 
  
    
      
        Z
      
    
    \{{\textbackslash}displaystyle Z\}
   to the equation

for possibly noncommutative X and Y in the Lie algebra of a Lie group. There are various ways of writing the formula, but all ultimately yield an expression for 
  
    
      
        Z
      
    
    \{{\textbackslash}displaystyle Z\}
   in Lie algebraic terms, that is, as a formal series (not necessarily convergent) in 
  
    
      
        X
      
    
    \{{\textbackslash}displaystyle X\}
   and 
  
    
      
        Y
      
    
    \{{\textbackslash}displaystyle Y\}
   and iterated commutators thereof. The first few terms of this series are:

where "
  
    
      
        ⋯
      
    
    \{{\textbackslash}displaystyle {\textbackslash}cdots \}
  " indicates terms involving higher commutators of 
  
    
      
        X
      
    
    \{{\textbackslash}displaystyle X\}
   and 
  
    
      
        Y
      
    
    \{{\textbackslash}displaystyle Y\}
  . If 
  
    
      
        X
      
    
    \{{\textbackslash}displaystyle X\}
   and 
  
    
      
        Y
      
    
    \{{\textbackslash}displaystyle Y\}
   are sufficiently small elements of the Lie algebra 
  
    
      
        
          
            g
          
        
      
    
    \{{\textbackslash}displaystyle \{{\textbackslash}mathfrak \{g\}\}\}
   of a Lie group 
  
    
      
        G
      
    
    \{{\textbackslash}displaystyle G\}
  , the series is convergent. Meanwhile, every element 
  
    
      
        g
      
    
    \{{\textbackslash}displaystyle g\}
   sufficiently close to the identity in 
  
    
      
        G
      
    
    \{{\textbackslash}displaystyle G\}
   can be expressed as 
  
    
      
        g
        =
        
          e
          
            X
          
        
      
    
    \{{\textbackslash}displaystyle g=e{\textasciicircum}\{X\}\}
   for a small 
  
    
      
        X
      
    
    \{{\textbackslash}displaystyle X\}
   in 
  
    
      
        
          
            g
          
        
      
    
    \{{\textbackslash}displaystyle \{{\textbackslash}mathfrak \{g\}\}\}
  . Thus, we can say that near the identity the group multiplication in 
  
    
      
        G
      
    
    \{{\textbackslash}displaystyle G\}
  —written as 
  
    
      
        
          e
          
            X
          
        
        
          e
          
            Y
          
        
        =
        
          e
          
            Z
          
        
      
    
    \{{\textbackslash}displaystyle e{\textasciicircum}\{X\}e{\textasciicircum}\{Y\}=e{\textasciicircum}\{Z\}\}
  —can be expressed in purely Lie algebraic terms. The Baker–Campbell–Hausdorff formula can be used to give comparatively simple proofs of deep results in the Lie group–Lie algebra correspondence.
If 
  
    
      
        X
      
    
    \{{\textbackslash}displaystyle X\}
   and 
  
    
      
        Y
      
    
    \{{\textbackslash}displaystyle Y\}
   are sufficiently small 
  
    
      
        n
        ×
        n
      
    
    \{{\textbackslash}displaystyle n{\textbackslash}times n\}
   matrices, then 
  
    
      
        Z
      
    
    \{{\textbackslash}displaystyle Z\}
   can be computed as the logarithm of 
  
    
      
        
          e
          
            X
          
        
        
          e
          
            Y
          
        
      
    
    \{{\textbackslash}displaystyle e{\textasciicircum}\{X\}e{\textasciicircum}\{Y\}\}
  , where the exponentials and the logarithm can be computed as power series. The point of the Baker–Campbell–Hausdorff formula is then the highly nonobvious claim that 
  
    
      
        Z
        :=
        log
        ⁡
        
          (
          
            
              e
              
                X
              
            
            
              e
              
                Y
              
            
          
          )
        
      
    
    \{{\textbackslash}displaystyle Z:={\textbackslash}log {\textbackslash}left(e{\textasciicircum}\{X\}e{\textasciicircum}\{Y\}{\textbackslash}right)\}
   can be expressed as a series in repeated commutators of 
  
    
      
        X
      
    
    \{{\textbackslash}displaystyle X\}
   and 
  
    
      
        Y
      
    
    \{{\textbackslash}displaystyle Y\}
  .
Modern expositions of the formula can be found in, among other places, the books of Rossmann and Hall.},
	language = {en},
	urldate = {2023-01-12},
	journal = {Wikipedia},
	month = oct,
	year = {2022},
	note = {Page Version ID: 1115922051},
}

@article{vaibhav_efficient_2019,
	title = {Efficient {Nonlinear} {Fourier} {Transform} {Algorithms} of {Order} {Four} on {Equispaced} {Grid}},
	volume = {31},
	issn = {1041-1135, 1941-0174},
	url = {http://arxiv.org/abs/1903.11702},
	doi = {10.1109/LPT.2019.2925052},
	abstract = {We explore two classes of exponential integrators in this letter to design nonlinear Fourier transform (NFT) algorithms with a desired accuracy-complexity trade-off and a convergence order of 4 on an equispaced grid. The integrating factor based method in the class of Runge-Kutta methods yield algorithms with complexity O(N log2 N) (where N is the number of samples of the signal) which have superior accuracy-complexity trade-off than any of the fast methods known currently. The integrators based on Magnus series expansion, namely, standard and commutator-free Magnus methods yield algorithms of complexity O(N2) that have superior error behavior even for moderately small step-sizes and higher signal strengths.},
	language = {en},
	number = {15},
	urldate = {2023-01-12},
	journal = {IEEE Photonics Technology Letters},
	author = {Vaibhav, Vishal},
	month = aug,
	year = {2019},
	note = {arXiv:1903.11702 [physics]},
	keywords = {Mathematics - Numerical Analysis, Physics - Computational Physics},
	pages = {1269--1272},
	annote = {Comment: 4 pages},
	file = {Vaibhav - 2019 - Efficient Nonlinear Fourier Transform Algorithms o.pdf:C\:\\Users\\Admin\\Zotero\\storage\\Y6ZICUXL\\Vaibhav - 2019 - Efficient Nonlinear Fourier Transform Algorithms o.pdf:application/pdf},
}

@misc{noauthor_magnus_2022,
	title = {Magnus expansion},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Magnus_expansion&oldid=1117728056},
	abstract = {In mathematics and physics, the Magnus expansion, named after Wilhelm Magnus (1907–1990), provides an exponential representation of the solution of a first-order homogeneous linear differential equation for a linear operator. In particular, it furnishes the fundamental matrix of a system of linear ordinary differential equations of order n with varying coefficients. The exponent is aggregated as an infinite series, whose terms involve multiple integrals and nested commutators.},
	language = {en},
	urldate = {2023-01-12},
	journal = {Wikipedia},
	month = oct,
	year = {2022},
	note = {Page Version ID: 1117728056},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\WKBPK8ZV\\Magnus_expansion.html:text/html},
}

@article{akhtar_solving_2015,
	title = {{SOLVING} {INITIAL} {VALUE} {ORDINARY} {DIFFERENTIAL} {EQUATIONS} {BY} {MONTE} {CARLO} {METHOD}},
	abstract = {The objective of this paper is to perform a computational analysis of an existing Monte Carlo based algorithm to solve initial value problem of ordinary differential equations (ODEs). Firstly the problems associated with the existing algorithm have been rectified by suggesting a new elaborate algorithm. Then the new algorithm has been applied to solve different types of ODEs including simple, explicit coupled, implicit and coupled system of first order ODEs. Furthermore the same has also been implemented to known physical systems such as Van der Pol equation and SIR epidemic model. The limitations of proposed algorithm have also been identified by applying Lipschitz continuity check for an exemplary ODE. Finally it has been demonstrated that it still very difficult to propose a computationally efficient algorithm to solve ODEs with considerable accuracy using Monte Carlo method.},
	language = {en},
	author = {Akhtar, Muhammad Naveed and Durad, Muhammad Hanif and Ahmed, Asad},
	year = {2015},
	file = {Akhtar e.a. - 2015 - SOLVING INITIAL VALUE ORDINARY DIFFERENTIAL EQUATI.pdf:C\:\\Users\\Admin\\Zotero\\storage\\WTUKCBSR\\Akhtar e.a. - 2015 - SOLVING INITIAL VALUE ORDINARY DIFFERENTIAL EQUATI.pdf:application/pdf},
}

@misc{gupta_convergence_2021,
	title = {Convergence of {Recursive} {Stochastic} {Algorithms} using {Wasserstein} {Divergence}},
	url = {http://arxiv.org/abs/2003.11403},
	abstract = {This paper develops a uniﬁed framework, based on iterated random operator theory, to analyze the convergence of constant stepsize recursive stochastic algorithms (RSAs). RSAs use randomization to eﬃciently compute expectations, and so their iterates form a stochastic process. The key idea of our analysis is to lift the RSA into an appropriate higher-dimensional space and then express it as an equivalent Markov chain. Instead of determining the convergence of this Markov chain (which may not converge under constant stepsize), we study the convergence of the distribution of this Markov chain. To study this, we deﬁne a new notion of Wasserstein divergence. We show that if the distribution of the iterates in the Markov chain satisfy a contraction property with respect to the Wasserstein divergence, then the Markov chain admits an invariant distribution. We show that convergence of a large family of constant stepsize RSAs can be understood using this framework, and we provide several detailed examples.},
	language = {en},
	urldate = {2023-01-11},
	publisher = {arXiv},
	author = {Gupta, Abhishek and Haskell, William B.},
	month = jan,
	year = {2021},
	note = {arXiv:2003.11403 [cs, eess, math, stat]},
	keywords = {Mathematics - Probability, Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control, 93E35, 60J20, 68Q32, Electrical Engineering and Systems Science - Systems and Control},
	annote = {Comment: 34 pages, submitted to SIMODS},
	file = {Gupta en Haskell - 2021 - Convergence of Recursive Stochastic Algorithms usi.pdf:C\:\\Users\\Admin\\Zotero\\storage\\IAT28HNB\\Gupta en Haskell - 2021 - Convergence of Recursive Stochastic Algorithms usi.pdf:application/pdf},
}

@misc{abhishek_gupta_recursive_2020,
	title = {Recursive {Stochastic} {Algorithms}: {A} {Markov} {Chain} {Perspective}},
	shorttitle = {Recursive {Stochastic} {Algorithms}},
	url = {https://www.youtube.com/watch?v=f1IP6rpqaEE},
	abstract = {Creative Commons Attribution license (reuse allowed)},
	urldate = {2023-01-11},
	author = {{Abhishek Gupta}},
	month = oct,
	year = {2020},
}

@article{zinkevich_parallelized_nodate,
	title = {Parallelized {Stochastic} {Gradient} {Descent}},
	abstract = {With the increase in available data parallel machine learning has become an increasingly pressing problem. In this paper we present the ﬁrst parallel stochastic gradient descent algorithm including a detailed analysis and experimental evidence. Unlike prior work on parallel optimization algorithms [5, 7] our variant comes with parallel acceleration guarantees and it poses no overly tight latency constraints, which might only be available in the multicore setting. Our analysis introduces a novel proof technique — contractive mappings to quantify the speed of convergence of parameter distributions to their asymptotic limits. As a side effect this answers the question of how quickly stochastic gradient descent algorithms reach the asymptotically normal regime [1, 8].},
	language = {en},
	author = {Zinkevich, Martin A and Smola, Alex and Weimer, Markus and Li, Lihong},
	file = {Zinkevich e.a. - Parallelized Stochastic Gradient Descent.pdf:C\:\\Users\\Admin\\Zotero\\storage\\7SDXTQBD\\Zinkevich e.a. - Parallelized Stochastic Gradient Descent.pdf:application/pdf},
}

@misc{mohamad_scaling_2022,
	title = {Scaling up {Stochastic} {Gradient} {Descent} for {Non}-convex {Optimisation}},
	url = {http://arxiv.org/abs/2210.02882},
	abstract = {Stochastic gradient descent (SGD) is a widely adopted iterative method for optimizing differentiable objective functions. In this paper, we propose and discuss a novel approach to scale up SGD in applications involving non-convex functions and large datasets. We address the bottleneck problem arising when using both shared and distributed memory. Typically, the former is bounded by limited computation resources and bandwidth whereas the latter suffers from communication overheads. We propose a uniﬁed distributed and parallel implementation of SGD (named DPSGD) that relies on both asynchronous distribution and lock-free parallelism. By combining two strategies into a uniﬁed framework, DPSGD is able to strike a better trade-off between local computation and communication. The convergence properties of DPSGD are studied for non-convex problems such as those arising in statistical modelling and machine learning. Our theoretical analysis shows that DPSGD leads to speed-up with respect to the number of cores a√nd number of workers while guaranteeing an asymptotic convergence rate of O(1/ T ) given that the number of cores is bounded by T 1/4 and the number of workers is bounded by T 1/2 where T is the number of iterations. The potential gains that can be achieved by DPSGD are demonstrated empirically on a stochastic variational inference problem (Latent Dirichlet Allocation) and on a deep reinforcement learning (DRL) problem (advantage actor critic - A2C) resulting in two algorithms: DPSVI and HSA2C. Empirical results validate our theoretical ﬁndings. Comparative studies are conducted to show the performance of the proposed DPSGD against the state-of-the-art DRL algorithms.},
	language = {en},
	urldate = {2023-01-11},
	publisher = {arXiv},
	author = {Mohamad, Saad and Alamri, Hamad and Bouchachia, Abdelhamid},
	month = oct,
	year = {2022},
	note = {arXiv:2210.02882 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Distributed, Parallel, and Cluster Computing, Mathematics - Optimization and Control},
	file = {Mohamad e.a. - 2022 - Scaling up Stochastic Gradient Descent for Non-con.pdf:C\:\\Users\\Admin\\Zotero\\storage\\UJS9IZZ9\\Mohamad e.a. - 2022 - Scaling up Stochastic Gradient Descent for Non-con.pdf:application/pdf},
}

@misc{he_accelerating_2022,
	title = {Accelerating {Parallel} {Stochastic} {Gradient} {Descent} via {Non}-blocking {Mini}-batches},
	url = {http://arxiv.org/abs/2211.00889},
	abstract = {SOTA decentralized SGD algorithms can overcome the bandwidth bottleneck at the parameter server by using communication collectives like Ring All-Reduce for synchronization. While the parameter updates in distributed SGD may happen asynchronously there is still a synchronization barrier to make sure that the local training epoch at every learner is complete before the learners can advance to the next epoch. The delays in waiting for the slowest learners(stragglers) remain to be a problem in the synchronization steps of these state-of-the-art decentralized frameworks. In this paper, we propose the (de)centralized Non-blocking SGD (Non-blocking SGD) which can address the straggler problem in a heterogeneous environment. The main idea of Non-blocking SGD is to split the original batch into mini-batches, then accumulate the gradients and update the model based on ﬁnished mini-batches. The Non-blocking idea can be implemented using decentralized algorithms including Ring All-reduce, D-PSGD, and MATCHA to solve the straggler problem. Moreover, using gradient accumulation to update the model also guarantees convergence and avoids gradient staleness. Run-time analysis with random straggler delays and computational efﬁciency/throughput of devices is also presented to show the advantage of Non-blocking SGD. Experiments on a suite of datasets and deep learning networks validate the theoretical analyses and demonstrate that Non-blocking SGD speeds up the training and fastens the convergence. Compared with the state-of-the-art decentralized asynchronous algorithms like D-PSGD and MACHA, Non-blocking SGD takes up to 2x fewer time to reach the same training loss in a heterogeneous environment.},
	language = {en},
	urldate = {2023-01-11},
	publisher = {arXiv},
	author = {He, Haoze and Dube, Parijat},
	month = nov,
	year = {2022},
	note = {arXiv:2211.00889 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Distributed, Parallel, and Cluster Computing},
	annote = {Comment: 12 pages, 4 figures},
	file = {He en Dube - 2022 - Accelerating Parallel Stochastic Gradient Descent .pdf:C\:\\Users\\Admin\\Zotero\\storage\\5TLNEYY3\\He en Dube - 2022 - Accelerating Parallel Stochastic Gradient Descent .pdf:application/pdf},
}

@misc{carmon_resqueing_2023,
	title = {{ReSQueing} {Parallel} and {Private} {Stochastic} {Convex} {Optimization}},
	url = {http://arxiv.org/abs/2301.00457},
	abstract = {We introduce a new tool for stochastic convex optimization (SCO): a Reweighted Stochastic Query (ReSQue) estimator for the gradient of a function convolved with a (Gaussian) probability density. Combining ReSQue with recent advances in ball oracle acceleration [CJJ+20, ACJ+21], we develop algorithms achieving state-of-the-art complexities for SCO in parallel and private settings. For a SCO objective constrained to the unit ball in Rd, we obtain the following results (up to polylogarithmic factors).},
	language = {en},
	urldate = {2023-01-11},
	publisher = {arXiv},
	author = {Carmon, Yair and Jambulapati, Arun and Jin, Yujia and Lee, Yin Tat and Liu, Daogao and Sidford, Aaron and Tian, Kevin},
	month = jan,
	year = {2023},
	note = {arXiv:2301.00457 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control, Computer Science - Cryptography and Security, Computer Science - Data Structures and Algorithms},
	file = {Carmon e.a. - 2023 - ReSQueing Parallel and Private Stochastic Convex O.pdf:C\:\\Users\\Admin\\Zotero\\storage\\JDNVG82B\\Carmon e.a. - 2023 - ReSQueing Parallel and Private Stochastic Convex O.pdf:application/pdf},
}

@misc{ostrovsky_unbiased_2014,
	title = {Unbiased {Monte} {Carlo} estimation for solving of linear integral equation, with error estimate},
	url = {http://arxiv.org/abs/1408.4205},
	abstract = {We oﬀer a new Monte-Carlo method for solving linear integral equation which gives the unbiased estimation for solution of Volterra’s and Fredholm’s type, and consider the problem of conﬁdence region building.},
	language = {en},
	urldate = {2023-01-10},
	publisher = {arXiv},
	author = {Ostrovsky, E. and Sirota, L.},
	month = aug,
	year = {2014},
	note = {arXiv:1408.4205 [math]},
	keywords = {Mathematics - Numerical Analysis},
	file = {Ostrovsky en Sirota - 2014 - Unbiased Monte Carlo estimation for solving of lin.pdf:C\:\\Users\\Admin\\Zotero\\storage\\UBUR3CE9\\Ostrovsky en Sirota - 2014 - Unbiased Monte Carlo estimation for solving of lin.pdf:application/pdf},
}

@article{yang_new_2021,
	title = {A {New} {Fast} {Monte} {Carlo} {Code} for {Solving} {Radiative} {Transfer} {Equations} based on {Neumann} {Solution}},
	volume = {254},
	issn = {0067-0049, 1538-4365},
	url = {http://arxiv.org/abs/2104.07007},
	doi = {10.3847/1538-4365/abec73},
	abstract = {In this paper, we proposed a new Monte Carlo radiative transport (MCRT) scheme, which is based completely on the Neumann series solution of Fredholm integral equation. This scheme indicates that the essence of MCRT is the calculation of inﬁnite terms of multiple integrals in Neumann solution simultaneously. Under this perspective we redescribed MCRT procedure systematically, in which the main work amounts to choose an associated probability distribution function (PDF) for a set of random variables and the corresponding unbiased estimation functions. We can select a relatively optimal estimation procedure that has a lower variance from an inﬁnite possible choices, such as the term by term estimation. In this scheme, MCRT can be regarded as a pure problem of integral evaluation, rather than as the tracing of random walking photons. Keeping this in mind, one can avert some subtle intuitive mistakes. In addition the δ-functions in these integrals can be eliminated in advance by integrating them out directly. This fact together with the optimal chosen random variables can remarkably improve the Monte Carlo (MC) computational eﬃciency and accuracy, especially in systems with axial or spherical symmetry. An MCRT code, Lemona(Linear Integral Equations’ Monte Carlo Solver Based on the Neumann solution), has been developed completely based on this scheme. Finally, we intend to verify the validation of Lemon, a suite of test problems mainly restricted to ﬂat spacetime have been reproduced and the corresponding results are illustrated in detail.},
	language = {en},
	number = {2},
	urldate = {2023-01-10},
	journal = {The Astrophysical Journal Supplement Series},
	author = {Yang, Xiao-lin and Wang, Jian-cheng and Yang, Chu-yuan},
	month = jun,
	year = {2021},
	note = {arXiv:2104.07007 [astro-ph, physics:physics]},
	keywords = {Physics - Computational Physics, Astrophysics - High Energy Astrophysical Phenomena},
	pages = {29},
	annote = {Comment: 37 pages, 28 figures. The code can be download from: https://github.com/yangxiaolinyn/Lemon (or https://bitbucket.org/yangxiaolinsc/lemonsourcecode/src/main/) and https://doi.org/10.5281/zenodo.4686355. Comments are welcome},
	file = {2104.07007.pdf:C\:\\Users\\Admin\\Zotero\\storage\\5R9X8WF9\\2104.07007.pdf:application/pdf},
}

@misc{gopalakrishna_note_2021,
	title = {A note on {Fredholm} integral equation},
	url = {http://arxiv.org/abs/2106.07194},
	abstract = {This note gives results on the existence of semi-continuous solutions of a Fredholm integral equation of the second kind using Tarski’s ﬁxed point theorem.},
	language = {en},
	urldate = {2023-01-10},
	publisher = {arXiv},
	author = {Gopalakrishna, Chaitanya},
	month = jun,
	year = {2021},
	note = {arXiv:2106.07194 [math]},
	keywords = {Mathematics - Analysis of PDEs, 45B05, 47H10, 06B23, Mathematics - Rings and Algebras},
	annote = {Comment: 7 pages},
	file = {Gopalakrishna - 2021 - A note on Fredholm integral equation.pdf:C\:\\Users\\Admin\\Zotero\\storage\\BF5MEFDI\\Gopalakrishna - 2021 - A note on Fredholm integral equation.pdf:application/pdf},
}

@misc{keller_integral_2019,
	title = {Integral {Equations} and {Machine} {Learning}},
	url = {http://arxiv.org/abs/1712.06115},
	abstract = {As both light transport simulation and reinforcement learning are ruled by the same Fredholm integral equation of the second kind, reinforcement learning techniques may be used for photorealistic image synthesis: Eﬃciency may be dramatically improved by guiding light transport paths by an approximate solution of the integral equation that is learned during rendering. In the light of the recent advances in reinforcement learning for playing games, we investigate the representation of an approximate solution of an integral equation by artiﬁcial neural networks and derive a loss function for that purpose. The resulting Monte Carlo and quasi-Monte Carlo methods train neural networks with standard information instead of linear information and naturally are able to generate an arbitrary number of training samples. The methods are demonstrated for applications in light transport simulation.},
	language = {en},
	urldate = {2023-01-10},
	publisher = {arXiv},
	author = {Keller, Alexander and Dahm, Ken},
	month = jan,
	year = {2019},
	note = {arXiv:1712.06115 [cs]},
	keywords = {Computer Science - Graphics, Computer Science - Machine Learning},
	file = {Keller en Dahm - 2019 - Integral Equations and Machine Learning.pdf:C\:\\Users\\Admin\\Zotero\\storage\\Q43J8XEA\\Keller en Dahm - 2019 - Integral Equations and Machine Learning.pdf:application/pdf},
}

@misc{crucinio_particle_2021,
	title = {A {Particle} {Method} for {Solving} {Fredholm} {Equations} of the {First} {Kind}},
	url = {http://arxiv.org/abs/2009.09974},
	abstract = {Fredholm integral equations of the ﬁrst kind are the prototypical example of ill-posed linear inverse problems. They model, among other things, reconstruction of distorted noisy observations and indirect density estimation and also appear in instrumental variable regression. However, their numerical solution remains a challenging problem. Many techniques currently available require a preliminary discretization of the domain of the solution and make strong assumptions about its regularity. For example, the popular expectation maximization smoothing (EMS) scheme requires the assumption of piecewise constant solutions which is inappropriate for most applications. We propose here a novel particle method that circumvents these two issues. This algorithm can be thought of as a Monte Carlo approximation of the EMS scheme which not only performs an adaptive stochastic discretization of the domain but also results in smooth approximate solutions. We analyze the theoretical properties of the EMS iteration and of the corresponding particle algorithm. Compared to standard EMS, we show experimentally that our novel particle method provides state-of-the-art performance for realistic systems, including motion deblurring and reconstruction of cross-section images of the brain from positron emission tomography.},
	language = {en},
	urldate = {2023-01-10},
	publisher = {arXiv},
	author = {Crucinio, Francesca R. and Doucet, Arnaud and Johansen, Adam M.},
	month = apr,
	year = {2021},
	note = {arXiv:2009.09974 [stat]},
	keywords = {Statistics - Computation, Statistics - Methodology},
	file = {Crucinio e.a. - 2021 - A Particle Method for Solving Fredholm Equations o.pdf:C\:\\Users\\Admin\\Zotero\\storage\\HMHHAWGP\\Crucinio e.a. - 2021 - A Particle Method for Solving Fredholm Equations o.pdf:application/pdf},
}

@misc{schneider_itvolt_2022,
	title = {{ITVOLT}: {An} {Iterative} {Solver} for {Volterra} {Integral} {Equations} with {Application} to the {Time}-{Dependent} {Schr}{\textbackslash}"odinger {Equation}},
	shorttitle = {{ITVOLT}},
	url = {http://arxiv.org/abs/2210.15677},
	abstract = {We present a novel iterative method for solving Volterra integral equations of the second kind. Based on global Lagrange interpolation, the method is simple to implement and applicable to a wide variety of problems. Here, we present the method in detail and discuss several applications, emphasizing in particular its use on the time-dependent Schro¨dinger equation.},
	language = {en},
	urldate = {2023-01-10},
	publisher = {arXiv},
	author = {Schneider, Ryan and Gharibnejad, Heman and Schneider, Barry I.},
	month = oct,
	year = {2022},
	note = {arXiv:2210.15677 [physics]},
	keywords = {Mathematics - Numerical Analysis, Physics - Computational Physics, 45D05, 65F10, 65D32},
	annote = {Comment: 20 pages, 9 tables, 5 figures},
	file = {Schneider e.a. - 2022 - ITVOLT An Iterative Solver for Volterra Integral .pdf:C\:\\Users\\Admin\\Zotero\\storage\\VKU8FNSZ\\Schneider e.a. - 2022 - ITVOLT An Iterative Solver for Volterra Integral .pdf:application/pdf},
}

@misc{azze_optimal_2022-1,
	title = {Optimal exercise of {American} options under time-dependent {Ornstein}-{Uhlenbeck} processes},
	url = {http://arxiv.org/abs/2211.04095},
	abstract = {We study the barrier that gives the optimal time to exercise an American option written on a time-dependent Ornstein–Uhlenbeck process, a diﬀusion often adopted by practitioners to model commodity prices and interest rates. By framing the optimal exercise of the American option as a problem of optimal stopping and relying on probabilistic arguments, we provide a non-linear Volterra-type integral equation characterizing the exercise boundary, develop a novel comparison argument to derive upper and lower bounds for such a boundary, and prove its diﬀerentiability and Lipschitz continuity in any closed interval that excludes the expiration date. We implement a Picard iteration algorithm to solve the Volterra integral equation and show illustrative examples that shed light on the boundary’s dependence on the process’s drift and volatility.},
	language = {en},
	urldate = {2023-01-10},
	publisher = {arXiv},
	author = {Azze, Abel and D'Auria, Bernardo and García-Portugués, Eduardo},
	month = nov,
	year = {2022},
	note = {arXiv:2211.04095 [math, q-fin]},
	keywords = {Mathematics - Probability, Quantitative Finance - Pricing of Securities, Quantitative Finance - Mathematical Finance, 60G40, 60J60},
	annote = {Comment: 22 pages, 3 figures},
	file = {Azze e.a. - 2022 - Optimal exercise of American options under time-de.pdf:C\:\\Users\\Admin\\Zotero\\storage\\G2H9S8M4\\Azze e.a. - 2022 - Optimal exercise of American options under time-de.pdf:application/pdf},
}

@misc{formica_method_2021,
	title = {Method {Monte}-{Carlo} for solving of non-linear integral equations},
	url = {http://arxiv.org/abs/2102.07859},
	abstract = {We oﬀer in this short report a simple Monte - Carlo method for solving a well posed non - linear integral equations of second Fredholm’s and Volterra’s type and built a conﬁdence region for solution in an uniform norm, applying the grounded Central Limit Theorem in the Banach space of continuous functions.},
	language = {en},
	urldate = {2023-01-10},
	publisher = {arXiv},
	author = {Formica, M. R. and Ostrovsky, E. and Sirota, L.},
	month = feb,
	year = {2021},
	note = {arXiv:2102.07859 [cs, math]},
	keywords = {Mathematics - Numerical Analysis},
	file = {Formica e.a. - 2021 - Method Monte-Carlo for solving of non-linear integ.pdf:C\:\\Users\\Admin\\Zotero\\storage\\INK9IZXC\\Formica e.a. - 2021 - Method Monte-Carlo for solving of non-linear integ.pdf:application/pdf},
}

@misc{hajimohammadi_legendre_2021,
	title = {Legendre {Deep} {Neural} {Network} ({LDNN}) and its application for approximation of nonlinear {Volterra} {Fredholm} {Hammerstein} integral equations},
	url = {http://arxiv.org/abs/2106.14320},
	abstract = {Various phenomena in biology, physics, and engineering are modeled by diﬀerential equations. These diﬀerential equations including partial diﬀerential equations and ordinary diﬀerential equations can be converted and represented as integral equations. In particular, Volterra–Fredholm–Hammerstein integral equations are the main type of these integral equations and researchers are interested in investigating and solving these equations. In this paper, we propose Legendre Deep Neural Network (LDNN) for solving nonlinear Volterra–Fredholm–Hammerstein integral equations (V-F-H-IEs). LDNN utilizes Legendre orthogonal polynomials as activation functions of the Deep structure. We present how LDNN can be used to solve nonlinear V-F-H-IEs. We show using the Gaussian quadrature collocation method in combination with LDNN results in a novel numerical solution for nonlinear V-F-H-IEs. Several examples are given to verify the performance and accuracy of LDNN.},
	language = {en},
	urldate = {2023-01-10},
	publisher = {arXiv},
	author = {Hajimohammadi, Zeinab and Parand, Kourosh and Ghodsi, Ali},
	month = jun,
	year = {2021},
	note = {arXiv:2106.14320 [cs, math]},
	keywords = {Mathematics - Numerical Analysis, Computer Science - Machine Learning},
	file = {Hajimohammadi e.a. - 2021 - Legendre Deep Neural Network (LDNN) and its applic.pdf:C\:\\Users\\Admin\\Zotero\\storage\\PYEIWQ2R\\Hajimohammadi e.a. - 2021 - Legendre Deep Neural Network (LDNN) and its applic.pdf:application/pdf},
}

@misc{enthought_high_2016,
	title = {High {Quality}, {High} {Performance} {Clustering} with {HDBSCAN} {\textbar} {SciPy} 2016 {\textbar} {Leland} {McInnes}},
	url = {https://www.youtube.com/watch?v=AgPQ76RIi6A},
	urldate = {2023-01-10},
	author = {{Enthought}},
	month = jul,
	year = {2016},
}

@misc{stitch_fix_multithreaded_algo_2020,
	title = {Algo {Hour} - {Nearest} {Neighbor} {Descent} (and friends) {\textbar} {Dr}. {Leland} {McInnes}},
	url = {https://www.youtube.com/watch?v=OvT2NY_FV_g},
	urldate = {2023-01-10},
	author = {{Stitch Fix Multithreaded}},
	month = may,
	year = {2020},
}

@misc{pydata_bluffers_2019,
	title = {A {Bluffer}'s {Guide} to {Dimension} {Reduction} - {Leland} {McInnes}},
	url = {https://www.youtube.com/watch?v=9iol3Lk6kyU},
	urldate = {2023-01-10},
	author = {{PyData}},
	month = feb,
	year = {2019},
}

@misc{enthought_umap_2018,
	title = {{UMAP} {Uniform} {Manifold} {Approximation} and {Projection} for {Dimension} {Reduction} {\textbar} {SciPy} 2018 {\textbar}},
	url = {https://www.youtube.com/watch?v=nq6iPZVUxZU},
	urldate = {2023-01-10},
	author = {{Enthought}},
	month = jul,
	year = {2018},
}

@inproceedings{duminil-copin_sixty_2019,
	address = {Rio de Janeiro, Brazil},
	title = {{SIXTY} {YEARS} {OF} {PERCOLATION}},
	isbn = {978-981-327-287-3 978-981-327-288-0},
	url = {https://www.worldscientific.com/doi/abs/10.1142/9789813272880_0162},
	doi = {10.1142/9789813272880_0162},
	abstract = {Percolation models describe the inside of a porous material. The theory emerged timidly in the middle of the twentieth century before becoming one of the major objects of interest in probability and mathematical physics. The golden age of percolation is probably the eighties, during which most of the major results were obtained for the most classical of these models, named Bernoulli percolation, but it is really the two following decades which put percolation theory at the crossroad of several domains of mathematics. In this broad review, we propose to describe brieﬂy some recent progress as well as some famous challenges remaining in the ﬁeld. This review is not intended to probabilists (and a fortiori not to specialists in percolation theory): the target audience is mathematicians of all kinds.},
	language = {en},
	urldate = {2023-01-09},
	booktitle = {Proceedings of the {International} {Congress} of {Mathematicians} ({ICM} 2018)},
	publisher = {WORLD SCIENTIFIC},
	author = {Duminil-Copin, Hugo},
	month = may,
	year = {2019},
	pages = {2829--2856},
	file = {Duminil-Copin - 2019 - SIXTY YEARS OF PERCOLATION.pdf:C\:\\Users\\Admin\\Zotero\\storage\\KAH28XWG\\Duminil-Copin - 2019 - SIXTY YEARS OF PERCOLATION.pdf:application/pdf},
}

@misc{subr_q-net_2021,
	title = {Q-{NET}: {A} {Network} for {Low}-{Dimensional} {Integrals} of {Neural} {Proxies}},
	shorttitle = {Q-{NET}},
	url = {http://arxiv.org/abs/2006.14396},
	abstract = {Many applications require the calculation of integrals of multidimensional functions. A general and popular procedure is to estimate integrals by averaging multiple evaluations of the function. Often, each evaluation of the function entails costly computations. The use of a {\textbackslash}emph\{proxy\} or surrogate for the true function is useful if repeated evaluations are necessary. The proxy is even more useful if its integral is known analytically and can be calculated practically. We propose the use of a versatile yet simple class of artificial neural networks -- sigmoidal universal approximators -- as a proxy for functions whose integrals need to be estimated. We design a family of fixed networks, which we call Q-NETs, that operate on parameters of a trained proxy to calculate exact integrals over {\textbackslash}emph\{any subset of dimensions\} of the input domain. We identify transformations to the input space for which integrals may be recalculated without resampling the integrand or retraining the proxy. We highlight the benefits of this scheme for a few applications such as inverse rendering, generation of procedural noise, visualization and simulation. The proposed proxy is appealing in the following contexts: the dimensionality is low (\${\textless}10\$D); the estimation of integrals needs to be decoupled from the sampling strategy; sparse, adaptive sampling is used; marginal functions need to be known in functional form; or when powerful Single Instruction Multiple Data/Thread (SIMD/SIMT) pipelines are available for computation.},
	language = {en},
	urldate = {2023-01-08},
	publisher = {arXiv},
	author = {Subr, Kartic},
	month = mar,
	year = {2021},
	note = {arXiv:2006.14396 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: 11 pages (including appendix and references)},
	file = {Subr - 2021 - Q-NET A Network for Low-Dimensional Integrals of .pdf:C\:\\Users\\Admin\\Zotero\\storage\\N8BQBFKD\\Subr - 2021 - Q-NET A Network for Low-Dimensional Integrals of .pdf:application/pdf},
}

@article{zergainoh_construction_2007-1,
	title = {Construction of {Orthonormal} {Piecewise} {Polynomial} {Scaling} and {Wavelet} {Bases} on {Non}-{Equally} {Spaced} {Knots}},
	volume = {2007},
	issn = {1687-6180},
	url = {https://asp-eurasipjournals.springeropen.com/articles/10.1155/2007/27427},
	doi = {10.1155/2007/27427},
	language = {en},
	number = {1},
	urldate = {2023-01-08},
	journal = {EURASIP Journal on Advances in Signal Processing},
	author = {Zergaïnoh, Anissa and Chihab, Najat and Astruc, Jean Pierre},
	month = dec,
	year = {2007},
	pages = {027427},
	file = {Zergaïnoh e.a. - 2007 - Construction of Orthonormal Piecewise Polynomial S.pdf:C\:\\Users\\Admin\\Zotero\\storage\\IA4NHCZX\\Zergaïnoh e.a. - 2007 - Construction of Orthonormal Piecewise Polynomial S.pdf:application/pdf},
}

@misc{beznea_monte_2022,
	title = {From {Monte} {Carlo} to neural networks approximations of boundary value problems},
	url = {http://arxiv.org/abs/2209.01432},
	abstract = {In this paper we study probabilistic and neural network approximations for solutions to Poisson equation subject to H¨older or C2 data in general bounded domains of Rd. We aim at two fundamental goals.},
	language = {en},
	urldate = {2023-01-06},
	publisher = {arXiv},
	author = {Beznea, Lucian and Cimpean, Iulian and Lupascu-Stamate, Oana and Popescu, Ionel and Zarnescu, Arghir},
	month = sep,
	year = {2022},
	note = {arXiv:2209.01432 [cs, math]},
	keywords = {Mathematics - Analysis of PDEs, Mathematics - Probability, Computer Science - Artificial Intelligence, Mathematics - Numerical Analysis, Computer Science - Machine Learning},
	file = {Beznea e.a. - 2022 - From Monte Carlo to neural networks approximations.pdf:C\:\\Users\\Admin\\Zotero\\storage\\G4JL3TT7\\Beznea e.a. - 2022 - From Monte Carlo to neural networks approximations.pdf:application/pdf},
}

@misc{jaini_sum--squares_2019,
	title = {Sum-of-{Squares} {Polynomial} {Flow}},
	url = {http://arxiv.org/abs/1905.02325},
	abstract = {Triangular map is a recent construct in probability theory that allows one to transform any source probability density function to any target density function. Based on triangular maps, we propose a general framework for high-dimensional density estimation, by specifying one-dimensional transformations (equivalently conditional densities) and appropriate conditioner networks. This framework (a) reveals the commonalities and differences of existing autoregressive and ﬂow based methods, (b) allows a uniﬁed understanding of the limitations and representation power of these recent approaches and, (c) motivates us to uncover a new Sum-of-Squares (SOS) ﬂow that is interpretable, universal, and easy to train. We perform several synthetic experiments on various density geometries to demonstrate the beneﬁts (and shortcomings) of such transformations. SOS ﬂows achieve competitive results in simulations and several real-world datasets.},
	language = {en},
	urldate = {2023-01-06},
	publisher = {arXiv},
	author = {Jaini, Priyank and Selby, Kira A. and Yu, Yaoliang},
	month = jun,
	year = {2019},
	note = {arXiv:1905.02325 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 13 pages, ICML'2019},
	file = {Jaini e.a. - 2019 - Sum-of-Squares Polynomial Flow.pdf:C\:\\Users\\Admin\\Zotero\\storage\\PCM8RNZR\\Jaini e.a. - 2019 - Sum-of-Squares Polynomial Flow.pdf:application/pdf},
}

@misc{papamakarios_normalizing_2021,
	title = {Normalizing {Flows} for {Probabilistic} {Modeling} and {Inference}},
	url = {http://arxiv.org/abs/1912.02762},
	abstract = {Normalizing ﬂows provide a general mechanism for deﬁning expressive probability distributions, only requiring the speciﬁcation of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing ﬂows, ranging from improving their expressive power to expanding their application. We believe the ﬁeld has now matured and is in need of a uniﬁed perspective. In this review, we attempt to provide such a perspective by describing ﬂows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of ﬂow design, and discuss foundational topics such as expressive power and computational trade-oﬀs. We also broaden the conceptual framing of ﬂows by relating them to more general probability transformations. Lastly, we summarize the use of ﬂows for tasks such as generative modeling, approximate inference, and supervised learning.},
	language = {en},
	urldate = {2023-01-06},
	publisher = {arXiv},
	author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
	month = apr,
	year = {2021},
	note = {arXiv:1912.02762 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Review article, 64 pages, 9 figures. Published in the Journal of Machine Learning Research (see https://jmlr.org/papers/v22/19-1028.html)},
	file = {Papamakarios e.a. - 2021 - Normalizing Flows for Probabilistic Modeling and I.pdf:C\:\\Users\\Admin\\Zotero\\storage\\WS7G7WN2\\Papamakarios e.a. - 2021 - Normalizing Flows for Probabilistic Modeling and I.pdf:application/pdf},
}

@misc{durkan_neural_2019,
	title = {Neural {Spline} {Flows}},
	url = {http://arxiv.org/abs/1906.04032},
	abstract = {A normalizing ﬂow models a complex probability density as an invertible transformation of a simple base density. Flows based on either coupling or autoregressive transforms both offer exact density evaluation and sampling, but rely on the parameterization of an easily invertible elementwise transformation, whose choice determines the ﬂexibility of these models. Building upon recent work, we propose a fully-differentiable module based on monotonic rational-quadratic splines, which enhances the ﬂexibility of both coupling and autoregressive transforms while retaining analytic invertibility. We demonstrate that neural spline ﬂows improve density estimation, variational inference, and generative modeling of images.},
	language = {en},
	urldate = {2023-01-06},
	publisher = {arXiv},
	author = {Durkan, Conor and Bekasov, Artur and Murray, Iain and Papamakarios, George},
	month = dec,
	year = {2019},
	note = {arXiv:1906.04032 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Published at the 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada},
	file = {Durkan e.a. - 2019 - Neural Spline Flows.pdf:C\:\\Users\\Admin\\Zotero\\storage\\RNWFF9CZ\\Durkan e.a. - 2019 - Neural Spline Flows.pdf:application/pdf},
}

@misc{durkan_cubic-spline_2019,
	title = {Cubic-{Spline} {Flows}},
	url = {http://arxiv.org/abs/1906.02145},
	abstract = {A normalizing ﬂow models a complex probability density as an invertible transformation of a simple density. The invertibility means that we can evaluate densities and generate samples from a ﬂow. In practice, autoregressive ﬂow-based models are slow to invert, making either density estimation or sample generation slow. Flows based on coupling transforms are fast for both tasks, but have previously performed less well at density estimation than autoregressive ﬂows. We stack a new coupling transform, based on monotonic cubic splines, with LU-decomposed linear layers. The resulting cubic-spline ﬂow retains an exact onepass inverse, can be used to generate high-quality images, and closes the gap with autoregressive ﬂows on a suite of density-estimation tasks.},
	language = {en},
	urldate = {2023-01-06},
	publisher = {arXiv},
	author = {Durkan, Conor and Bekasov, Artur and Murray, Iain and Papamakarios, George},
	month = jun,
	year = {2019},
	note = {arXiv:1906.02145 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Appeared at the 1st Workshop on Invertible Neural Networks and Normalizing Flows at ICML 2019},
	file = {Durkan e.a. - 2019 - Cubic-Spline Flows.pdf:C\:\\Users\\Admin\\Zotero\\storage\\FG5VAIUR\\Durkan e.a. - 2019 - Cubic-Spline Flows.pdf:application/pdf},
}

@article{manzi_gradient-domain_nodate,
	title = {Gradient-{Domain} {Bidirectional} {Path} {Tracing}},
	abstract = {Gradient-domain path tracing has recently been introduced as an efﬁcient realistic image synthesis algorithm. This paper introduces a bidirectional gradient-domain sampler that outperforms traditional bidirectional path tracing often by a factor of two to ﬁve in terms of squared error at equal render time. It also improves over unidirectional gradient-domain path tracing in challenging visibility conditions, similarly to how conventional bidirectional path tracing improves over its unidirectional counterpart. Our algorithm leverages a novel multiple importance sampling technique and an efﬁcient implementation of a high-quality shift mapping suitable for bidirectional path tracing. We demonstrate the versatility of our approach in several challenging light transport scenarios.},
	language = {en},
	author = {Manzi, Marco and Kettunen, Markus and Aittala, Miika and Lehtinen, Jaakko and Durand, Frédo and Zwicker, Matthias},
	file = {Manzi e.a. - Gradient-Domain Bidirectional Path Tracing.pdf:C\:\\Users\\Admin\\Zotero\\storage\\G9T7TZDT\\Manzi e.a. - Gradient-Domain Bidirectional Path Tracing.pdf:application/pdf},
}

@article{manzi_gradient-domain_nodate-1,
	title = {Gradient-{Domain} {Bidirectional} {Path} {Tracing}},
	abstract = {Gradient-domain path tracing has recently been introduced as an efﬁcient realistic image synthesis algorithm. This paper introduces a bidirectional gradient-domain sampler that outperforms traditional bidirectional path tracing often by a factor of two to ﬁve in terms of squared error at equal render time. It also improves over unidirectional gradient-domain path tracing in challenging visibility conditions, similarly to how conventional bidirectional path tracing improves over its unidirectional counterpart. Our algorithm leverages a novel multiple importance sampling technique and an efﬁcient implementation of a high-quality shift mapping suitable for bidirectional path tracing. We demonstrate the versatility of our approach in several challenging light transport scenarios.},
	language = {en},
	author = {Manzi, Marco and Kettunen, Markus and Aittala, Miika and Lehtinen, Jaakko and Durand, Frédo and Zwicker, Matthias},
	file = {Manzi e.a. - Gradient-Domain Bidirectional Path Tracing.pdf:C\:\\Users\\Admin\\Zotero\\storage\\U4XPCDLI\\Manzi e.a. - Gradient-Domain Bidirectional Path Tracing.pdf:application/pdf},
}

@misc{dahm_learning_2017,
	title = {Learning {Light} {Transport} the {Reinforced} {Way}},
	url = {http://arxiv.org/abs/1701.07403},
	abstract = {We show that the equations of reinforcement learning and light transport simulation are related integral equations. Based on this correspondence, a scheme to learn importance while sampling path space is derived. The new approach is demonstrated in a consistent light transport simulation algorithm that uses reinforcement learning to progressively learn where light comes from. As using this information for importance sampling includes information about visibility, too, the number of light transport paths with zero contribution is dramatically reduced, resulting in much less noisy images within a ﬁxed time budget.},
	language = {en},
	urldate = {2023-01-06},
	publisher = {arXiv},
	author = {Dahm, Ken and Keller, Alexander},
	month = aug,
	year = {2017},
	note = {arXiv:1701.07403 [cs]},
	keywords = {Computer Science - Graphics, Computer Science - Machine Learning},
	annote = {Comment: Revised version},
	file = {Dahm en Keller - 2017 - Learning Light Transport the Reinforced Way.pdf:C\:\\Users\\Admin\\Zotero\\storage\\2D4V4CM6\\Dahm en Keller - 2017 - Learning Light Transport the Reinforced Way.pdf:application/pdf},
}

@article{ruppert_robust_2020,
	title = {Robust fitting of parallax-aware mixtures for path guiding},
	volume = {39},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/3386569.3392421},
	doi = {10.1145/3386569.3392421},
	abstract = {Effective local light transport guiding demands for high quality guiding information, i.e., a precise representation of the directional incident radiance distribution at every point inside the scene. We introduce a parallax-aware distribution model based on parametric mixtures. By parallax-aware warping of the distribution, the local approximation of the 5D radiance field remains valid and precise across large spatial regions, even for close-by contributors. Our robust optimization scheme fits parametric mixtures to radiance samples collected in previous rendering passes. Robustness is achieved by splitting and merging of components refining the mixture. These splitting and merging decisions minimize and bound the expected variance of the local radiance estimator. In addition, we extend the fitting scheme to a robust, iterative update method, which allows for incremental training of our model using smaller sample batches. This results in more frequent training updates and, at the same time, significantly reduces the required sample memory footprint. The parametric representation of our model allows for the application of advanced importance sampling methods such as radiance-based, cosine-aware, and even product importance sampling. Our method further smoothly integrates next-event estimation (NEE) into path guiding, avoiding importance sampling of contributions better covered by NEE. The proposed robust fitting and update scheme, in combination with the parallax-aware representation, results in faster learning and lower variance compared to state-of-the-art path guiding approaches.},
	language = {en},
	number = {4},
	urldate = {2023-01-06},
	journal = {ACM Transactions on Graphics},
	author = {Ruppert, Lukas and Herholz, Sebastian and Lensch, Hendrik P. A.},
	month = aug,
	year = {2020},
	file = {Ruppert e.a. - 2020 - Robust fitting of parallax-aware mixtures for path.pdf:C\:\\Users\\Admin\\Zotero\\storage\\Y3W4KYQT\\Ruppert e.a. - 2020 - Robust fitting of parallax-aware mixtures for path.pdf:application/pdf},
}

@misc{muller_neural_2019,
	title = {Neural {Importance} {Sampling}},
	url = {http://arxiv.org/abs/1808.03856},
	abstract = {We propose to use deep neural networks for generating samples in Monte Carlo integration. Our work is based on non-linear independent components estimation (NICE), which we extend in numerous ways to improve performance and enable its application to integration problems. First, we introduce piecewise-polynomial coupling transforms that greatly increase the modeling power of individual coupling layers. Second, we propose to preprocess the inputs of neural networks using one-blob encoding, which stimulates localization of computation and improves inference. Third, we derive a gradient-descent-based optimization for the KL and the \${\textbackslash}chi{\textasciicircum}2\$ divergence for the specific application of Monte Carlo integration with unnormalized stochastic estimates of the target distribution. Our approach enables fast and accurate inference and efficient sample generation independently of the dimensionality of the integration domain. We show its benefits on generating natural images and in two applications to light-transport simulation: first, we demonstrate learning of joint path-sampling densities in the primary sample space and importance sampling of multi-dimensional path prefixes thereof. Second, we use our technique to extract conditional directional densities driven by the product of incident illumination and the BSDF in the rendering equation, and we leverage the densities for path guiding. In all applications, our approach yields on-par or higher performance than competing techniques at equal sample count.},
	language = {en},
	urldate = {2023-01-06},
	publisher = {arXiv},
	author = {Müller, Thomas and McWilliams, Brian and Rousselle, Fabrice and Gross, Markus and Novák, Jan},
	month = sep,
	year = {2019},
	note = {arXiv:1808.03856 [cs, stat]},
	keywords = {Computer Science - Graphics, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 19 pages, 15 figures. Accepted for publication in ACM Transactions on Graphics; presented at SIGGRAPH 2019},
	file = {Müller e.a. - 2019 - Neural Importance Sampling.pdf:C\:\\Users\\Admin\\Zotero\\storage\\UQDR2FVH\\Müller e.a. - 2019 - Neural Importance Sampling.pdf:application/pdf},
}

@misc{muller_neural_2020,
	title = {Neural {Control} {Variates}},
	url = {http://arxiv.org/abs/2006.01524},
	abstract = {We propose neural control variates (NCV) for unbiased variance reduction in parametric Monte Carlo integration. So far, the core challenge of applying the method of control variates has been finding a good approximation of the integrand that is cheap to integrate. We show that a set of neural networks can face that challenge: a normalizing flow that approximates the shape of the integrand and another neural network that infers the solution of the integral equation. We also propose to leverage a neural importance sampler to estimate the difference between the original integrand and the learned control variate. To optimize the resulting parametric estimator, we derive a theoretically optimal, variance-minimizing loss function, and propose an alternative, composite loss for stable online training in practice. When applied to light transport simulation, neural control variates are capable of matching the state-of-the-art performance of other unbiased approaches, while providing means to develop more performant, practical solutions. Specifically, we show that the learned light-field approximation is of sufficient quality for high-order bounces, allowing us to omit the error correction and thereby dramatically reduce the noise at the cost of negligible visible bias.},
	language = {en},
	urldate = {2023-01-06},
	publisher = {arXiv},
	author = {Müller, Thomas and Rousselle, Fabrice and Novák, Jan and Keller, Alexander},
	month = sep,
	year = {2020},
	note = {arXiv:2006.01524 [cs, stat]},
	keywords = {Computer Science - Graphics, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: To appear at SIGGRAPH Asia 2020. Updated with better loss function, leading to better results. 19 pages, 14 figures},
	file = {Müller e.a. - 2020 - Neural Control Variates.pdf:C\:\\Users\\Admin\\Zotero\\storage\\VJD8P7DL\\Müller e.a. - 2020 - Neural Control Variates.pdf:application/pdf},
}

@article{kondapaneni_optimal_2019,
	title = {Optimal multiple importance sampling},
	volume = {38},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/3306346.3323009},
	doi = {10.1145/3306346.3323009},
	abstract = {Multiple Importance Sampling (MIS) is a key technique for achieving robustness of Monte Carlo estimators in computer graphics and other fields. We derive optimal weighting functions for MIS that provably minimize the variance of an MIS estimator, given a set of sampling techniques. We show that the resulting variance reduction over the balance heuristic can be higher than predicted by the variance bounds derived by Veach and Guibas, who assumed only non-negative weights in their proof. We theoretically analyze the variance of the optimal MIS weights and show the relation to the variance of the balance heuristic. Furthermore, we establish a connection between the new weighting functions and control variates as previously applied to mixture sampling. We apply the new optimal weights to integration problems in light transport and show that they allow for new design considerations when choosing the appropriate sampling techniques for a given integration problem.},
	language = {en},
	number = {4},
	urldate = {2023-01-06},
	journal = {ACM Transactions on Graphics},
	author = {Kondapaneni, Ivo and Vevoda, Petr and Grittmann, Pascal and Skřivan, Tomáš and Slusallek, Philipp and Křivánek, Jaroslav},
	month = aug,
	year = {2019},
	pages = {1--14},
	file = {Kondapaneni e.a. - 2019 - Optimal multiple importance sampling.pdf:C\:\\Users\\Admin\\Zotero\\storage\\LN9YUIJZ\\Kondapaneni e.a. - 2019 - Optimal multiple importance sampling.pdf:application/pdf},
}

@misc{albert_tau-leaping_2023,
	title = {A tau-leaping method for computing joint probability distributions of the first-passage time and position of a {Brownian} particle},
	url = {http://arxiv.org/abs/2301.00647},
	abstract = {First passage time (FPT), also known as ﬁrst hitting time, is the time a particle, subject to some stochastic process, hits or crosses a closed surface for the very ﬁrst time. τ -leaping methods are a class of stochastic algorithms in which, instead of simulating every single reaction, many reactions are “leaped” over in order to shorten the computing time. In this paper we developed a τ -leaping method for computing the FPT and position in arbitrary volumes for a Brownian particle governed by the Langevin equation. The τ -leaping method proposed here works as follows. A sphere is inscribed within the volume of interest (VOI) centered at the initial particle’s location. On this sphere, the FPT is sampled, as well as the position, which becomes the new initial position. Then, another sphere, centered at this new location, is inscribed. This process continues until the sphere becomes smaller than some minimal radius Rmin. When this occurs, the τ -leaping switches to the conventional Monte Carlo, which runs until the particle either crosses the surface of the VOI or ﬁnds its way to a position where a sphere of radius {\textgreater} Rmin can be inscribed. The switching between τ -leaping and MC continues until the particle crosses the surface of the VOI. The purpose of a minimal radius is to avoid having to sample the velocities, which become irrelevant when the particle diﬀuses beyond a certain distance, i. e. Rmin The size of this radius depends on the system parameters and on one’s notion of accuracy: the larger this radius the more accurate the τ -leaping method, but also less eﬃcient. This trade oﬀ between accuracy and eﬃciency is discussed. For two VOI, the τ -leaping method is shown to be accurate and more eﬃcient than MC by at least a factor of 10 and up to a factor of about 110. However, while MC becomes exponentially slower with increasing VOI, the eﬃciency of the τ -leaping method remains relatively unchanged. Thus, the τ -leaping method can potentially be many orders of magnitude more eﬃcient than MC.},
	language = {en},
	urldate = {2023-01-05},
	publisher = {arXiv},
	author = {Albert, Jaroslav},
	month = jan,
	year = {2023},
	note = {arXiv:2301.00647 [cond-mat, q-bio]},
	keywords = {Condensed Matter - Soft Condensed Matter, Quantitative Biology - Molecular Networks},
	file = {Albert - 2023 - A tau-leaping method for computing joint probabili.pdf:C\:\\Users\\Admin\\Zotero\\storage\\J5YXETE7\\Albert - 2023 - A tau-leaping method for computing joint probabili.pdf:application/pdf},
}

@misc{salaun_regression-based_2022,
	title = {Regression-based {Monte} {Carlo} {Integration}},
	url = {http://arxiv.org/abs/2211.07422},
	abstract = {Monte Carlo integration is typically interpreted as an estimator of the expected value using stochastic samples. There exists an alternative interpretation in calculus where Monte Carlo integration can be seen as estimating a {\textbackslash}emph\{constant\} function -- from the stochastic evaluations of the integrand -- that integrates to the original integral. The integral mean value theorem states that this {\textbackslash}emph\{constant\} function should be the mean (or expectation) of the integrand. Since both interpretations result in the same estimator, little attention has been devoted to the calculus-oriented interpretation. We show that the calculus-oriented interpretation actually implies the possibility of using a more {\textbackslash}emph\{complex\} function than a {\textbackslash}emph\{constant\} one to construct a more efficient estimator for Monte Carlo integration. We build a new estimator based on this interpretation and relate our estimator to control variates with least-squares regression on the stochastic samples of the integrand. Unlike prior work, our resulting estimator is {\textbackslash}emph\{provably\} better than or equal to the conventional Monte Carlo estimator. To demonstrate the strength of our approach, we introduce a practical estimator that can act as a simple drop-in replacement for conventional Monte Carlo integration. We experimentally validate our framework on various light transport integrals. The code is available at {\textbackslash}url\{https://github.com/iribis/regressionmc\}.},
	language = {en},
	urldate = {2023-01-05},
	publisher = {arXiv},
	author = {Salaün, Corentin and Gruson, Adrien and Hua, Binh-Son and Hachisuka, Toshiya and Singh, Gurprit},
	month = nov,
	year = {2022},
	note = {arXiv:2211.07422 [cs]},
	keywords = {Computer Science - Graphics},
	annote = {Comment: 14 pages, 16 figures, ACM Trans. Graph., Vol. 41, No. 4, Article 79. Publication date: July 2022},
	file = {Salaün e.a. - 2022 - Regression-based Monte Carlo Integration.pdf:C\:\\Users\\Admin\\Zotero\\storage\\FDCESJF7\\Salaün e.a. - 2022 - Regression-based Monte Carlo Integration.pdf:application/pdf},
}

@inproceedings{yang_efficient_2019,
	title = {Efficient {Estimation} of {Heat} {Kernel} {PageRank} for {Local} {Clustering}},
	url = {http://arxiv.org/abs/1904.02707},
	doi = {10.1145/3299869.3319886},
	abstract = {Given an undirected graph G and a seed node s, the local clustering problem aims to identify a high-quality cluster containing s in time roughly proportional to the size of the cluster, regardless of the size of G. This problem finds numerous applications on large-scale graphs. Recently, heat kernel PageRank (HKPR), which is a measure of the proximity of nodes in graphs, is applied to this problem and found to be more efficient compared with prior methods. However, existing solutions for computing HKPR either are prohibitively expensive or provide unsatisfactory error approximation on HKPR values, rendering them impractical especially on billion-edge graphs. In this paper, we present TEA and TEA+, two novel local graph clustering algorithms based on HKPR, to address the aforementioned limitations. Specifically, these algorithms provide non-trivial theoretical guarantees in relative error of HKPR values and the time complexity. The basic idea is to utilize deterministic graph traversal to produce a rough estimation of exact HKPR vector, and then exploit Monte-Carlo random walks to refine the results in an optimized and non-trivial way. In particular, TEA+ offers practical efficiency and effectiveness due to non-trivial optimizations. Extensive experiments on real-world datasets demonstrate that TEA+ outperforms the state-of-the-art algorithm by more than four times on most benchmark datasets in terms of computational time when achieving the same clustering quality, and in particular, is an order of magnitude faster on large graphs including the widely studied Twitter and Friendster datasets.},
	language = {en},
	urldate = {2023-01-05},
	booktitle = {Proceedings of the 2019 {International} {Conference} on {Management} of {Data}},
	author = {Yang, Renchi and Xiao, Xiaokui and Wei, Zhewei and Bhowmick, Sourav S. and Zhao, Jun and Li, Rong-Hua},
	month = jun,
	year = {2019},
	note = {arXiv:1904.02707 [cs]},
	keywords = {Computer Science - Databases, Computer Science - Social and Information Networks},
	pages = {1339--1356},
	annote = {Comment: The technical report for the full research paper accepted in the SIGMOD 2019},
	file = {Yang e.a. - 2019 - Efficient Estimation of Heat Kernel PageRank for L.pdf:C\:\\Users\\Admin\\Zotero\\storage\\AZE6CUJG\\Yang e.a. - 2019 - Efficient Estimation of Heat Kernel PageRank for L.pdf:application/pdf},
}

@misc{zhang_advanced_2021,
	title = {An {Advanced} {Parallel} {PageRank} {Algorithm}},
	url = {http://arxiv.org/abs/2112.07363},
	abstract = {Initially used to rank web pages, PageRank has now been applied in may ﬁelds. In general case, there are plenty of special vertices such as dangling vertices and unreferenced vertices in the graph. Existing PageRank algorithms usually consider them as ‘bad‘ vertices since they may take troubles. However, in this paper, we propose a parallel PageRank algorithm which can take advantage of these special vertices. For this end, we ﬁrstly interpret PageRank from the information transmitting perspective and give a constructive deﬁnition of PageRank. Then, based on the information transmitting interpretation, a parallel PageRank algorithm which we call the Information Transmitting Algorithm(ITA) is proposed. We prove that the dangling vertices can increase ITA’s convergence rate and the unreferenced vertices and weak unreferenced vertices can decrease ITA’s calculations. Compared with the MONTE CARLO method, ITA has lower bandwidth requirement. Compared with the power method, ITA has higher convergence rate and generates less calculations. Finally, experimental results on four data sets demonstrate that ITA is 1.5-4 times faster than the power method and converges more uniformly.},
	language = {en},
	urldate = {2023-01-05},
	publisher = {arXiv},
	author = {Zhang, Qi and Yao, Zhengan and Liang, Jun and Zhang, Zanbo},
	month = dec,
	year = {2021},
	note = {arXiv:2112.07363 [cs]},
	keywords = {Computer Science - Networking and Internet Architecture},
	file = {Zhang e.a. - 2021 - An Advanced Parallel PageRank Algorithm.pdf:C\:\\Users\\Admin\\Zotero\\storage\\YZS4ETMH\\Zhang e.a. - 2021 - An Advanced Parallel PageRank Algorithm.pdf:application/pdf},
}

@article{das_sarma_fast_2015,
	title = {Fast distributed {PageRank} computation},
	volume = {561},
	issn = {03043975},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397514002709},
	doi = {10.1016/j.tcs.2014.04.003},
	abstract = {Over the last decade, PageRank has gained importance in a wide range of applications and domains, ever since it ﬁrst proved to be effective in determining node importance in large graphs (and was a pioneering idea behind Google’s search engine). In distributed computing alone, PageRank vector, or more generally random walk based quantities have been used for several different applications ranging from determining important nodes, load balancing, search, and identifying connectivity structures. Surprisingly, however, there has been little work towards designing provably eﬃcient fully-distributed algorithms for computing PageRank. The diﬃculty is that traditional matrix–vector multiplication style iterative methods may not always adapt well to the distributed setting owing to communication bandwidth restrictions and convergence rates.},
	language = {en},
	urldate = {2023-01-05},
	journal = {Theoretical Computer Science},
	author = {Das Sarma, Atish and Molla, Anisur Rahaman and Pandurangan, Gopal and Upfal, Eli},
	month = jan,
	year = {2015},
	pages = {113--121},
	file = {Das Sarma e.a. - 2015 - Fast distributed PageRank computation.pdf:C\:\\Users\\Admin\\Zotero\\storage\\FLUGEZHI\\Das Sarma e.a. - 2015 - Fast distributed PageRank computation.pdf:application/pdf},
}

@article{linetsky_path_nodate,
	title = {The {Path} {Integral} {Approach} to {Financial} {Modeling} and {Options} {Pricing}},
	abstract = {In this paper we review some applications of the path integral methodology of quantum mechanics to ﬁnancial modeling and options pricing. A path integral is deﬁned as a limit of the sequence of ﬁnite-dimensional integrals, in a much the same way as the Riemannian integral is deﬁned as a limit of the sequence of ﬁnite sums. The risk-neutral valuation formula for path-dependent options contingent upon multiple underlying assets admits an elegant representation in terms of path integrals (Feynman–Kac formula). The path integral representation of transition probability density (Green’s function) explicitly satisﬁes the diffusion PDE. Gaussian path integrals admit a closed-form solution given by the Van Vleck formula. Analytical approximations are obtained by means of the semiclassical (moments) expansion. Difﬁcult path integrals are computed by numerical procedures, such as Monte Carlo simulation or deterministic discretization schemes. Several examples of pathdependent options are treated to illustrate the theory (weighted Asian options, ﬂoating barrier options, and barrier options with ladder-like barriers).},
	language = {en},
	author = {Linetsky, Vadim},
	file = {Linetsky - The Path Integral Approach to Financial Modeling a.pdf:C\:\\Users\\Admin\\Zotero\\storage\\3ZDBN84W\\Linetsky - The Path Integral Approach to Financial Modeling a.pdf:application/pdf},
}

@article{efendiev_multiscale_2004,
	title = {Multiscale {Finite} {Element} {Methods} for {Nonlinear} {Problems} and {Their} {Applications}},
	volume = {2},
	issn = {15396746, 19450796},
	url = {http://www.intlpress.com/site/pub/pages/journals/items/cms/content/vols/0002/0004/a002/},
	doi = {10.4310/CMS.2004.v2.n4.a2},
	abstract = {In this paper we propose a generalization of multiscale ﬁnite element methods (MsFEM) to nonlinear problems. We study the convergence of the proposed method for nonlinear elliptic equations and propose an oversampling technique. Numerical examples demonstrate that the oversampling technique greatly reduces the error. The application of MsFEM to porous media ﬂows is considered. Finally, we describe further generalizations of MsFEM to nonlinear time-dependent equations and discuss the convergence of the method for various kinds of heterogeneities.},
	language = {en},
	number = {4},
	urldate = {2023-01-05},
	journal = {Communications in Mathematical Sciences},
	author = {Efendiev, Y. and Ginting, V. and Hou, T. Y.},
	year = {2004},
	pages = {553--589},
	file = {Efendiev e.a. - 2004 - Multiscale Finite Element Methods for Nonlinear Pr.pdf:C\:\\Users\\Admin\\Zotero\\storage\\T66753T4\\Efendiev e.a. - 2004 - Multiscale Finite Element Methods for Nonlinear Pr.pdf:application/pdf},
}

@article{halton_sequential_2008,
	title = {Sequential {Monte} {Carlo} for linear systems – a practical summary},
	volume = {14},
	issn = {0929-9629, 1569-3961},
	url = {https://www.degruyter.com/document/doi/10.1515/MCMA.2008.001/html},
	doi = {10.1515/MCMA.2008.001},
	abstract = {This paper has been written in response to many requests for a practical guide to the use of the technique of sequential Monte Carlo in the fast numerical solving of large systems of linear equations. This method, which I have used with considerable success to solve such problems, improving the tricks of the trade as I learned more about it, has suffered from some neglect through the mathematical difﬁculty, for some of those who are more interested in using the tool than in thinking about it, of some of the theoretical aspects of rigorously proving its validity, which – at this juncture – is no longer in question. I hope that I have now closed this gap in the related literature.},
	language = {en},
	number = {1},
	urldate = {2023-01-04},
	journal = {Monte Carlo Methods and Applications},
	author = {Halton, John H.},
	month = jan,
	year = {2008},
	pages = {1--27},
	file = {Halton - 2008 - Sequential Monte Carlo for linear systems – a prac.pdf:C\:\\Users\\Admin\\Zotero\\storage\\YGVFCZZK\\Halton - 2008 - Sequential Monte Carlo for linear systems – a prac.pdf:application/pdf},
}

@misc{noauthor_screened_nodate,
	title = {screened poisson equation via {WoS}},
	file = {1-s2.0-0041555369900706-main.pdf:C\:\\Users\\Admin\\Zotero\\storage\\M6U2RW8L\\screened poisson with WoS.pdf:application/pdf},
}

@article{delaurentis_monte_1990,
	title = {A {Monte} {Carlo} method for poisson's equation},
	volume = {90},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/002199919090199B},
	doi = {10.1016/0021-9991(90)90199-B},
	language = {en},
	number = {1},
	urldate = {2022-12-26},
	journal = {Journal of Computational Physics},
	author = {Delaurentis, J.M and Romero, L.A},
	month = sep,
	year = {1990},
	pages = {123--140},
	file = {Delaurentis en Romero - 1990 - A Monte Carlo method for poisson's equation.pdf:C\:\\Users\\Admin\\Zotero\\storage\\HV3ST26K\\Delaurentis en Romero - 1990 - A Monte Carlo method for poisson's equation.pdf:application/pdf},
}

@article{novak_monte_2018,
	title = {Monte {Carlo} {Methods} for {Volumetric} {Light} {Transport} {Simulation}},
	volume = {37},
	issn = {01677055},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13383},
	doi = {10.1111/cgf.13383},
	abstract = {The wide adoption of path-tracing algorithms in high-end realistic rendering has stimulated many diverse research initiatives. In this paper we present a coherent survey of methods that utilize Monte Carlo integration for estimating light transport in scenes containing participating media. Our work complements the volume-rendering state-of-the-art report by Cerezo et al. [CPP∗05]; we review publications accumulated since its publication over a decade ago, and include earlier methods that are key for building light transport paths in a stochastic manner. We begin by describing analog and non-analog procedures for freepath sampling and discuss various expected-value, collision, and track-length estimators for computing transmittance. We then review the various rendering algorithms that employ these as building blocks for path sampling. Special attention is devoted to null-collision methods that utilize ﬁctitious matter to handle spatially varying densities; we import two “next-ﬂight” estimators originally developed in nuclear sciences. Whenever possible, we draw connections between image-synthesis techniques and methods from particle physics and neutron transport to provide the reader with a broader context.},
	language = {en},
	number = {2},
	urldate = {2022-12-23},
	journal = {Computer Graphics Forum},
	author = {Novák, Jan and Georgiev, Iliyan and Hanika, Johannes and Jarosz, Wojciech},
	month = may,
	year = {2018},
	pages = {551--576},
	file = {Novák e.a. - 2018 - Monte Carlo Methods for Volumetric Light Transport.pdf:C\:\\Users\\Admin\\Zotero\\storage\\8Y3IJRVP\\Novák e.a. - 2018 - Monte Carlo Methods for Volumetric Light Transport.pdf:application/pdf},
}

@article{veach_robust_nodate,
	title = {{ROBUST} {MONTE} {CARLO} {METHODS} {FOR} {LIGHT} {TRANSPORT} {SIMULATION}},
	language = {en},
	author = {Veach, Eric},
	file = {Veach - ROBUST MONTE CARLO METHODS FOR LIGHT TRANSPORT SIM.pdf:C\:\\Users\\Admin\\Zotero\\storage\\HDZ56Y9U\\Veach - ROBUST MONTE CARLO METHODS FOR LIGHT TRANSPORT SIM.pdf:application/pdf},
}

@article{sabelfeld_random_2017,
	title = {Random walk on spheres algorithm for solving transient drift-diffusion-reaction problems},
	volume = {23},
	issn = {1569-3961},
	url = {https://www.degruyter.com/document/doi/10.1515/mcma-2017-0113/html},
	doi = {10.1515/mcma-2017-0113},
	abstract = {We suggest in this paper a Random Walk on Spheres (RWS) method for solving transient drift-diffusion-reaction problems which is an extension of our algorithm we developed recently [26] for solving steady-state drift-diffusion problems. Both two-dimensional and three-dimensional problems are solved. Survival probability, first passage time and the exit position for a sphere (disc) of the drift-diffusion-reaction process are explicitly derived from a generalized spherical integral relation we prove both for two-dimensional and three-dimensional problems. The distribution of the exit position on the sphere has the form of the von Mises–Fisher distribution which can be simulated efficiently. Rigorous expressions are derived in the case of constant velocity drift, but the algorithm is then extended to solve drift-diffusion-reaction problems with arbitrary varying drift velocity vector. The method can efficiently be applied to calculate the fluxes of the solution to any part of the boundary. This can be done by applying a reciprocity theorem which we prove here for the drift-diffusion-reaction problems with general boundary conditions. Applications of this approach to methods of cathodoluminescence (CL) and electron beam induced current (EBIC) imaging of defects and dislocations in semiconductors are presented.},
	language = {en},
	number = {3},
	urldate = {2022-12-22},
	journal = {Monte Carlo Methods and Applications},
	author = {Sabelfeld, Karl K.},
	month = sep,
	year = {2017},
	note = {Publisher: De Gruyter},
	keywords = {cathodoluminescence, Drift-diffusion-reaction equation, reciprocity relation, Robin boundary conditions, spherical integral relation, von Mises–Fisher distribution},
	pages = {189--212},
}

@article{sabelfeld_random_2019,
	title = {Random walk on rectangles and parallelepipeds algorithm for solving transient anisotropic drift-diffusion-reaction problems},
	volume = {25},
	doi = {10.1515/mcma-2019-2039},
	abstract = {In this paper a random walk on arbitrary rectangles (2D) and parallelepipeds (3D) algorithm is developed for solving transient anisotropic drift-diffusion-reaction equations. The method is meshless, both in space and time. The approach is based on a rigorous representation of the first passage time and exit point distributions for arbitrary rectangles and parallelepipeds. The probabilistic representation is then transformed to a form convenient for stochastic simulation. The method can be used to calculate fluxes to any desired part of the boundary, from arbitrary sources. A global version of the method we call here as a stochastic expansion from cell to cell (SECC) algorithm for calculating the whole solution field is suggested. Application of this method to solve a system of transport equations for electrons and holes in a semicoductor is discussed. This system consists of the continuity equations for particle densities and a Poisson equation for electrostatic potential. To validate the method we have derived a series of exact solutions of the drift-diffusion-reaction problem in a three-dimensional layer presented in the last section in details.},
	journal = {Monte Carlo Methods and Applications},
	author = {Sabelfeld, Karl},
	month = may,
	year = {2019},
}

@article{rioux-lavoie_monte_2022,
	title = {A {Monte} {Carlo} {Method} for {Fluid} {Simulation}},
	volume = {41},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/3550454.3555450},
	doi = {10.1145/3550454.3555450},
	abstract = {We present a novel Monte Carlo-based fluid simulation approach capable of pointwise and stochastic estimation of fluid motion. Drawing on the Feynman-Kac representation of the vorticity transport equation, we propose a recursive Monte Carlo estimator of the Biot-Savart law and extend it with a stream function formulation that allows us to treat free-slip boundary conditions using a Walk-on-Spheres algorithm. Inspired by the Monte Carlo literature in rendering, we design and compare variance reduction schemes suited to a fluid simulation context for the first time, show its applicability to complex boundary settings, and detail a simple and practical implementation with temporal grid caching. We validate the correctness of our approach via quantitative and qualitative evaluations – across a range of settings and domain geometries – and thoroughly explore its parameters’ design space. Finally, we provide an in-depth discussion of several axes of future work building on this new numerical simulation modality. CCS Concepts: • Mathematics of computing → Probabilistic algorithms; Partial differential equations; • Computing methodologies → Modeling and simulation.},
	language = {en},
	number = {6},
	urldate = {2022-12-22},
	journal = {ACM Transactions on Graphics},
	author = {Rioux-Lavoie, Damien and Sugimoto, Ryusuke and Özdemir, Tümay and Shimada, Naoharu H. and Batty, Christopher and Nowrouzezahrai, Derek and Hachisuka, Toshiya},
	month = dec,
	year = {2022},
	pages = {1--16},
	file = {Rioux-Lavoie e.a. - 2022 - A Monte Carlo Method for Fluid Simulation.pdf:C\:\\Users\\Admin\\Zotero\\storage\\76CW9YCY\\Rioux-Lavoie e.a. - 2022 - A Monte Carlo Method for Fluid Simulation.pdf:application/pdf},
}

@article{qi_bidirectional_2022,
	title = {A bidirectional formulation for {Walk} on {Spheres}},
	volume = {41},
	issn = {0167-7055, 1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.14586},
	doi = {10.1111/cgf.14586},
	abstract = {Numerically solving partial differential equations (PDEs) is central to many applications in computer graphics and scientific modeling. Conventional methods for solving PDEs often need to discretize the space first, making them less efficient for complex geometry. Unlike conventional methods, the walk on spheres (WoS) algorithm recently introduced to graphics is a grid-free Monte Carlo method that can provide numerical solutions of Poisson equations without discretizing space. We draw analogies between WoS and classical rendering algorithms, and find that the WoS algorithm is conceptually equivalent to forward path tracing. Inspired by similar approaches in light transport, we propose a novel WoS reformulation that operates in the reverse direction, starting at source points and estimating the Green’s function at “sensor” points. Implementations of this algorithm show improvement over classical WoS in solving Poisson equation with sparse sources. Our approach opens exciting avenues for future algorithms for PDE estimation which, analogous to light transport, connect WoS walks starting from sensors and sources and combine different strategies for robust solution algorithms in all cases.},
	language = {en},
	number = {4},
	urldate = {2022-12-22},
	journal = {Computer Graphics Forum},
	author = {Qi, Yang and Seyb, Dario and Bitterli, Benedikt and Jarosz, Wojciech},
	month = jul,
	year = {2022},
	pages = {51--62},
	file = {Qi e.a. - 2022 - A bidirectional formulation for Walk on Spheres.pdf:C\:\\Users\\Admin\\Zotero\\storage\\Y6LCPRIN\\Qi e.a. - 2022 - A bidirectional formulation for Walk on Spheres.pdf:application/pdf},
}

@article{sabelfeld_application_2018,
	title = {Application of the von {Mises}–{Fisher} distribution to {Random} {Walk} on {Spheres} method for solving high-dimensional diffusion–advection–reaction equations},
	volume = {138},
	issn = {01677152},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167715218301160},
	doi = {10.1016/j.spl.2018.03.002},
	abstract = {We suggest a new efficient and reliable random walk method, continuous both in space and time, for solving high-dimensional diffusion–advection–reaction equations. It is based on a discovered intrinsic relation between the von Mises–Fisher distribution on a sphere with this type of equations. It can be formulated as follows: the von Mises–Fisher distribution uniquely defines the solution of a diffusion–advection equation in any bounded or unbounded domain if the relevant boundary value problem for this equation satisfies regular existence and uniqueness conditions. Both two- and three-dimensional transient equations are included in our considerations. The accuracy and the cost of the suggested random walk on spheres method are estimated.},
	language = {en},
	urldate = {2022-12-20},
	journal = {Statistics \& Probability Letters},
	author = {Sabelfeld, Karl K.},
	month = jul,
	year = {2018},
	pages = {137--142},
	file = {Sabelfeld - 2018 - Application of the von Mises–Fisher distribution t.pdf:C\:\\Users\\Admin\\Zotero\\storage\\E78HU5DQ\\Sabelfeld - 2018 - Application of the von Mises–Fisher distribution t.pdf:application/pdf},
}

@article{jin_first_2017,
	title = {First {Passage} {Time} for {Brownian} {Motion} and {Piecewise} {Linear} {Boundaries}},
	volume = {19},
	issn = {1387-5841, 1573-7713},
	url = {http://link.springer.com/10.1007/s11009-015-9475-2},
	doi = {10.1007/s11009-015-9475-2},
	abstract = {We propose a new approach to calculating the first passage time densities for Brownian motion crossing piecewise linear boundaries which can be discontinuous. Using this approach we obtain explicit formulas for the first passage densities and show that they are continuously differentiable except at the break points of the boundaries. Furthermore, these formulas can be used to approximate the first passage time distributions for general nonlinear boundaries. The numerical computation can be easily done by using the Monte Carlo integration, which is straightforward to implement. Some numerical examples are presented for illustration. This approach can be further extended to compute two-sided boundary crossing distributions.},
	language = {en},
	number = {1},
	urldate = {2022-12-20},
	journal = {Methodology and Computing in Applied Probability},
	author = {Jin, Zhiyong and Wang, Liqun},
	month = mar,
	year = {2017},
	pages = {237--253},
	file = {Jin en Wang - 2017 - First Passage Time for Brownian Motion and Piecewi.pdf:C\:\\Users\\Admin\\Zotero\\storage\\BNBKMEFU\\Jin en Wang - 2017 - First Passage Time for Brownian Motion and Piecewi.pdf:application/pdf},
}

@article{drabeck_monte_nodate,
	title = {Monte {Carlo} {Simulation} of {Boundary} {Crossing} {Probabilities} for a {Brownian} {Motion} and {Curved} {Boundaries}},
	language = {en},
	author = {Drabeck, Florian},
	file = {Drabeck - Monte Carlo Simulation of Boundary Crossing Probab.pdf:C\:\\Users\\Admin\\Zotero\\storage\\36MEIWXP\\Drabeck - Monte Carlo Simulation of Boundary Crossing Probab.pdf:application/pdf},
}

@misc{herrmann_exact_2017,
	title = {Exact simulation of the first-passage time of diffusions},
	url = {http://arxiv.org/abs/1705.06881},
	abstract = {Since diﬀusion processes arise in so many diﬀerent ﬁelds, eﬃcient technics for the simulation of sample paths, like discretization schemes, represent crucial tools in applied probability. Such methods permit to obtain approximations of the ﬁrst-passage times as a by-product. For eﬃciency reasons, it is particularly challenging to simulate directly this hitting time by avoiding to construct the whole paths. In the Brownian case, the distribution of the ﬁrst-passage time is explicitly known and can be easily used for simulation purposes. The authors introduce a new rejection sampling algorithm which permits to perform an exact simulation of the ﬁrst-passage time for general one-dimensional diﬀusion processes. The efﬁciency of the method, which is essentially based on Girsanov’s transformation, is described through theoretical results and numerical examples.},
	language = {en},
	urldate = {2022-12-20},
	publisher = {arXiv},
	author = {Herrmann, Samuel and Zucca, Cristina},
	month = may,
	year = {2017},
	note = {arXiv:1705.06881 [math]},
	keywords = {Mathematics - Probability},
	file = {Herrmann en Zucca - 2017 - Exact simulation of the first-passage time of diff.pdf:C\:\\Users\\Admin\\Zotero\\storage\\UZ8C3VE3\\Herrmann en Zucca - 2017 - Exact simulation of the first-passage time of diff.pdf:application/pdf},
}

@misc{noauthor_volterra_2022,
	title = {Volterra integral equation},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Volterra_integral_equation&oldid=1125547908},
	abstract = {In mathematics, the Volterra integral equations are a special type of integral equations. They are divided into two groups referred to as the first and the second kind.
A linear Volterra equation of the first kind is

  
    
      
        f
        (
        t
        )
        =
        
          ∫
          
            a
          
          
            t
          
        
        K
        (
        t
        ,
        s
        )
        
        x
        (
        s
        )
        
        d
        s
      
    
    \{{\textbackslash}displaystyle f(t)={\textbackslash}int \_\{a\}{\textasciicircum}\{t\}K(t,s){\textbackslash},x(s){\textbackslash},ds\}
  where f is a given function and x is an unknown function to be solved for.  A linear Volterra equation of the second kind is

  
    
      
        x
        (
        t
        )
        =
        f
        (
        t
        )
        +
        
          ∫
          
            a
          
          
            t
          
        
        K
        (
        t
        ,
        s
        )
        x
        (
        s
        )
        
        d
        s
        .
      
    
    \{{\textbackslash}displaystyle x(t)=f(t)+{\textbackslash}int \_\{a\}{\textasciicircum}\{t\}K(t,s)x(s){\textbackslash},ds.\}
  In operator theory, and in Fredholm theory, the corresponding operators are called Volterra operators.  A useful method to solve such equations, the Adomian decomposition method, is due to George Adomian.
A linear Volterra integral equation is a convolution equation if

  
    
      
        x
        (
        t
        )
        =
        f
        (
        t
        )
        +
        
          ∫
          
            
              t
              
                0
              
            
          
          
            t
          
        
        K
        (
        t
        −
        s
        )
        x
        (
        s
        )
        
        d
        s
        .
      
    
    \{{\textbackslash}displaystyle x(t)=f(t)+{\textbackslash}int \_\{t\_\{0\}\}{\textasciicircum}\{t\}K(t-s)x(s){\textbackslash},ds.\}
  The function 
  
    
      
        K
      
    
    \{{\textbackslash}displaystyle K\}
   in the integral is called the kernel. Such equations can be analyzed and solved by means of Laplace transform techniques.
For a weakly singular kernel of the form 
  
    
      
        K
        (
        t
        ,
        s
        )
        =
        (
        
          t
          
            2
          
        
        −
        
          s
          
            2
          
        
        
          )
          
            −
            α
          
        
      
    
    \{{\textbackslash}displaystyle K(t,s)=(t{\textasciicircum}\{2\}-s{\textasciicircum}\{2\}){\textasciicircum}\{-{\textbackslash}alpha \}\}
   with 
  
    
      
        0
        {\textless}
        α
        {\textless}
        1
      
    
    \{{\textbackslash}displaystyle 0{\textless}{\textbackslash}alpha {\textless}1\}
  , Volterra integral equation of the first kind can conveniently be transformed into a classical Abel integral equation. 
The Volterra integral equations were introduced by Vito Volterra and then studied by Traian Lalescu in his 1908 thesis, Sur les équations de Volterra, written under the direction of Émile Picard.   In 1911, Lalescu wrote the first book ever on integral equations.
Volterra integral equations find application in demography as Lotka's integral equation, the study of viscoelastic materials,
in actuarial science through the renewal equation, and in fluid mechanics to describe the flow behavior near finite-sized boundaries.},
	language = {en},
	urldate = {2022-12-20},
	journal = {Wikipedia},
	month = dec,
	year = {2022},
	note = {Page Version ID: 1125547908},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\BXA6JUFN\\Volterra_integral_equation.html:text/html},
}

@misc{yang_walk_2015,
	title = {Walk on {Spheres} {Algorithm} for {Helmholtz} and {Yukawa} {Equations} via {Duffin} {Correspondence}},
	url = {http://arxiv.org/abs/1512.07725},
	abstract = {We show that a constant-potential time-independent Schro¨dinger equation with Dirichlet boundary data can be reformulated as a Laplace equation with Dirichlet boundary data. With this reformulation, which we call the Duﬃn correspondence, we provide a classical Walk On Spheres (WOS) algorithm for Monte Carlo simulation of the solutions of the boundary value problem. We compare the obtained Duﬃn WOS algorithm with existing modiﬁed WOS algorithms.},
	language = {en},
	urldate = {2022-12-20},
	publisher = {arXiv},
	author = {Yang, Xuxin and Rasila, Antti and Sottinen, Tommi},
	month = dec,
	year = {2015},
	note = {arXiv:1512.07725 [math]},
	keywords = {Mathematics - Analysis of PDEs, Mathematics - Probability, Mathematics - Numerical Analysis, 65C05, 68U20, 35Q40},
	annote = {Comment: 14 pages, 5 figures},
	file = {Yang e.a. - 2015 - Walk on Spheres Algorithm for Helmholtz and Yukawa.pdf:C\:\\Users\\Admin\\Zotero\\storage\\3XFZ3E64\\Yang e.a. - 2015 - Walk on Spheres Algorithm for Helmholtz and Yukawa.pdf:application/pdf},
}

@article{lejay_new_2013,
	title = {New {Monte} {Carlo} schemes for simulating diffusions in discontinuous media},
	volume = {245},
	issn = {03770427},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377042712005444},
	doi = {10.1016/j.cam.2012.12.013},
	abstract = {We introduce new Monte Carlo simulation schemes for diﬀusions in a discontinuous media divided in subdomains with piecewise constant diﬀusivity. These schemes are higher order extensions of the usual schemes and take into account the two dimensional aspects of the diﬀusion at the interface between subdomains. This is achieved using either stochastic processes techniques or an approach based on ﬁnite diﬀerences. Numerical tests on elliptic, parabolic and eigenvalue problems involving an operator in divergence form show the eﬃciency of these new schemes.},
	language = {en},
	urldate = {2022-12-20},
	journal = {Journal of Computational and Applied Mathematics},
	author = {Lejay, Antoine and Maire, Sylvain},
	month = jun,
	year = {2013},
	pages = {97--116},
	file = {Lejay en Maire - 2013 - New Monte Carlo schemes for simulating diffusions .pdf:C\:\\Users\\Admin\\Zotero\\storage\\U84MVIQQ\\Lejay en Maire - 2013 - New Monte Carlo schemes for simulating diffusions .pdf:application/pdf},
}

@article{herrmann_first-passage_2016,
	title = {The first-passage time of the {Brownian} motion to a curved boundary: an algorithmic approach},
	volume = {38},
	issn = {1064-8275, 1095-7197},
	shorttitle = {The first-passage time of the {Brownian} motion to a curved boundary},
	url = {http://arxiv.org/abs/1501.07060},
	doi = {10.1137/151006172},
	abstract = {Under some weak conditions, the ﬁrst-passage time of the Brownian motion to a continuous curved boundary is an almost surely ﬁnite stopping time. Its probability density function (pdf) is explicitly known only in few particular cases. Several mathematical studies proposed to approximate the pdf in a quite general framework or even to simulate this hitting time using a discrete time approximation of the Brownian motion. The authors study a new algorithm which permits to simulate the ﬁrst-passage time using an iterating procedure. The convergence rate presented in this paper suggests that the method is very eﬃcient.},
	language = {en},
	number = {1},
	urldate = {2022-12-20},
	journal = {SIAM Journal on Scientific Computing},
	author = {Herrmann, Samuel and Tanré, Etienne},
	month = jan,
	year = {2016},
	note = {arXiv:1501.07060 [math]},
	keywords = {Mathematics - Probability, 65C05, 65N75, 60G40},
	pages = {A196--A215},
	file = {Herrmann en Tanré - 2016 - The first-passage time of the Brownian motion to a.pdf:C\:\\Users\\Admin\\Zotero\\storage\\5NRAE68H\\Herrmann en Tanré - 2016 - The first-passage time of the Brownian motion to a.pdf:application/pdf},
}

@misc{pentland_error_2022,
	title = {Error bound analysis of the stochastic parareal algorithm},
	url = {http://arxiv.org/abs/2211.05496},
	abstract = {Stochastic parareal (SParareal) is a probabilistic variant of the popular parallel-intime algorithm known as parareal. Similarly to parareal, it combines ﬁne- and coarse-grained solutions to an ordinary diﬀerential equation (ODE) using a predictor-corrector (PC) scheme. The key diﬀerence is that carefully chosen random perturbations are added to the PC to try to accelerate the location of a stochastic solution to the ODE. In this paper, we derive superlinear and linear mean-square error bounds for SParareal applied to nonlinear systems of ODEs using diﬀerent types of perturbations. We illustrate these bounds numerically on a linear system of ODEs and a scalar nonlinear ODE, showing a good match between theory and numerics.},
	language = {en},
	urldate = {2023-02-25},
	publisher = {arXiv},
	author = {Pentland, Kamran and Tamborrino, Massimiliano and Sullivan, T. J.},
	month = nov,
	year = {2022},
	note = {arXiv:2211.05496 [cs, math, stat]},
	keywords = {Mathematics - Numerical Analysis, Statistics - Computation, 65L70, 65Y05, 65C99},
	file = {Pentland e.a. - 2022 - Error bound analysis of the stochastic parareal al.pdf:C\:\\Users\\Admin\\Zotero\\storage\\STV8JTHP\\Pentland e.a. - 2022 - Error bound analysis of the stochastic parareal al.pdf:application/pdf},
}

@misc{carrel_low-rank_2022,
	title = {Low-rank {Parareal}: a low-rank parallel-in-time integrator},
	shorttitle = {Low-rank {Parareal}},
	url = {http://arxiv.org/abs/2203.08455},
	abstract = {In this work, the Parareal algorithm is applied to evolution problems that admit good low-rank approximations and for which the dynamical low-rank approximation (DLRA) can be used as time stepper. Many discrete integrators for DLRA have recently been proposed, based on splitting the projected vector ﬁeld or by applying projected Runge–Kutta methods. The cost and accuracy of these methods are mostly governed by the rank chosen for the approximation. These properties are used in a new method, called low-rank Parareal, in order to obtain a time-parallel DLRA solver for evolution problems. The algorithm is analyzed on aﬃne linear problems and the results are illustrated numerically.},
	language = {en},
	urldate = {2023-02-25},
	publisher = {arXiv},
	author = {Carrel, Benjamin and Gander, Martin J. and Vandereycken, Bart},
	month = sep,
	year = {2022},
	note = {arXiv:2203.08455 [cs, math]},
	keywords = {Mathematics - Numerical Analysis, 65L05, 65L20, 65L70, 68W10, 65F45, 65F55},
	file = {Carrel e.a. - 2022 - Low-rank Parareal a low-rank parallel-in-time int.pdf:C\:\\Users\\Admin\\Zotero\\storage\\L5268KDM\\Carrel e.a. - 2022 - Low-rank Parareal a low-rank parallel-in-time int.pdf:application/pdf},
}

@article{gander_analysis_2008,
	title = {Analysis of a {Krylov} subspace enhanced parareal algorithm for linear problems},
	volume = {25},
	issn = {1270-900X},
	url = {http://www.esaim-proc.org/10.1051/proc:082508},
	doi = {10.1051/proc:082508},
	abstract = {The parareal algorithm is a numerical method to integrate evolution problems on parallel computers. The performance of the algorithm is well understood for diﬀusive problems, and it can have spectacular performance when applied to certain non-linear problems. Its convergence properties are however less favorable for hyperbolic problems. We present and analyze in this paper a variant of the parareal algorithm, recently proposed in the PITA framework for systems of second order ordinary diﬀerential equations.},
	language = {en},
	urldate = {2023-02-25},
	journal = {ESAIM: Proceedings},
	author = {Gander, M. and Petcu, M.},
	editor = {Cancès, E. and Faure, S. and Graille, B.},
	year = {2008},
	pages = {114--129},
	file = {Gander en Petcu - 2008 - Analysis of a Krylov subspace enhanced parareal al.pdf:C\:\\Users\\Admin\\Zotero\\storage\\Q9UAI328\\Gander en Petcu - 2008 - Analysis of a Krylov subspace enhanced parareal al.pdf:application/pdf},
}

@misc{gander_unified_2023,
	title = {A unified analysis framework for iterative parallel-in-time algorithms},
	url = {http://arxiv.org/abs/2203.16069},
	abstract = {Parallel-in-time integration has been the focus of intensive research eﬀorts over the past two decades due to the advent of massively parallel computer architectures and the scaling limits of purely spatial parallelization. Various iterative parallel-in-time (PinT) algorithms have been proposed, like Parareal, PFASST, MGRIT, and Space-Time Multi-Grid (STMG). These methods have been described using diﬀerent notations, and the convergence estimates that are available are diﬃcult to compare. We describe Parareal, PFASST, MGRIT and STMG for the Dahlquist model problem using a common notation and give precise convergence estimates using generating functions. This allows us, for the ﬁrst time, to directly compare their convergence. We prove that all four methods eventually converge super-linearly, and also compare them numerically. The generating function framework provides further opportunities to explore and analyze existing and new methods.},
	language = {en},
	urldate = {2023-02-25},
	publisher = {arXiv},
	author = {Gander, M. J. and Lunet, T. and Ruprecht, D. and Speck, R.},
	month = feb,
	year = {2023},
	note = {arXiv:2203.16069 [cs, math]},
	keywords = {Mathematics - Numerical Analysis, Computer Science - Computational Engineering, Finance, and Science},
	file = {2203.16069.pdf:C\:\\Users\\Admin\\Zotero\\storage\\ARYQ6U3W\\2203.16069.pdf:application/pdf},
}

@misc{maday_adaptive_2020,
	title = {An {Adaptive} {Parareal} {Algorithm}},
	url = {http://arxiv.org/abs/1909.08333},
	abstract = {In this paper, we consider the problem of accelerating the numerical simulation of time dependent problems by time domain decomposition. The available algorithms enabling such decompositions present severe eﬃciency limitations and are an obstacle for the solution of large scale and high dimensional problems. Our main contribution is the improvement of the parallel eﬃciency of the parareal in time method. The parareal method is based on combining predictions made by a numerically inexpensive solver (with coarse physics and/or coarse resolution) with corrections coming from an expensive solver (with highﬁdelity physics and high resolution). At convergence, the algorithm provides a solution that has the ﬁne solver’s high-ﬁdelity physics and high resolution. In the classical version, the ﬁne solver has a ﬁxed high accuracy which is the major obstacle to achieve a competitive parallel eﬃciency. In this paper, we develop an adaptive variant that overcomes this obstacle by dynamically increasing the accuracy of the ﬁne solver across the parareal iterations. We theoretically show that the parallel eﬃciency becomes very competitive in the ideal case where the cost of the coarse solver is small, thus proving that the only remaining factors impeding full scalability become the cost of the coarse solver and communication time. The developed theory has also the merit of setting a general framework to understand the success of several extensions of parareal based on iteratively improving the quality of the ﬁne solver and re-using information from previous parareal steps. We illustrate the actual performance of the method in stiﬀ ODEs, which are a challenging family of problems since the only mechanism for adaptivity is time and eﬃciency is aﬀected by the cost of the coarse solver.},
	language = {en},
	urldate = {2023-02-25},
	publisher = {arXiv},
	author = {Maday, Y. and Mula, O.},
	month = mar,
	year = {2020},
	note = {arXiv:1909.08333 [cs, math]},
	keywords = {Mathematics - Numerical Analysis, 65M12, 65N55, 65Y05, 65Y20},
	file = {Maday en Mula - 2020 - An Adaptive Parareal Algorithm.pdf:C\:\\Users\\Admin\\Zotero\\storage\\3JZWT34D\\Maday en Mula - 2020 - An Adaptive Parareal Algorithm.pdf:application/pdf},
}

@misc{noauthor_monte_2023,
	title = {Monte {Carlo} integration},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Monte_Carlo_integration&oldid=1135560956},
	abstract = {In mathematics, Monte Carlo integration is a technique for numerical integration using random numbers. It is a particular Monte Carlo method that numerically computes a definite integral. While other algorithms usually evaluate the integrand at a regular grid, Monte Carlo randomly chooses points at which the integrand is evaluated. This method is particularly useful for higher-dimensional integrals.There are different methods to perform a Monte Carlo integration, such as uniform sampling, stratified sampling, importance sampling, sequential Monte Carlo (also known as a particle filter), and mean-field particle methods.},
	language = {en},
	urldate = {2023-03-01},
	journal = {Wikipedia},
	month = jan,
	year = {2023},
	note = {Page Version ID: 1135560956},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\GELHMB8Z\\Monte_Carlo_integration.html:text/html},
}

@article{lepage_adaptive_2021,
	title = {Adaptive {Multidimensional} {Integration}: {VEGAS} {Enhanced}},
	volume = {439},
	issn = {00219991},
	shorttitle = {Adaptive {Multidimensional} {Integration}},
	url = {http://arxiv.org/abs/2009.05112},
	doi = {10.1016/j.jcp.2021.110386},
	abstract = {We describe a new algorithm, VEGAS+, for adaptive multidimensional Monte Carlo integration. The new algorithm adds a second adaptive strategy, adaptive stratiﬁed sampling, to the adaptive importance sampling that is the basis for its widely used predecessor VEGAS. Both VEGAS and VEGAS+ are effective for integrands with large peaks, but VEGAS+ can be much more effective for integrands with multiple peaks or other signiﬁcant structures aligned with diagonals of the integration volume. We give examples where VEGAS+ is 2–19× more accurate than VEGAS. We also show how to combine VEGAS+ with other integrators, such as the widely available MISER algorithm, to make new hybrid integrators. For a different kind of hybrid, we show how to use integrand samples, generated using MCMC or other methods, to optimize VEGAS+ before integrating. We give an example where preconditioned VEGAS+ is more than 100× as efﬁcient as VEGAS+ without preconditioning. Finally, we give examples where VEGAS+ is more than 10× as efﬁcient as MCMC for Bayesian integrals with D = 3 and 21 parameters. We explain why VEGAS+ will often outperform MCMC for small and moderate sized problems.},
	language = {en},
	urldate = {2023-03-01},
	journal = {Journal of Computational Physics},
	author = {Lepage, G. Peter},
	month = aug,
	year = {2021},
	note = {arXiv:2009.05112 [hep-ph, physics:physics]},
	keywords = {Physics - Computational Physics, High Energy Physics - Phenomenology},
	pages = {110386},
	annote = {Comment: 23 pages, 11 figures},
	file = {Lepage - 2021 - Adaptive Multidimensional Integration VEGAS Enhan.pdf:C\:\\Users\\Admin\\Zotero\\storage\\HQJAQY43\\Lepage - 2021 - Adaptive Multidimensional Integration VEGAS Enhan.pdf:application/pdf},
}

@article{mousavi_hamiltonian_2021,
	title = {Hamiltonian {Adaptive} {Importance} {Sampling}},
	volume = {28},
	issn = {1070-9908, 1558-2361},
	url = {http://arxiv.org/abs/2209.13716},
	doi = {10.1109/LSP.2021.3068616},
	abstract = {Importance sampling (IS) is a powerful Monte Carlo (MC) methodology for approximating integrals, for instance in the context of Bayesian inference. In IS, the samples are simulated from the so-called proposal distribution, and the choice of this proposal is key for achieving a high performance. In adaptive IS (AIS) methods, a set of proposals is iteratively improved. AIS is a relevant and timely methodology although many limitations remain yet to be overcome, e.g., the curse of dimensionality in high-dimensional and multi-modal problems. Moreover, the Hamiltonian Monte Carlo (HMC) algorithm has become increasingly popular in machine learning and statistics. HMC has several appealing features such as its exploratory behavior, especially in high-dimensional targets, when other methods suffer. In this paper, we introduce the novel Hamiltonian adaptive importance sampling (HAIS) method. HAIS implements a two-step adaptive process with parallel HMC chains that cooperate at each iteration. The proposed HAIS efﬁciently adapts a population of proposals, extracting the advantages of HMC. HAIS can be understood as a particular instance of the generic layered AIS family with an additional resampling step. HAIS achieves a signiﬁcant performance improvement in high-dimensional problems w.r.t. state-of-the-art algorithms. We discuss the statistical properties of HAIS and show its high performance in two challenging examples.},
	language = {en},
	urldate = {2023-03-01},
	journal = {IEEE Signal Processing Letters},
	author = {Mousavi, Ali and Monsefi, Reza and Elvira, Víctor},
	year = {2021},
	note = {arXiv:2209.13716 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {713--717},
	file = {Mousavi e.a. - 2021 - Hamiltonian Adaptive Importance Sampling.pdf:C\:\\Users\\Admin\\Zotero\\storage\\CKVBTMH7\\Mousavi e.a. - 2021 - Hamiltonian Adaptive Importance Sampling.pdf:application/pdf},
}

@article{carrazza_vegasflow_2020,
	title = {{VegasFlow}: accelerating {Monte} {Carlo} simulation across multiple hardware platforms},
	volume = {254},
	issn = {00104655},
	shorttitle = {{VegasFlow}},
	url = {http://arxiv.org/abs/2002.12921},
	doi = {10.1016/j.cpc.2020.107376},
	abstract = {We present VegasFlow , a new software for fast evaluation of high dimensional integrals based on Monte Carlo integration techniques designed for platforms with hardware accelerators. The growing complexity of calculations and simulations in many areas of science have been accompanied by advances in the computational tools which have helped their developments. VegasFlow enables developers to delegate all complicated aspects of hardware or platform implementation to the library so they can focus on the problem at hand. This software is inspired on the Vegas algorithm, ubiquitous in the particle physics community as the driver of cross section integration, and based on Google’s powerful TensorFlow library. We benchmark the performance of this library on many diﬀerent consumer and professional grade GPUs and CPUs.},
	language = {en},
	urldate = {2023-03-01},
	journal = {Computer Physics Communications},
	author = {Carrazza, Stefano and Cruz-Martinez, Juan M.},
	month = sep,
	year = {2020},
	note = {arXiv:2002.12921 [hep-ex, physics:hep-ph, physics:physics, stat]},
	keywords = {Statistics - Machine Learning, Physics - Computational Physics, High Energy Physics - Phenomenology, High Energy Physics - Experiment},
	pages = {107376},
	annote = {Comment: 6 pages, 5 figures, final version published in CPC},
	file = {Carrazza en Cruz-Martinez - 2020 - VegasFlow accelerating Monte Carlo simulation acr.pdf:C\:\\Users\\Admin\\Zotero\\storage\\DVF3BGFQ\\Carrazza en Cruz-Martinez - 2020 - VegasFlow accelerating Monte Carlo simulation acr.pdf:application/pdf},
}

@misc{noauthor_hardware_2022,
	title = {Hardware acceleration},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Hardware_acceleration&oldid=1098931508},
	abstract = {Hardware acceleration is the use of computer hardware designed to perform specific functions more efficiently when compared to software running on a general-purpose central processing unit (CPU). Any transformation of data that can be calculated in software running on a generic CPU can also be calculated in custom-made hardware, or in some mix of both.
To perform computing tasks more quickly (or better in some other way), generally one can invest time and money in improving the software, improving the hardware, or both. There are various approaches with advantages and disadvantages in terms of decreased latency, increased throughput and reduced energy consumption. Typical advantages of focusing on software may include more rapid development, lower non-recurring engineering costs, heightened portability, and ease of updating features or patching bugs, at the cost of overhead to compute general operations. Advantages of focusing on hardware may include speedup, reduced power consumption, lower latency, increased parallelism and bandwidth, and better utilization of area and functional components available on an integrated circuit; at the cost of lower ability to update designs once etched onto silicon and higher costs of functional verification, and times to market. In the hierarchy of digital computing systems ranging from general-purpose processors to fully customized hardware, there is a tradeoff between flexibility and efficiency, with efficiency increasing by orders of magnitude when any given application is implemented higher up that hierarchy. This hierarchy includes general-purpose processors such as CPUs, more specialized processors such as GPUs, fixed-function implemented on field-programmable gate arrays (FPGAs), and fixed-function implemented on application-specific integrated circuits (ASICs).Hardware acceleration is advantageous for performance, and practical when the functions are fixed so updates are not as needed as in software solutions. With the advent of reprogrammable logic devices such as FPGAs, the restriction of hardware acceleration to fully fixed algorithms has eased since 2010, allowing hardware acceleration to be applied to problem domains requiring modification to algorithms and processing control flow. The disadvantage however, is that in many open source projects, it requires proprietary libraries that not all vendors are keen to distribute or expose, making it difficult to integrate in such projects.},
	language = {en},
	urldate = {2023-03-01},
	journal = {Wikipedia},
	month = jul,
	year = {2022},
	note = {Page Version ID: 1098931508},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\DYFFG8BP\\Hardware_acceleration.html:text/html},
}

@misc{bendavid_efficient_2017,
	title = {Efficient {Monte} {Carlo} {Integration} {Using} {Boosted} {Decision} {Trees} and {Generative} {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1707.00028},
	abstract = {New machine learning based algorithms have been developed and tested for Monte Carlo integration based on generative Boosted Decision Trees and Deep Neural Networks. Both of these algorithms exhibit substantial improvements compared to existing algorithms for non-factorizable integrands in terms of the achievable integration precision for a given number of target function evaluations. Large scale Monte Carlo generation of complex collider physics processes with improved eﬃciency can be achieved by implementing these algorithms into commonly used matrix element Monte Carlo generators once their robustness is demonstrated and performance validated for the relevant classes of matrix elements.},
	language = {en},
	urldate = {2023-03-01},
	publisher = {arXiv},
	author = {Bendavid, Joshua},
	month = jun,
	year = {2017},
	note = {arXiv:1707.00028 [hep-ph, physics:physics]},
	keywords = {Physics - Computational Physics, High Energy Physics - Phenomenology},
	file = {Bendavid - 2017 - Efficient Monte Carlo Integration Using Boosted De.pdf:C\:\\Users\\Admin\\Zotero\\storage\\VAWIJ2CM\\Bendavid - 2017 - Efficient Monte Carlo Integration Using Boosted De.pdf:application/pdf},
}

@article{huang_evaluation_nodate,
	title = {Evaluation of an {Analog} {Accelerator} for {Linear} {Algebra}},
	abstract = {Due to the end of supply voltage scaling and the increasing percentage of dark silicon in modern integrated circuits, researchers are looking for new scalable ways to get useful computation from existing silicon technology. In this paper we present a reconﬁgurable analog accelerator for solving systems of linear equations. Commonly perceived downsides of analog computing, such as low precision and accuracy, limited problem sizes, and difﬁculty in programming are all compensated for using methods we discuss. Based on a prototyped analog accelerator chip we compare the performance and energy consumption of the analog solver against an efﬁcient digital algorithm running on a CPU, and ﬁnd that the analog accelerator approach may be an order of magnitude faster and provide one third energy savings, depending on the accelerator design. Due to the speed and efﬁciency of linear algebra algorithms running on digital computers, an analog accelerator that matches digital performance needs a large silicon footprint. Finally, we conclude that problem classes outside of systems of linear equations may hold more promise for analog acceleration.},
	language = {en},
	author = {Huang, Yipeng and Guo, Ning and Seok, Mingoo and Tsividis, Yannis and Sethumadhavan, Simha},
	file = {Huang e.a. - Evaluation of an Analog Accelerator for Linear Alg.pdf:C\:\\Users\\Admin\\Zotero\\storage\\TF7SI6TR\\Huang e.a. - Evaluation of an Analog Accelerator for Linear Alg.pdf:application/pdf},
}

@misc{noauthor_analog_2023,
	title = {Analog computer},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Analog_computer&oldid=1140592830},
	abstract = {An analog computer or analogue computer is a type of computer that uses the continuous variation aspect of physical phenomena such as electrical, mechanical, or hydraulic quantities (analog signals) to model the problem being solved. In contrast, digital computers represent varying quantities symbolically and by discrete values of both time and amplitude (digital signals).
Analog computers can have a very wide range of complexity. Slide rules and nomograms are the simplest, while naval gunfire control computers and large hybrid digital/analog computers were among the most complicated. Complex mechanisms for process control and protective relays used analog computation to perform control and protective functions.
Analog computers were widely used in scientific and industrial applications even after the advent of digital computers, because at the time they were typically much faster, but they started to become obsolete as early as the 1950s and 1960s, although they remained in use in some specific applications, such as aircraft flight simulators, the flight computer in aircraft, and for teaching control systems in universities. Perhaps the most relatable example of analog computers are mechanical watches where the continuous and periodic rotation of interlinked gears drives the seconds, minutes and hours needles in the clock. More complex applications, such as aircraft flight simulators and synthetic-aperture radar, remained the domain of analog computing (and hybrid computing) well into the 1980s, since digital computers were insufficient for the task.},
	language = {en},
	urldate = {2023-03-01},
	journal = {Wikipedia},
	month = feb,
	year = {2023},
	note = {Page Version ID: 1140592830},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\78SJPMU4\\Analog_computer.html:text/html},
}

@article{guo_investigation_nodate,
	title = {Investigation of {Energy}-{Efficient} {Hybrid} {Analog}/{Digital} {Approximate} {Computation} in {Continuous} {Time}},
	language = {en},
	author = {Guo, Ning},
	file = {Guo - Investigation of Energy-Efficient Hybrid AnalogDi.pdf:C\:\\Users\\Admin\\Zotero\\storage\\DZW3H37R\\Guo - Investigation of Energy-Efficient Hybrid AnalogDi.pdf:application/pdf},
}

@inproceedings{huang_case_2018,
	address = {Shanghai, China},
	title = {A {Case} {Study} in {Analog} {Co}-{Processing} for {Solving} {Stochastic} {Differential} {Equations}},
	isbn = {978-1-5386-6811-5},
	url = {https://ieeexplore.ieee.org/document/8631831/},
	doi = {10.1109/ICDSP.2018.8631831},
	abstract = {Stochastic differential equations (SDEs) are an important class of mathematical models for areas such as physics and ﬁnance. Usually the model outputs are in the form of statistics of the dependent variables, generated from many solutions of the SDE using different samples of the random variables. Challenges in using existing conventional digital computer architectures for solving SDEs include: rapidly generating the random input variables for the SDE solutions, and having to use numerical integration to solve the differential equations. Recent work by our group has explored using hybrid analog-digital computing to solve differential equations. In the hybrid computing model, we solve differential equations by encoding variables as continuous values, which evolve in continuous time. In this paper we review the prior work, and study using the architecture, in conjunction with analog noise, to solve a canonical SDE, the Black-Scholes SDE.},
	language = {en},
	urldate = {2023-03-01},
	booktitle = {2018 {IEEE} 23rd {International} {Conference} on {Digital} {Signal} {Processing} ({DSP})},
	publisher = {IEEE},
	author = {Huang, Yipeng and Guo, Ning and Sethumadhavan, Simha and Seok, Mingoo and Tsividis, Yannis},
	month = nov,
	year = {2018},
	pages = {1--5},
	file = {Huang e.a. - 2018 - A Case Study in Analog Co-Processing for Solving S.pdf:C\:\\Users\\Admin\\Zotero\\storage\\DVZPDWCW\\Huang e.a. - 2018 - A Case Study in Analog Co-Processing for Solving S.pdf:application/pdf},
}

@inproceedings{huang_hybrid_2017,
	address = {Cambridge Massachusetts},
	title = {Hybrid analog-digital solution of nonlinear partial differential equations},
	isbn = {978-1-4503-4952-9},
	url = {https://dl.acm.org/doi/10.1145/3123939.3124550},
	doi = {10.1145/3123939.3124550},
	abstract = {We tackle the important problem class of solving nonlinear partial di↵erential equations. While nonlinear PDEs are typically solved in high-performance supercomputers, they are increasingly used in graphics and embedded systems, where e ciency is important.},
	language = {en},
	urldate = {2023-03-01},
	booktitle = {Proceedings of the 50th {Annual} {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture}},
	publisher = {ACM},
	author = {Huang, Yipeng and Guo, Ning and Seok, Mingoo and Tsividis, Yannis and Mandli, Kyle and Sethumadhavan, Simha},
	month = oct,
	year = {2017},
	pages = {665--678},
	file = {Huang e.a. - 2017 - Hybrid analog-digital solution of nonlinear partia.pdf:C\:\\Users\\Admin\\Zotero\\storage\\WZ7SMKY8\\Huang e.a. - 2017 - Hybrid analog-digital solution of nonlinear partia.pdf:application/pdf},
}

@article{georgiev_integral_2019,
	title = {Integral formulations of volumetric transmittance},
	volume = {38},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/3355089.3356559},
	doi = {10.1145/3355089.3356559},
	abstract = {Computing the light attenuation between two given points is an essential yet expensive task in volumetric light transport simulation. Existing unbiased transmittance estimators are all based on "null-scattering" random walks enabled by augmenting the media with fictitious matter. This formulation prevents the use of traditional Monte Carlo estimator variance analysis, thus the efficiency of such methods is understood from a mostly empirical perspective. In this paper, we present several novel integral formulations of volumetric transmittance in which existing estimators arise as direct Monte Carlo estimators. Breaking from physical intuition, we show that the null-scattering concept is not strictly required for unbiased transmittance estimation, but is a form of control variates for effectively reducing variance. Our formulations bring new insight into the problem and the efficiency of existing estimators. They also provide a framework for devising new types of transmittance estimators with distinct and complementary performance tradeoffs, as well as a clear recipe for applying sample stratification.},
	language = {en},
	number = {6},
	urldate = {2023-03-02},
	journal = {ACM Transactions on Graphics},
	author = {Georgiev, Iliyan and Misso, Zackary and Hachisuka, Toshiya and Nowrouzezahrai, Derek and Křivánek, Jaroslav and Jarosz, Wojciech},
	month = dec,
	year = {2019},
	pages = {1--17},
	file = {3355089.pdf:C\:\\Users\\Admin\\Zotero\\storage\\J48ZZ86P\\3355089.pdf:application/pdf},
}

@misc{goda_randomizing_2022,
	title = {Randomizing the trapezoidal rule gives the optimal {RMSE} rate in {Gaussian} {Sobolev} spaces},
	url = {http://arxiv.org/abs/2212.11476},
	abstract = {Randomized quadratures for integrating functions in Sobolev spaces of order α ≥ 1, where the integrability condition is with respect to the Gaussian measure, are considered. In this function space, the optimal rate for the worst-case root-mean-squared error (RMSE) is established. Here, optimality is for a general class of quadratures, in which adaptive non-linear algorithms with a possibly varying number of function evaluations are also allowed. The optimal rate is given by showing matching bounds. First, a lower bound on the worst-case RMSE of O(n−α−1/2) is proven, where n denotes an upper bound on the expected number of function evaluations. It turns out that a suitably randomized trapezoidal rule attains this rate, up to a logarithmic factor. A practical error estimator for this trapezoidal rule is also presented. Numerical results support our theory.},
	language = {en},
	urldate = {2023-03-06},
	publisher = {arXiv},
	author = {Goda, Takashi and Kazashi, Yoshihito and Suzuki, Yuya},
	month = dec,
	year = {2022},
	note = {arXiv:2212.11476 [cs, math]},
	keywords = {Mathematics - Numerical Analysis},
	annote = {Comment: 21 pages},
	file = {Goda e.a. - 2022 - Randomizing the trapezoidal rule gives the optimal.pdf:C\:\\Users\\Admin\\Zotero\\storage\\E7GZXZDN\\Goda e.a. - 2022 - Randomizing the trapezoidal rule gives the optimal.pdf:application/pdf},
}

@misc{mitchell_decomposition_2022,
	title = {Decomposition and conformal mapping techniques for the quadrature of nearly singular integrals},
	url = {http://arxiv.org/abs/2210.09954},
	abstract = {Gauss-Legendre quadrature and the trapezoidal rule are powerful tools for numerical integration of analytic functions. For nearly singular problems, however, these standard methods become unacceptably slow. We discuss and generalize some existing methods for improving on these schemes when the location of the nearby singularity is known. We conclude with an application to some nearly singular surface integrals of viscous flow.},
	language = {en},
	urldate = {2023-03-06},
	publisher = {arXiv},
	author = {Mitchell, William and Natkin, Abbie and Robertson, Paige and Sullivan, Marika and Yu, Xuechen and Zhu, Chenxin},
	month = oct,
	year = {2022},
	note = {arXiv:2210.09954 [cs, math]},
	keywords = {Mathematics - Numerical Analysis, 65D32, 30C20, 76D07},
	file = {2210.09954.pdf:C\:\\Users\\Admin\\Zotero\\storage\\I4A6MUMA\\2210.09954.pdf:application/pdf},
}

@misc{izzo_convergence_2022,
	title = {Convergence of a class of high order corrected trapezoidal rules},
	url = {http://arxiv.org/abs/2208.08216},
	abstract = {We present convergence theory for corrected quadrature rules on uniform Cartesian grids for functions with a point singularity. We begin by deriving an error estimate for the punctured trapezoidal rule, and then derive error expansions. We deﬁne the corrected trapezoidal rules, based on the punctured trapezoidal rule, where the weights for the nodes close to the singularity are judiciously corrected based on these expansions. Then we deﬁne the composite corrected trapezoidal rules for a larger family of functions using series expansions around the point singularity and applying corrected trapezoidal rules appropriately. We prove that we can achieve high order accuracy by using a suﬃcient number of correction nodes around the point singularity and of expansion terms.},
	language = {en},
	urldate = {2023-03-06},
	publisher = {arXiv},
	author = {Izzo, Federico and Runborg, Olof and Tsai, Richard},
	month = aug,
	year = {2022},
	note = {arXiv:2208.08216 [cs, math]},
	keywords = {Mathematics - Numerical Analysis, 65D30, 65D32},
	annote = {Comment: 23 pages, 1 figure},
	file = {2208.08216.pdf:C\:\\Users\\Admin\\Zotero\\storage\\7BMQ6MUX\\2208.08216.pdf:application/pdf},
}

@article{song_high-order_2022,
	title = {High-order implicit time integration scheme based on {Pad}{\textbackslash}'e expansions},
	volume = {390},
	issn = {00457825},
	url = {http://arxiv.org/abs/2103.12282},
	doi = {10.1016/j.cma.2021.114436},
	abstract = {A single-step high-order implicit time integration scheme for the solution of transient and wave propagation problems is presented. It is constructed from the Pad´e expansions of the matrix exponential solution of a system of ﬁrst-order ordinary diﬀerential equations formulated in the state-space. A computationally eﬃcient scheme is developed exploiting the techniques of polynomial factorization and partial fractions of rational functions, and by decoupling the solution for the displacement and velocity vectors. An important feature of the novel algorithm is that no direct inversion of the mass matrix is required. From the diagonal Pad´e expansion of order M a time-stepping scheme of order 2M is developed. Here, each elevation of the accuracy by two orders results in an additional system of real or complex sparse equations to be solved. These systems are comparable in complexity to the standard Newmark method, i.e., the eﬀective system matrix is a linear combination of the static stiﬀness, damping, and mass matrices. It is shown that the second-order scheme is equivalent to Newmark’s constant average acceleration method, often also referred to as trapezoidal rule. The proposed time integrator has been implemented in MATLAB using the built-in direct linear equation solvers. In this article, numerical examples featuring nearly one million degrees of freedom are presented. High-accuracy and eﬃciency in comparison with common second-order time integration schemes are observed. The MATLAB-implementation is available from the authors upon request or from the GitHub repository (to be added).},
	language = {en},
	urldate = {2023-03-06},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Song, Chongmin and Eisenträger, Sascha},
	month = feb,
	year = {2022},
	note = {arXiv:2103.12282 [cs, math]},
	keywords = {Mathematics - Numerical Analysis, 65M22, G.1.3, G.1.8, J.2},
	pages = {114436},
	annote = {Comment: 43 pages, 19 figures},
	file = {2103.12282.pdf:C\:\\Users\\Admin\\Zotero\\storage\\NTJ24PYR\\2103.12282.pdf:application/pdf},
}

@article{kruse_error_2017,
	title = {Error analysis of randomized {Runge}-{Kutta} methods for differential equations with time-irregular coefficients},
	volume = {17},
	issn = {1609-9389, 1609-4840},
	url = {http://arxiv.org/abs/1701.03444},
	doi = {10.1515/cmam-2016-0048},
	abstract = {This paper contains an error analysis of two randomized explicit Runge-Kutta schemes for ordinary diﬀerential equations (ODEs) with timeirregular coeﬃcient functions. In particular, the methods are applicable to ODEs of Carath´eodory type, whose coeﬃcient functions are only integrable with respect to the time variable but are not assumed to be continuous. A further ﬁeld of application are ODEs with coeﬃcient functions that contain weak singularities with respect to the time variable.},
	language = {en},
	number = {3},
	urldate = {2023-03-06},
	journal = {Computational Methods in Applied Mathematics},
	author = {Kruse, Raphael and Wu, Yue},
	month = jul,
	year = {2017},
	note = {arXiv:1701.03444 [math]},
	keywords = {Mathematics - Numerical Analysis, 65C05, 65L05, 65L06, 65L20},
	pages = {479--498},
	annote = {Comment: 24 pages, 3 figures},
	file = {1701.03444.pdf:C\:\\Users\\Admin\\Zotero\\storage\\WF8T4VEL\\1701.03444.pdf:application/pdf},
}

@misc{wu_randomised_2020,
	title = {A randomised trapezoidal quadrature},
	url = {http://arxiv.org/abs/2011.15086},
	abstract = {A randomised trapezoidal quadrature rule is proposed for continuous functions which enjoys less regularity than commonly required. Indeed, we consider functions in some fractional Sobolev space. Various error bounds for this randomised rule are established while an error bound for classical trapezoidal quadrature is obtained for comparison. The randomised trapezoidal quadrature rule is shown to improve the order of convergence by half.},
	language = {en},
	urldate = {2023-03-06},
	publisher = {arXiv},
	author = {Wu, Yue},
	month = dec,
	year = {2020},
	note = {arXiv:2011.15086 [cs, math]},
	keywords = {Mathematics - Probability, Mathematics - Numerical Analysis, 65C05, 65D30},
	file = {Wu - 2020 - A randomised trapezoidal quadrature.pdf:C\:\\Users\\Admin\\Zotero\\storage\\ZZ4A2GLQ\\Wu - 2020 - A randomised trapezoidal quadrature.pdf:application/pdf},
}

@misc{grant_elementary_2019,
	title = {Elementary numerical methods for double integrals},
	url = {http://arxiv.org/abs/1905.05805},
	abstract = {Approximations to the integral \${\textbackslash}int\_a{\textasciicircum}b{\textbackslash}int\_c{\textasciicircum}d f(x,y){\textbackslash},dy{\textbackslash},dx\$ are obtained under the assumption that the partial derivatives of the integrand are in an \$L{\textasciicircum}p\$ space, for some \$1{\textbackslash}leq p{\textbackslash}leq{\textbackslash}infty\$. We assume \$\{{\textbackslash}lVert f\_\{xy\}{\textbackslash}rVert\}\_p\$ is bounded (integration over \$[a,b]{\textbackslash}times[c,d]\$), assume \$\{{\textbackslash}lVert f\_x({\textbackslash}cdot,c){\textbackslash}rVert\}\_p\$ and \$\{{\textbackslash}lVert f\_x({\textbackslash}cdot,d){\textbackslash}rVert\}\_p\$ are bounded (integration over \$[a,b]\$), and assume \$\{{\textbackslash}lVert f\_y(a,{\textbackslash}cdot){\textbackslash}rVert\}\_p\$ and \$\{{\textbackslash}lVert f\_y(b,{\textbackslash}cdot){\textbackslash}rVert\}\_p\$ are bounded (integration over \$[c,d]\$). The methods are elementary, using only integration by parts and H{\textbackslash}"older's inequality. Versions of the trapezoidal rule, composite trapezoidal rule, midpoint rule and composite midpoint rule are given, with error estimates in terms of the above norms.},
	language = {en},
	urldate = {2023-03-06},
	publisher = {arXiv},
	author = {Grant, Cameron and Talvila, Erik},
	month = may,
	year = {2019},
	note = {arXiv:1905.05805 [math]},
	keywords = {Mathematics - Numerical Analysis, Primary 41A55, 65D30. Secondary 26D15},
	annote = {Comment: To appear in Minnesota Journal of Undergraduate Mathematics},
	file = {Grant en Talvila - 2019 - Elementary numerical methods for double integrals.pdf:C\:\\Users\\Admin\\Zotero\\storage\\C2T9FPFP\\Grant en Talvila - 2019 - Elementary numerical methods for double integrals.pdf:application/pdf},
}

@misc{brune_derivative_2018,
	title = {Derivative {Corrections} to the {Trapezoidal} {Rule}},
	url = {http://arxiv.org/abs/1808.04743},
	abstract = {Extensions to the trapezoidal rule using derivative information are studied for periodic integrands and integrals along the entire real line. Integrands which are analytic within a half plane or within a strip containing the path of integration are considered. Derivative-free error bounds are obtained. Alternative approaches to including derivative information are discussed.},
	language = {en},
	urldate = {2023-03-06},
	publisher = {arXiv},
	author = {Brune, Carl R.},
	month = aug,
	year = {2018},
	note = {arXiv:1808.04743 [math]},
	keywords = {Mathematics - Numerical Analysis, 65D32},
	annote = {Comment: 19 pages, 2 figures},
	file = {Brune - 2018 - Derivative Corrections to the Trapezoidal Rule.pdf:C\:\\Users\\Admin\\Zotero\\storage\\ADTJQB7R\\Brune - 2018 - Derivative Corrections to the Trapezoidal Rule.pdf:application/pdf},
}

@misc{christopoulos_polynomial_2013,
	title = {Polynomial regression using trapezoidal rule for computing {Legendre} coefficients},
	url = {http://arxiv.org/abs/1311.7525},
	abstract = {We are presenting a method for computing the Fourier coeﬃcients of a given polynomial regression by using the trapezoidal rule for numerical integration. As function basis we use the orthogonal Legendre polynomials. The results are accurate and stable compared to Forsythe’s method.},
	language = {en},
	urldate = {2023-03-06},
	publisher = {arXiv},
	author = {Christopoulos, Demetris T.},
	month = nov,
	year = {2013},
	note = {arXiv:1311.7525 [math, stat]},
	keywords = {Mathematics - Numerical Analysis, Statistics - Computation, Primary 62J05, Secondary 65D99},
	annote = {Comment: 13 pages, 2 figures, 4 tables},
	file = {Christopoulos - 2013 - Polynomial regression using trapezoidal rule for c.pdf:C\:\\Users\\Admin\\Zotero\\storage\\MNCK7RST\\Christopoulos - 2013 - Polynomial regression using trapezoidal rule for c.pdf:application/pdf},
}

@misc{talvila_simple_2012,
	title = {Simple derivation of basic quadrature formulas},
	url = {http://arxiv.org/abs/1202.0249},
	abstract = {Simple proofs of the midpoint, trapezoidal and Simpson’s rules are proved for numerical integration on a compact interval. The integrand is assumed to be twice continuously diﬀerentiable for the midpoint and trapezoidal rules, and to be four times continuously diﬀerentiable for Simpson’s rule. Errors are estimated in terms of the uniform norm of second or fourth derivatives of the integrand. The proof uses only integration by parts, applied to the second or fourth derivative of the integrand, multiplied by an appropriate polynomial or piecewise polynomial function. A corrected trapezoidal rule that includes the ﬁrst derivative of the integrand at the endpoints of the integration interval is also proved in this manner, the coeﬃcient in the error estimate being smaller than for the midpoint and trapezoidal rules. The proofs are suitable for presentation in a calculus or elementary numerical analysis class. Several student projects are suggested.},
	language = {en},
	urldate = {2023-03-06},
	publisher = {arXiv},
	author = {Talvila, Erik and Wiersma, Matthew},
	month = feb,
	year = {2012},
	note = {arXiv:1202.0249 [math]},
	keywords = {Mathematics - Numerical Analysis, 26D15, 65D30, 26A42, 41A55, 65D32, Mathematics - Classical Analysis and ODEs},
	annote = {Comment: To appear in Atlantic Electronic Journal of Mathematics},
	file = {Talvila en Wiersma - 2012 - Simple derivation of basic quadrature formulas.pdf:C\:\\Users\\Admin\\Zotero\\storage\\XSLY6YKE\\Talvila en Wiersma - 2012 - Simple derivation of basic quadrature formulas.pdf:application/pdf},
}

@article{jentzen_random_2009,
	title = {A random {Euler} scheme for {Carathéodory} differential equations},
	volume = {224},
	issn = {03770427},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377042708002136},
	doi = {10.1016/j.cam.2008.05.060},
	abstract = {We study a random Euler scheme for the approximation of Carathéodory differential equations and give a precise error analysis. In particular, we show that under weak assumptions, this approximation scheme obtains the same rate of convergence as the classical Monte–Carlo method for integration problems.},
	language = {en},
	number = {1},
	urldate = {2023-03-06},
	journal = {Journal of Computational and Applied Mathematics},
	author = {Jentzen, A. and Neuenkirch, A.},
	month = feb,
	year = {2009},
	pages = {346--359},
	file = {Jentzen en Neuenkirch - 2009 - A random Euler scheme for Carathéodory differentia.pdf:C\:\\Users\\Admin\\Zotero\\storage\\LFZQS9Q7\\Jentzen en Neuenkirch - 2009 - A random Euler scheme for Carathéodory differentia.pdf:application/pdf},
}

@article{coulibaly_quasi-randomized_1999,
	title = {A quasi-randomized {Runge}-{Kutta} method},
	volume = {68},
	issn = {0025-5718},
	url = {http://www.ams.org/journal-getitem?pii=S0025-5718-99-01056-X},
	doi = {10.1090/S0025-5718-99-01056-X},
	abstract = {We analyze a quasi-Monte Carlo method to solve the initial-value problem for a system of diﬀerential equations y (t) = f (t, y(t)). The function f is smooth in y and we suppose that f and Dy1f are of bounded variation in t and that Dy2f is bounded in a neighborhood of the graph of the solution. The method is akin to the second order Heun method of the Runge-Kutta family. It uses a quasi-Monte Carlo estimate of integrals. The error bound involves the square of the step size as well as the discrepancy of the point set used for quasi-Monte Carlo approximation. Numerical experiments show that the quasi-randomized method outperforms a recently proposed randomized numerical method.},
	language = {en},
	number = {226},
	urldate = {2023-03-06},
	journal = {Mathematics of Computation},
	author = {Coulibaly, Ibrahim and Lécot, Christian},
	month = apr,
	year = {1999},
	pages = {651--660},
	file = {Coulibaly en Lécot - 1999 - A quasi-randomized Runge-Kutta method.pdf:C\:\\Users\\Admin\\Zotero\\storage\\LQ4QYKR2\\Coulibaly en Lécot - 1999 - A quasi-randomized Runge-Kutta method.pdf:application/pdf},
}

@article{daun_randomized_2011,
	title = {On the randomized solution of initial value problems},
	volume = {27},
	issn = {0885064X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0885064X1000066X},
	doi = {10.1016/j.jco.2010.07.002},
	language = {en},
	number = {3-4},
	urldate = {2023-03-06},
	journal = {Journal of Complexity},
	author = {Daun, Thomas},
	month = jun,
	year = {2011},
	pages = {300--311},
	file = {Daun - 2011 - On the randomized solution of initial value proble.pdf:C\:\\Users\\Admin\\Zotero\\storage\\NCVQFBK5\\Daun - 2011 - On the randomized solution of initial value proble.pdf:application/pdf},
}

@misc{noauthor_stiff_nodate,
	title = {Stiff {Differential} {Equations}},
	url = {https://www.mathworks.com/company/newsletters/articles/stiff-differential-equations.html},
	abstract = {Stiffness is a subtle, difficult, and important - concept in the numerical solution of ordinary differential equations.},
	language = {en},
	urldate = {2023-03-07},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\674H6FG6\\stiff-differential-equations.html:text/html},
}

@misc{noauthor_perturbation_2023,
	title = {Perturbation theory},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Perturbation_theory&oldid=1131120602},
	abstract = {In mathematics and applied mathematics, perturbation theory comprises methods for finding an approximate solution to a problem, by starting from the exact solution of a related, simpler problem. A critical feature of the technique is a middle step that breaks the problem into "solvable" and "perturbative" parts.  In perturbation theory, the solution is expressed as a power series in a small parameter 
  
    
      
        ε
      
    
    \{{\textbackslash}displaystyle {\textbackslash}varepsilon \}
  . The first term is the known solution to the solvable problem.  Successive terms in the series at higher powers of 
  
    
      
        ε
      
    
    \{{\textbackslash}displaystyle {\textbackslash}varepsilon \}
   usually become smaller.  An approximate 'perturbation solution' is obtained by truncating the series, usually by keeping only the first two terms, the solution to the known problem and the 'first order' perturbation correction.
Perturbation theory is used in a wide range of fields, and reaches its most sophisticated and advanced forms in quantum field theory. Perturbation theory (quantum mechanics) describes the use of this method in quantum mechanics. The field in general remains actively and heavily researched across multiple disciplines.},
	language = {en},
	urldate = {2023-03-07},
	journal = {Wikipedia},
	month = jan,
	year = {2023},
	note = {Page Version ID: 1131120602},
	file = {Snapshot:C\:\\Users\\Admin\\Zotero\\storage\\Y4XGJLUT\\Perturbation_theory.html:text/html},
}

@article{khan_analytical_2019,
	title = {Analytical {Solution} of {Van} {Der} {Pol}’s {Differential} {Equation} {Using} {Homotopy} {Perturbation} {Method}},
	volume = {07},
	issn = {2327-4352, 2327-4379},
	url = {http://www.scirp.org/journal/doi.aspx?DOI=10.4236/jamp.2019.71001},
	doi = {10.4236/jamp.2019.71001},
	abstract = {In this research work, Homotopy perturbation method (HPM) is applied to find the approximate solution of the Van der Pol Differential equation (VDPDE), which is a well-known nonlinear ODE. Firstly, the approximate solution of Van Der Pol equation is developed using Dirichlet boundary conditions. Then a comparison between the present results and previously published results is presented and a good agreement is observed. Finally, HPM method is applied to find the approximate solution of VDPDE with Robin and Neumann boundary conditions.},
	language = {en},
	number = {01},
	urldate = {2023-03-07},
	journal = {Journal of Applied Mathematics and Physics},
	author = {Khan, Md. Mamun-Ur-Rashid},
	year = {2019},
	pages = {1--12},
	file = {Khan - 2019 - Analytical Solution of Van Der Pol’s Differential .pdf:C\:\\Users\\Admin\\Zotero\\storage\\S442NHWI\\Khan - 2019 - Analytical Solution of Van Der Pol’s Differential .pdf:application/pdf},
}

@article{soomro_comparison_2013,
	title = {A {Comparison} of {Numerical} {Methods} for {Solving} the {Unforced} {Van} {Der} {Pol}’s {Equation}},
	abstract = {Due to the advancements in the field of computational mathematics, numerical methods are most widely being utilized to solve the equations arising in the fields of applied medical sciences, engineering and technology. In this paper, the numerical solutions of an important equation of applied dynamics: namely, the Unforced Van der Pol’s Equation (UFVDP) are obtained by reducing it to a system of two first order differential equations. The objective of this work is to investigate the efficiency of improved Heun’s (IH) method against the classical Runge-Kutta (RK4) and Mid-point (MP) methods for UFVDP equation. For analysis of accuracy, the Poincare-Lindstedt method has been used as a comparison criterion and respective error bounds are obtained. The results show that the popular RK4 method retains its better accuracy than other methods used for comparison.},
	language = {en},
	author = {Soomro, Abdul Sattar and Tularam, Gurudeo Anand and Shaikh, Muhammad Mujtaba},
	year = {2013},
	file = {Soomro e.a. - 2013 - A Comparison of Numerical Methods for Solving the .pdf:C\:\\Users\\Admin\\Zotero\\storage\\G8ZFGQ6S\\Soomro e.a. - 2013 - A Comparison of Numerical Methods for Solving the .pdf:application/pdf},
}

@article{tzitzouris_notes_nodate,
	title = {Notes on {Perturbation} {Techniques} for {ODEs}},
	language = {en},
	author = {Tzitzouris, James A},
	file = {Tzitzouris - Notes on Perturbation Techniques for ODEs.pdf:C\:\\Users\\Admin\\Zotero\\storage\\DYKBRWX6\\Tzitzouris - Notes on Perturbation Techniques for ODEs.pdf:application/pdf},
}

@book{kuehn_multiple_2015,
	address = {Cham},
	series = {Applied {Mathematical} {Sciences}},
	title = {Multiple {Time} {Scale} {Dynamics}},
	volume = {191},
	isbn = {978-3-319-12315-8 978-3-319-12316-5},
	url = {https://link.springer.com/10.1007/978-3-319-12316-5},
	language = {en},
	urldate = {2023-03-08},
	publisher = {Springer International Publishing},
	author = {Kuehn, Christian},
	year = {2015},
	doi = {10.1007/978-3-319-12316-5},
	file = {Kuehn - 2015 - Multiple Time Scale Dynamics.pdf:C\:\\Users\\Admin\\Zotero\\storage\\KEKJNI5S\\Kuehn - 2015 - Multiple Time Scale Dynamics.pdf:application/pdf},
}

@misc{noauthor_intro_nodate,
	title = {intro peturbation theory},
	file = {[Texts in Applied Mathematics №20] Mark H. Holmes (auth.) - Introduction to Perturbation Methods (1995, Springer) [10.1007_978-1-4612-5347-1] - libgen.li.pdf:C\:\\Users\\Admin\\Zotero\\storage\\A7D8KXBJ\\[Texts in Applied Mathematics №20] Mark H. Holmes (auth.) - Introduction to Perturbation Methods (1995, Springer) [10.1007_978-1-4612-5347-1] - libgen.li.pdf:application/pdf},
}
