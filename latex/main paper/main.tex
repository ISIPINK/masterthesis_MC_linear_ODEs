\documentclass[a4paper,12pt]{article}

\setlength{\textwidth}{15.0cm}
\setlength{\textheight}{24.0cm}
\setlength{\topmargin}{0cm}
\setlength{\headsep}{0cm}
\setlength{\headheight}{0cm}
\pagestyle{plain}

\usepackage[dvips]{epsfig}
\usepackage{tikz}

\usepackage[
backend=biber,
style=alphabetic,
]{biblatex}

\usepackage{amsmath,amssymb,amsthm}
\input{environments.tex}

\usepackage{comment}
\usepackage{listings}
\input{custom commands.tex}

\addbibresource{bibliography.bib} 
\setlength{\parindent}{0pt}

\begin{document}

\begin{comment}
\title{Recursive Monte Carlo}
\author{Isidoor Pinillo Esquivel}
\maketitle
\end{comment}

\input{titelblad_MP.tex}

\newpage
\tableofcontents
\newpage

\begin{abstract}
    We will write this at the end. Also need a dutch abstract
\end{abstract}

\section{Introduction}

\subsection{Introductory Example}
In this section we introduce recursive  Monte Carlo with following problem:

\begin{equation} \label{ydy}
    y'=y, y(0)=1.
\end{equation}

Integrating both sides of (\ref{ydy}) obtains:

\begin{equation} \label{Integral ydy}
    y(t) = 1 + \int_{0}^{t} y(s) ds.
\end{equation}

Equation (\ref{Integral ydy}) is a recursive integral equation or to be more specific
a linear Volterra integral equation of the second type. By estimating the recursive integral
of equation (\ref{Integral ydy}) with Monte Carlo one derives following estimator:

\[
    Y(t) = 1 + t y(Ut)
    .\]

With $U \sim \text{Uniform}(0,1)$. If $y$ is well behaved then $E[Y(t)]=y(t)$ but we can't
calculate $Y(t)$ without accesses to $y(s),s<t$. Notice that we can replace $y$ by a
unbiased estimator of it without changing $E[Y(t)]=y(t)$ by the law of total expectance
($E[X] = E[E[X|Z]]$). By replacing $y$ by $Y$ itself we obtain a recursive expression for $Y$:

\begin{equation}\label{recursive RV}
    Y(t) = 1 + tY(Ut).
\end{equation}

Equation (\ref{recursive RV}) is a recursive random variable equation (RRVE). If you would implement equation
(\ref{recursive RV}) with recursion it will run indefinitely. A biased way of around this is by approximating
$Y(t) \approx 1$ near $t = 0$. Later we discuss Russian roulette (\ref{Russian roulette}) which
can be used as an unbiased stopping mechanism.

\vspace*{0.2cm}

\begin{pythonn}[implementation of (\ref{recursive RV})] \label{python eps ydy}
    \pythoncode{python code/eps_ydy.py}
    To gain insight into realizations of RRVEs, it can be helpful to plot
    all recursive calls $(t,Y(t))$, as shown in Figure \ref{fig:intro example}
    for this implementation.

    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/intro example.png}
        \caption{Recursive calls of (\ref{python eps ydy})}
        \label{fig:intro example}
    \end{figure}
\end{pythonn}

An issue with (\ref{python eps ydy}) is that the variance increases rapidly when $t$ increases. Later
this is issue gets resolved in the section on ODEs. Note that (\ref{python eps ydy}) keeps desirable properties
from unbiased Monte Carlo methods such as being embarrassingly parallel and
having simple error estimates.


\subsection{Contributions}
We write this at the end. Probably a lot of conjectures.

\subsection{Related Work}
work on
\begin{itemize}
    \item alternative methods for recursive integrals
    \item MC work on ODEs
    \item MC work on PDEs
    \item WoS
\end{itemize}
This is just to give a general overview we probably reference specific ideas when we first introduce them.

\section{Background}

\subsection{Notation}
Notations used in this thesis include:

\begin{itemize}
    \item $U \sim \text{Uniform}(0,1)$
    \item $B(p) \sim \text{Bernoulli}(p)$
    \item RV = random variable
    \item RRVE (recursive RV equation): An equation that defines a
          family of random variables in terms of its self.
    \item MC = Monte Carlo
\end{itemize}


\subsection{Modifying Monte Carlo}
In this subsection, we discuss techniques for modifying RRVEs
in a way that preserves the expected value of the solution while
acquiring more desirable properties. \\

Russian roulette is a MC technique commonly used in rendering.
The main idea behind Russian roulette is to replace a random variable
with a less computationally expensive approximation sometimes.

\begin{definition}[Russian roulette] \label{Russian roulette}
    Define Russian roulette on $X$ with free parameters
    $Y_{1},Y_{2}: E[Y_{1}] = E[Y_{2}]$, $p \in [0,1]$ and $U$
    independent of $Y_{1},Y_{2},X$ the following way:
    \[
        X \rightarrow \begin{cases}
            \frac{1}{p}(X- (1-p)Y_{1}) & \text{ if } U<p \\
            Y_{2}                      & \text{ else }
        \end{cases}
        .\]
\end{definition}

\begin{example}[Russian roulette]
    Say that we are interested in estimating $E[Z]$ with $Z$
    defined in the following way:
    \[
        Z = U + \frac{f(U)}{1000}
        .\]
    where $f:\mathbb{R} \rightarrow [0,1]$ expensive to compute.
    Estimating $Z$ directly would require calling $f$ each
    simulation. We can modify $Z$ to
    \[
        \tilde{Z} = U + B\left(\frac{1}{100}\right)\frac{f(U)}{10}
        .\]
    Now $\tilde{Z}$
    just requires calling $f$ on average once every $100$ simulations with the variance
    only increasing slightly compared to $Z$.
\end{example}

Maybe this wasn't the best example because you could also estimate the expectance of the
$2$ terms of $Z$ separately.

\begin{example}[Russian roulette on (\ref{recursive RV})]
    Russian roulette can fix the indefinite recursion issue of
    equation (\ref{recursive RV}) by approximating $Y$ near $t = 0$ with $1$. Concretely
    we replace the $t$ in front of the recursive term with $B(t)$
    when $t<1$.
    \[
        Y(t) =
        \begin{cases}
            1 + B(t)Y(Ut) & \text{ if } t<1 \\
            1 + tY(Ut)    & \text{ else}
        \end{cases}
        .\]
\end{example}

\vspace{0.2cm}

\begin{pythonn}[Russian roulette on (\ref{recursive RV})] \label{RRpython}
    \pythoncode{python code/RR_ydy.py}
    Interestingly, $Y(t)$ is constrained to take on only integer values.
    This is visually evident on figure \ref{plt russian roulette}.
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/russian roulette example.png}
        \caption{Recursive calls $(t,Y(t))$ of (\ref{RRpython}) }
        \label{plt russian roulette}
    \end{figure}

\end{pythonn}

Splitting is a technique that has almost the reverse effect as Russian roulette.
The idea behind splitting is to reduce variance in certain places by using more
samples.

\begin{definition}[splitting]
    Splitting $X$ means using multiple $X_{j} \sim X$ not independent per se to
    lower variance by averaging them:
    \[
        \bar{X}= \frac{1}{N} \sum_{j=1}^{N} X_{j}
        .\]
\end{definition}

Splitting the recursive term in a RRVE can lead to (additive) branching recursion.
Extra care should be taken that branches get terminated quickly avoiding exponential increase
of computation power. This can be
achieved by termination strategies already discussed and later we discuss coupled recursion for
alleviating additive branching recursion in RRVEs.

\begin{example}[splitting on (\ref{recursive RV})]
    We can "split" the recursive term of  (\ref{recursive RV}) in $2$:
    \[
        Y(t) = 1 + \frac{t}{2}(Y_{1}(Ut)+Y_{2}(Ut))
        .\]
    with $Y_{1}(t),Y_{2}(t)$ i.i.d. $Y(t)$.
\end{example}

\vspace{0.2cm}

\begin{pythonn}[splitting on (\ref{recursive RV})]
    \pythoncode{python code/SRR_ydy.py}
\end{pythonn}

\begin{definition}[$2$-level MC] \label{2 level}
    $2$-level MC on $X$ with parameters $\tilde{X}, Y: E[\tilde{X}]=E[Y]$:
    \[
        X \rightarrow X-\tilde{X} + Y
        .\]
\end{definition}

\begin{definition}[control variates] \label{CV}
    Control variate on $f(X)$ is
    \[
        f(X) \rightarrow f(X)-\tilde{f}(X) + E[\tilde{f}(X)]
        .\]
\end{definition}
Control variates are a special case of $2$-level MC. Usually $\tilde{f}$ is an approximation
of $f$ to reduce variance.

\begin{example}[control variate on (\ref{recursive RV})]
    To make a control variate for (\ref{recursive RV}) that reduces variance
    we use following approximation of $y(t) \approx 1+t$:
    \[
        Y(t)= 1+t+\frac{t^{2}}{2} + t(Y(Ut)-1-Ut)
        .\]
    Notice that we can cancel the constant term of the control variate
    but that would affect the Russian roulette negatively.
\end{example}

\vspace*{0.2cm}
\begin{pythonn}[control variate on (\ref{recursive RV})]
    \pythoncode{python code/CVRR_ydy.py}
\end{pythonn}

\begin{comment}
Introduces Russian roulette, splitting, control variates, importance sampling and maybe quasi Monte Carlo with the
$y'=y$ example. We are missing importance sampling and quasi MC
\end{comment}

\begin{related}
    Our favorite work that discusses these techniques is \cite{veach_robust_nodate}.
    More interesting works can be found on MC techniques in rendering.
    $2$-level gets discussed in \cite{giles_multilevel_2013}.
\end{related}
% need to fix veach refrence see bibliography

\subsection{MC Trapezoidal Rule}
We present here a MC trapezoidal rule with similar convergence behavior to
methods discussed later. The MC trapezoidal rule will just be
regular MC control variated with the normal trapezoidal rule.

\begin{definition}[MC trapezoidal rule]
    Define the MC trapezoidal rule for $f$ on $[x,x+dx]$ the following
    way:
    \begin{equation}
        \int_{x}^{x+dx} f(s)ds \approx
        \frac{f(x)+f(x+dx)}{2} + f(S_{x})-f(x)-\frac{S_{x}-x}{dx}(f(x+dx)-f(x))
    \end{equation}
    with $S_{x} = \text{Uniform}(x,x+dx)$.
\end{definition}


Defining the composite MC trapezoidal rule as
the sum of MC trapezoidal rules on equally divided intervals
is possible but expensive. Every interval would add a function call
compared to the normal composite MC trapezoidal rule. Instead
you can aggressively Russian roulette into the normal trapezoidal rule
such that the increase in functions calls is arbitrarily small.

\begin{definition}[composite MC trapezoidal rule] \label{MCtrap}
    Define the composite MC trapezoidal rule for $f$ on $[a,b]$ with
    $n$ intervals and a Russian roulette rate $l$ the following way:
    \begin{align}
         & \int_{a}^{b} f(s)ds \approx        \\
         & \sum_{x}  \frac{f(x)+f(x+dx)}{2} +
        l B \left(\frac{1}{l} \right)
        \left(f(S_{x})-f(x)-\frac{S_{x}-x}{dx}(f(x+dx)-f(x)) \right)
    \end{align}

    with $S_{x} = \text{Uniform}(x,x+dx)$.

\end{definition}

\begin{pythonn}[implementation of (\ref{MCtrap})]
    We implement (\ref{MCtrap}) for $\int_{0}^{1}e^{s}ds$.
    \vspace*{0.5cm}
    \pythoncode{python code/trap1.py}
\end{pythonn}

What is surprising about this MC composite rule is that
under the right smoothness conditions it adds $0.5$
for every dimension order of convergence over the normal
composite rule.

\begin{lemma}[half variance phenomenon]
    Maybe a lemma about MC integrating a polynomial
    with proof and this becomes a theorem
\end{lemma}

\begin{proof}
    Also a maybe, maybe just a numerical example.
\end{proof}

\begin{related}
    Optimal theoretical bounds on randomized algorithms can be found in:
    (see literature randomized trapezoidal rule)
    \cite{wu_randomised_2020}.
\end{related}

comparing normal vs MC trapezoidal rule and highlighting the "half variance phenomenon".
+ maybe integrating polynomials for intuition

\subsection{Unbiased Non-Linearity}
At first sight it looks only possible to deal with linear problems in an unbiased way but by using
independent samples it possible to deal with polynomial non-linearity's which practically extend
to any continuos functions by the Weierstrass approximation theorem.  It is not always easy to
transform non-linearity into polynomials but it is not difficult to come up with
biased alternative approaches based on linearization or approximate polynomial non-linearity.


\begin{example}[$y'=y^{2}$]
    Let's do following example:
    \begin{equation} \label{dyy2}
        y'= y^2.
    \end{equation}
    with $y(1)=-1$. This has solution $-\frac{1}{t}$. Integrate both sides of
    equation (\ref{dyy2}) to arrive at following integral equation:
    \begin{equation} \label{Integral dyy2}
        y(t) = -1 + \int_{1}^{t} y(s) y(s) ds .
    \end{equation}
    To estimate the recursive integral in equation (\ref{Integral ydy}) we use $2$
    independent $Y_{1},Y_{2}\sim Y$ :
    \[
        Y(t) = -1 + (t-1) Y_{1}(S) Y_{2}(S)
        .\]
    With $S \sim \text{Uniform}(1,t)$. This is a branching RRVE this is
    typical when dealing with non-linearity.
\end{example}

\vspace*{0.2cm}
\begin{pythonn}[$y'=y^{2}$]
    \pythoncode{python code/dyy2.py}
\end{pythonn}

\begin{example}[$e^{E[X]}$]
    $e^{\int x(s)ds}$ is common expression encountered when studying ODEs.
    In this example we demonstrate how you can generate unbiased estimates of
    $e^{E[X]}$ with simulations of $X$. The taylor series of $e^{x}$ is:
    \begin{align}
        e^{E[X]} & = \sum_{n=0}^{\infty} \frac{E^{n}[X]}{n!}     \\
                 & = 1 + \frac{1}{1}E[X]\left(1+ \frac{1}{2}E[X]
        \left(1+\frac{1}{3}E[X]\left(1+ ...\right)\right)\right). \label{taylor e}
    \end{align}
    Change the fractions of equation (\ref{taylor e}) to Bernoulli processes
    and replace all $X$ with independent $X_j$ with $E[X]=E[X_{i}]$.
    \begin{align*}
        e^{E[X]} & = E
        \left[1 + B\left(\frac{1}{1}\right)E[X_1]
        \left(1+ B\left(\frac{1}{2}\right)E[X_2]
        \left(1+B\left(\frac{1}{3}\right)E[X_3]
        \left(1+ ...\right)
        \right)
        \right)
        \right]              \\
                 & = E\left[
            1 + B\left(\frac{1}{1}\right)X_1
            \left(1+ B\left(\frac{1}{2}\right)X_2
            \left(1+B\left(\frac{1}{3}\right)X_3
            \left(1+ ...\right)
            \right)
            \right)
        \right]              \\
    \end{align*}
    What is inside the expectation is something that we can simulate with simulations of $X_{j}$.
\end{example}

\vspace{0.2cm}
\begin{pythonn}[$e^{E[X]}$]
    The following python code estimates $e^{\int_{0}^{t} s^{2}ds}$:
    \vspace*{0.4cm}
    \pythoncode{python code/expX.py}
    %}
\end{pythonn}

\begin{related}
    A similar approach to non-linearity can be found in \cite{ermakov_monte_2019}.
    We have more papers on how to deal with non-linearity stashed, no idea if they are
    worth mentioning.
\end{related}

\subsection{Recursion}
In this section we discuss recursion related techniques.

\begin{technique}[coupled recursion]
    The idea behind coupled recursion is sharing recursion calls of
    multiple RRVEs for simulation. This does make them dependent.
    It is like assuming $2$ induction hypotheses at the same
    time and proving both inductions steps at the same time vs
    doing separate induction proofs. Which should be easier
    because you have accesses to more assumptions at the same time.
\end{technique}

\begin{example}[coupled recursion]
    Lets say you are interested in calculating the
    sensitivity of the solution of an ODE to a
    parameter $a$:
    \begin{align}
        y'             & =ay,y(0)=1 \Rightarrow \label{couple recu ex1} \\
        \partial_{a}y' & = y + a \partial_{a}y' \label{couple recu ex2}
    \end{align}
    Turn (\ref{couple recu ex1}) and (\ref{couple recu ex2}) into RRVEs.
    To emphasize that they are coupled, that they should
    recurse together we write them in a matrix equation:
    \begin{equation} \label{coupled mat}
        \begin{bmatrix}
            Y(t) \\
            \partial_{a}Y(t)
        \end{bmatrix}=
        \begin{bmatrix}
            1 \\
            0
        \end{bmatrix}+
        t \begin{bmatrix}
            a & 0 \\
            1 & a
        \end{bmatrix}
        \begin{bmatrix}
            Y(Ut) \\
            \partial_{a}Y(Ut)
        \end{bmatrix}.
    \end{equation}

\end{example}

\begin{pythonn} [implementation of (\ref{coupled mat})]
    \pythoncode{python code/coupled_mat.py}
\end{pythonn}

\begin{technique}[recursion in recursion]
    Recursion in recursion is what is sounds like. It is like proving an induction
    step of an induction proof with induction.
\end{technique}

%\begin{example}[recursion in recursion]
%    maybe induction in induction proof example or a reference to ODE solvers later.
%\end{example}

\begin{related}[recursion in recursion]
    The next flight variant of WoS
    is a beautiful example of recursion in recursion described in
    \cite{sawhney_grid-free_2022}.
\end{related}

Most programming languages support recursion but this comes with restrictions
like maximum recursion depth and performance issues. Tail recursion solve those
issues when possible.

\begin{technique}[non-branching tail recursion]
    Tail recursion involves reordering all operations
    so that almost no operation needs to happen after
    the recursion call. This allows us to return the
    answer without retracing all steps when we reach
    the last recursion call, and it can achieve similar
    speeds to a forward implementation.
\end{technique}

The non-branching recursion presented in the RRVEs of this paper
can be implemented straightforwardly due to the associativity of
all operations ($(xy)z = x(yz)$) involved. However, tail recursion
may not always be desirable as it discards intermediate values of
the recursion calls which may be of interest. To retain these intermediate
values while still partly optimizing for performance, it is possible
to combine tail recursion with normal recursion.

\begin{pythonn}[tail recursion on (\ref{coupled mat})]
    We implement (\ref{coupled mat}) but this time with tail recursion.
    We collect addition operations in a vector $sol$ and multiplication
    in a matrix $W$.
    \vspace{0.3cm}
    \pythoncode{python code/tailrecu.py}
\end{pythonn}

%Branching tail recursion is hard. There  are multiple ways to
%do branching tail recursion with each their advantages and disadvantages. \\
%In the context of recursive MC there are $2$ techniques that
%stand out:

%\begin{technique}[tree regrowing]
%    The structure of branching recursion can be captured by a tree. Storing that tree
%    in memory can be expensive. In recursion you only need to retrace steps
%    $1$ by $1$ therefore you only need local parts of the recursion tree. Tree
%    regrowing tries to alleviate memory issues by instead storing the whole
%    tree only storing seeds (of the random generator) of parts of the
%    tree and growing them when needed.
%\end{technique}
%
%\begin{technique}[backward tail recursion]
%    One way of doing branching tail recursion is by using operation buffers for
%    all leafs which is not memory friendly. In backward tail recursion you retrace
%    steps and do all operations in reverse to recover the buffer needed.
%\end{technique}


\begin{related}[branching recursion]
    This blog discusses branching tail recursion:
    \url{https://jeroenvanwijgerden.me/post/recursion-1/}.
    The techniques for tail recursion  gets discussed in \cite{vicini_path_2021}.
\end{related}


\section{ODEs}

%\subsection{Linear Recursive Integrals}
%We have algo in mind for this case based on coupled recursion on disjunct sets.
%
%\begin{definition}[Volterra equation of the second kind]
%    A Volterra equation of the second kind for $x$  is of the following form:
%    $$
%        x(t)=f(t)+\int_a^t K(t, s) x(s) ds.
%    $$
%    Given the kernel  $K(t, s)$  and  $ f(t)$.
%\end{definition}
%
%\begin{definition}[Fredholm equation of the second kind]
%    A Fredholm equation of the second kind for $\varphi$  is of the following form:
%    $$
%        \varphi(t)=f(t)+\lambda \int_a^b K(t, s) \varphi(s) ds.
%    $$
%    Given the kernel  $K(t, s)$  and  $ f(t)$.
%\end{definition}


\subsection{From ODEs to Integral Equations}
In this section we discuss informally how to turn ODEs into integral equations.

From ODEs to Integral Equations (continuation)
We continue our discussion on how to turn ODEs into integral equations.
Let's start from following form:
$$
    L(y)= f
$$
where $L$ is a linear operator, $f$ be generic for now and some initial/boundary condition
for $y$. All the methods we have in mind are some kind of integral transform:
$$
    y(t) = \int_{\Omega} \varphi(x) K(t,x)dx
$$
where the integral may also be a summation and we may chose $K(t,x), \Omega$ and let $\varphi(x)$ be our new unknown. Note that we don't know that such representation exist or even is well defined but we continue and fix this in the future (hopefully). If you sub this into the first equation you obtain the following:

\begin{align*}
    L \left(\int_{\Omega} \varphi(x) K(t,x)dx \right) & = f \Leftrightarrow \\
    \int_{\Omega} \varphi(x) L \left(K(t,x) \right)dx & = f
\end{align*}

this is a Fredholm integral equation of the first type in $\varphi(x)$
\url{https://en.wikipedia.org/wiki/Fredholm_integral_equation}
if we had
let $\Omega$ depend on $t$ in a certain way we would have obtained a Voltera integral
equation of the second kind
\url{https://en.wikipedia.org/wiki/Volterra_integral_equation}.

Let's derive the method of source green functions in this framework
\url{https://en.wikipedia.org/wiki/Green%27s_function}. 
This can be done by choosing the free things in a way something nice happens:
$$
    L \left(K(t,x) \right) = \delta(t-x)
$$

with the same  domain and initial/boundary conditions such that the ones of $y$ hold.
Choosing the initial/boundary conditions that way is easy but not trivial.

For a dirichlet boundary condition in $s$ the following can be done:

\begin{align*}
    y(s)   & = \int_{\Omega} \varphi(x) K(s,x)dx \Leftarrow                      \\
    K(s,x) & = \frac{y(s) l(x)}{\varphi(x)} \text{ and } 1 = \int_{\Omega}l(x)dx
\end{align*}

For a Neumann boundary condition in $s$ the following can be done:

\begin{align*}
    y'(s)   & = \int_{\Omega} \varphi(x) K'(s,x)dx \Leftarrow                      \\
    K'(s,x) & = \frac{y'(s) l(x)}{\varphi(x)} \text{ and } 1 = \int_{\Omega}l(x)dx
\end{align*}

with $l$ arbitrary. Linear type of initial/boundary conditions are very similar to this.
The $\varphi = f$ in the initial/boundary condition is annoying but can be avoided
by making the original initial/boundary condition $0$ by splitting explained in period1.\\

Going back because of our choice the following thing can be derived

\begin{align*}
    \int_{\Omega} \varphi(x) L \left(K(t,x) \right)dx & = f \Leftrightarrow \\
    \int_{\Omega} \varphi(x) \delta(t-x)dx            & = f \Leftrightarrow \\
    \varphi(t)                                        & = f
\end{align*}

Boundary Green functions deals with boundary conditions like how source Green functions deals with the source. The intuition behind them is the same as the solutions of a linear homogenous ODE that span a vector space.

$$
    y(t)= \int_{\partial B} \varphi(x) K(t,x) dx
$$

If you impose $L(y(t)) = 0$ on this you get the following:

\begin{align*}
    \int_{\partial B} \varphi(x) L(K(t,x)) dx & = 0 \Leftarrow \\
    L(K(t,x))                                 & = 0
\end{align*}

Again the initial conditions on $K(t,x)$ come from the original problem:

For a dirichlet boundary condition in $s$ the following can be done:

\begin{align*}
    y(s)   & = \int_{\partial \Omega} \varphi(x) K(s,x)dx \Leftarrow \\
    K(s,x) & = \delta(x-s) \text{ and } \varphi(s)= y(s)
\end{align*}

Other linear type initial/boundary conditions are very similar.

In the Green function method we searched an integral transform with a certain property
related to the equation that we were solving. Certain classes of integral
transformations have nice properties for a big class of equations.
A classic integral transform used for ODEs is the Fourier transform
\url{https://en.wikipedia.org/wiki/Fourier_transform}.
But we haven't figured
out how to deal with boundary conditions in this case.

The discrete version of an integral transform is a series transform,
in which you transfer information about the function to $\varphi_n$.
$$
    y(t) = \sum_{n=0}^{\infty} \varphi_n e_n(t)
$$
our original equation with this becomes:
\begin{align*}
    L \left(\sum_{n=0}^{\infty} \varphi_n e_n(t) \right) & = f \Leftrightarrow \\
    \sum_{n=0}^{\infty} \varphi_n L (e_n(t))             & = f
\end{align*}
Again there a lot of tricks you can pull of with this.
A convenient thing is when $L(e_{n}(t)) = \phi_{n}$ (and $e_{n}$
spans the space of functions which follow the initial/boundary conditions)
is bi-orthogonal basis against some $\psi_n$
$\left(\langle \phi_j \mid \psi_{k} \rangle= \delta_{jk}\right)$ .

\begin{align*}
    \sum_{n=0}^{\infty} \varphi_n \phi_{n}                                            & = f \Rightarrow                                   \\
    \left \langle \sum_{n=0}^{\infty} \varphi_n \phi_{n}\mid \psi_{j}  \right \rangle & =  \langle f\mid \psi_{j} \rangle \Leftrightarrow \\
    \sum_{n=0}^{\infty} \varphi_n \left \langle \phi_{n}\mid \psi_{j}  \right \rangle & =  \langle f\mid \psi_{j} \rangle \Leftrightarrow \\
    \sum_{n=0}^{\infty} \varphi_n \delta_{nj}                                         & =  \langle f\mid \psi_{j} \rangle \Leftrightarrow \\
    \varphi_j                                                                         & =  \langle f\mid \psi_{j} \rangle
\end{align*}
This means we have following expression for the solution:
\begin{align*}
    y(t) & = \sum_{n=0}^{\infty} \langle f(x)\mid \psi_{n}(x) \rangle e_{n}(t)  \Leftrightarrow \\
    y(t) & = \left\langle f(x)\mid  \sum_{n=0}^{\infty} \psi_{n}(x)e_{n}(t)  \right \rangle
\end{align*}
this expression in some cases depending on how the inner product is defined corresponds
with the Green function $G(t,x) =\sum_{n=0}^{\infty} \psi_{n}(x)e_{n}(t)$.

Related wikipedia page :
\url{https://en.wikipedia.org/wiki/Spectral_theory_of_ordinary_differential_equations}

This is probably not the only way to turn ODEs into integral equations. The Feynman-Kac formula
\url{https://en.wikipedia.org/wiki/Feynman%E2%80%93Kac_formula} 
is derived in an other way but still kind of obeys the general form we have given.

There are multiple ways to turn problems into integral equations for MC methods
but not all those integral equations gives you Monte Carlo methods with the same properties.
Things like: the type of the domain chosen, stochastic approximations made, what gets thrown
to the source term and what needs to be recursed on determine the properties of the Monte
Carlo method obtained.\\

Each Monte Carlo method doesn't have to be limited to $1$ integral equation.
One may use a different integral equation for each recursion step made in combination
with the different modifications discussed in period1. This makes for a big search space
of possible Monte Carlo algorithms. \\


Another thing to take in consideration is that finding Green functions is difficult a way
around that is by throwing everything in the source term but by doing this you probably
lose good properties. This approach is taken for example in Grid-Free Monte Carlo for
PDEs with Spatially Varying Coefficients. \\

To test that boundary Green functions work for ODEs we work out following example:
$$
    y'' = y, y(0) = 1, y'(1)=e
$$
with solution $y(t) = e^{t}$. We chose the splitting Green function method with
$\Omega = [-1,1],f = y$ as discussed as before. \\

Let's create integral representation of the boundary and source terms separately:

$$
    y''_{s} = f \text{ with } y_s(0)=0, y'_s(1)=0
$$
And the equation for the corresponding Green function:
$$
    G''(t,x) = \delta(t-x) \text{ with } G(0,x)=0, G'(1,x)=0
$$
$G$ must be something continuos piecewise linear with a jump of $1$ in the derivative
at $t = x$. By some algebra we find following solution:
$$
    G(t,x) =
    \begin{cases}
        -t & \text{if } t <  x   \\
        -x & \text{if } t \ge  x
    \end{cases}
$$
Write out the solution for $y_{s}(t)$:
$$
    y_{s}(t) = \int_{0}^{1} y(x) G(t,x) dx.
$$

We still have some problems to fix with the boundary Green functions ... \\
The boundary in for ODEs is discrete $\partial \Omega = \{0,1\}$.
So instead of an integral we have sum and Green function also splits into $2$...

$$
    y''_{b} = 0 \text{ with } y_{s}(0)=1, y'_{s}(1)= e
$$
Let's call the boundary function $K$ so that we don't confuse it with $G$.
So we have $K(t,0)$ and $K(t,1)$.The solution for these are easily found:

\begin{align*}
    K''(t,0) & = 0 \text{ with } K(0,0)=1, K'(0,1)=0 \Rightarrow \\
    K(t,0)   & =1
\end{align*}

\begin{align*}
    K''(t,1) & =0 \text{ with } K(1,0)=0, K'(1,1)=1 \Rightarrow \\
    K(t,1)   & =t
\end{align*}

Write out the solution for $y_{b}(t)$:
$$
    y_{b}(t) = 1 + e t
$$

If you put everything together you get:
$$
    y(t) = 1+et +\int_{0}^{1} y(x) G(t,x)dx.
$$
In the implementation we use Russian Roulette  with probability $1-\frac{1}{1.3}$ always for stopping.
In code this looks like:



\begin{definition}[boundary green function]
    The boundary green function of a linear differential problem with linear boundary
    conditions.
\end{definition}

\begin{definition}[source green function]
    For
    \[
        L(y(z)) = f
        .\]
    with $L$ a linear differential operator, $z$ a point in the input space of $y$
    ,$f$ arbitrary and linear boundary conditions.
    We define the source green function $G(z,s)$ with following property
    \[
        L(G(z,s))=\delta(z-s).
        .\]
    and null boundary conditions.
\end{definition}


The IVPs that we covered so far were easily transformed into integral equations.
This is not the case anymore for BVPs.
\begin{example}[$y''=y$]
    Lets look at following BVP:
    \begin{equation}
        y''=y, y(0)=1, y'(1)=e.
    \end{equation}
    with $y(t)= e^{t}$ as solution. We will be using
    the green functions of $y''$ to turn this into an integral equation.
\end{example}


\begin{example}[numerical green functions]
    There will be probably some green functions that we need
    that don't have an analytic expression yet.
\end{example}

\subsection{IVPs ODEs}
An IVP example probably using DRRMC maybe compare it to parareal. Maybe also non-linear algo

\subsection{BVPs ODEs}
A BVP example using yet another algo that hopefully has the half variance phenomenon.

\section{Higher Dimensional Recursive Integrals}
\subsection{Complicated Geometry}
\begin{example}[nasty $2$D integral]
    $2$D integral that is difficult because of its geometry
\end{example}

\subsection{Recursive Brownian Motion}
WoS like way to simulate Brownian motion which is related to the green function
of the heat equation

\begin{example}[recursive Brownian motion]
    see period5
\end{example}

\subsection{Heat Equation}
a geometric robust way to solve the heat equation and maybe a higher order method to solve
the heat equation

\subsection{Wave Equation}
probably won't get to it

\newpage
\printbibliography
\newpage

\section{Appendix}
Derivation of the green functions and some expressions.
\end{document}
