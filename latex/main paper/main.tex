\documentclass[a4paper,12pt]{article}

\setlength{\textwidth}{15.0cm}
\setlength{\textheight}{24.0cm}
\setlength{\topmargin}{0cm}
\setlength{\headsep}{0cm}
\setlength{\headheight}{0cm}
\pagestyle{plain}

\usepackage[dvips]{epsfig}
\usepackage{tikz}

\usepackage[
backend=biber,
style=alphabetic,
]{biblatex}

\usepackage{amsmath,amssymb,amsthm}
\input{environments.tex}

\usepackage{comment}
\usepackage{listings}
\input{custom commands.tex}

\addbibresource{bibliography.bib} 
\setlength{\parindent}{0pt}

\begin{document}

\begin{comment}
\title{Unbiased Monte Carlo for Recursive Integrals}
\author{Isidoor Pinillo Esquivel}
\maketitle
\end{comment}

\input{titelblad_MP.tex}

\newpage
\tableofcontents
\newpage

\begin{abstract}
    We will write this at the end.
\end{abstract}

\section{Introduction}

\subsection{Introductory Example}
To get familiar with Monte Carlo for estimating recursive integrals
we demonstrate it on following problem:

\begin{equation} \label{ydy}
    y'=y, y(0)=1.
\end{equation}

By integrating both sides of (\ref{ydy}) following integral equation can be derived:

\begin{equation} \label{Integral ydy}
    y(t) = 1 + \int_{0}^{t} y(s) ds.
\end{equation}

Equation (\ref{Integral ydy}) is a recursive integral equation or to be more specific
a linear Volterra integral equation of the second type. By naively using Monte
Carlo on the recursive integral of equation (\ref{Integral ydy}) one derives following estimator:

\[
    Y(t) = 1 + t y(Ut)
    .\]

where $U=\text{Uniform}(0,1)$. If $y$ is well behaved then $E[Y(t)]=y(t)$ but we can't
calculate $Y(t)$ without accesses to $y(s),s<t$. Notice that we can replace $y$ by a
unbiased estimator of it without changing $E[Y(t)]=y(t)$ by the law of total expectance
($E[X] = E[E[X|Z]]$). By replacing $y$ by $Y$ itself we obtain a recursive expression for $Y$:

\begin{equation}\label{recursive RV}
    Y(t) = 1 + tY(Ut).
\end{equation}

Equation (\ref{recursive RV}) is a recursive random variable equation. If you would implement equation
(\ref{recursive RV}) with recursion it will run indefinitely. A biased way of around this is by approximating
$Y(t) \approx 1$ near $t = 0$. Later we discuss Russian roulette (ref{Russian  roulette}) which
can be used as an unbiased stopping mechanism. \\

\begin{python}[implementation of (\ref{recursive RV})] \label{python eps ydy}
    \pythoncode{python code/eps_ydy.py}
\end{python}

An issue with (\ref{python eps ydy}) is that the variance increases rapidly when $t$ increases. Which we
later solve in the section on ODEs. Note that (\ref{python eps ydy}) keeps desirable properties
from unbiased Monte Carlo methods such as: being embarrassingly parallel,
robustness and having simple error estimates.


\subsection{Contributions}
We write this at the end.

\subsection{Related Work}
work on
\begin{itemize}
    \item alternative methods for recursive integrals
    \item MC work on ODEs
    \item MC work on PDEs
    \item WoS
\end{itemize}
This is just to give a general overview we probably reference specific ideas when we first introduce them.

\section{Background}
\subsection{Modifying Monte Carlo}
Once we have a recursive random variable equation it is possible the transform it
to have more desirable properties. All techniques available to classic Monte Carlo
my be used to modify recursive random variable equations without affecting the
unbiasedness. Our favorite work that discusses these techniques is \cite{veach_robust_nodate}.
% need to fix veach refrence see bibliography

Introduces Russian roulette, splitting, control variates, importance sampling and maybe quasi Monte Carlo with the
$y'=y$ example.

\subsection{Monte Carlo Trapezoidal Rule}
comparing normal vs Monte Carlo trapezoidal rule and highlighting the "half variance phenomenon".
+ maybe integrating polynomials for intuition

\subsection{Unbiased Non-Linearity}
\begin{example}[$y'=y^{2}$]
    see python note book
\end{example}

\begin{example}[$e^{E[X]}$]
    see python note book
\end{example}

\subsection{Recursion}

\begin{example}[coupled recursion]
    example with $y'=y$ (I need to redo this example)
\end{example}

\begin{example}[recursion in recursion]
    maybe induction in induction proof example
\end{example}

\begin{example}[tail recursion]
    discuss problems with implementing recursion and solutions.  \\
    inverse problem example
\end{example}

\subsection{Green Functions}
green function stuff that we will be needing, we aren't sure in how much detail we're going to go.

\begin{example}[numerical green functions]
    There will be probably some green functions that we need
    that don't have an analytic expression yet.
\end{example}

\section{$1$-Dimensional Recursive Integrals}

\subsection{Linear Recursive Integrals}
We have algo in mind for this case based on coupled recursion on disjunct sets.


\subsection{IVPs ODEs}
An IVP example probably using DRRMC maybe compare it to parareal. Maybe also non-linear algo

\subsection{BVPs ODEs}
A BVP example using yet another algo that hopefully has the half variance phenomenon.

\section{Higher Dimensional Recursive Integrals}
\subsection{Complicated Geometry}
\begin{example}[nasty $2$D integral]
    $2$D integral that is difficult because of its geometry
\end{example}

\subsection{Recursive Brownian Motion}
WoS like way to simulate Brownian motion which is related to the green function
of the heat equation

\begin{example}[recursive Brownian motion]
    see period5
\end{example}

\subsection{Heat Equation}
a geometric robust way to solve the heat equation and maybe a higher order method to solve
the heat equation

\subsection{Wave Equation}
probably won't get to it

\newpage
\printbibliography
\newpage

\section{Appendix}
Derivation of the green functions and some expressions.
\end{document}
