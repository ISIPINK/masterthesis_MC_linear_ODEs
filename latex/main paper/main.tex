\documentclass[a4paper,12pt]{article}


\setlength{\textwidth}{15.0cm}
\setlength{\textheight}{24.0cm}
\setlength{\topmargin}{0cm}
\setlength{\headsep}{0cm}
\setlength{\headheight}{0cm}
\pagestyle{plain}

\usepackage[dvips]{epsfig}
\usepackage{tikz}

\usepackage[
backend=biber,
style=alphabetic,
]{biblatex}

\usepackage{amsmath,amssymb,amsthm}
\input{environments.tex}

\usepackage{comment}
\usepackage{listings}
\input{custom commands.tex}

\addbibresource{bibliography.bib} 
\setlength{\parindent}{0pt}

\begin{document}

\begin{comment}
\title{Recursive Monte Carlo}
\author{Isidoor Pinillo Esquivel}
\maketitle
\end{comment}

\input{titelblad_MP.tex}

\newpage
\tableofcontents
\newpage

\begin{abstract}
    We will write this at the end. Also need a dutch abstract
\end{abstract}

\section{Introduction}

\subsection{Introductory Example}
In this subsection we introduce recursive  Monte Carlo with following problem:

\begin{equation} \label{ydy}
    y'=y, y(0)=1.
\end{equation}

Integrating both sides of (\ref{ydy}) obtains:

\begin{equation} \label{Integral ydy}
    y(t) = 1 + \int_{0}^{t} y(s) ds.
\end{equation}

Equation (\ref{Integral ydy}) is a recursive integral equation or to be more specific
a linear Volterra integral equation of the second type. By estimating the recursive integral
of equation (\ref{Integral ydy}) with Monte Carlo one derives following estimator:

\[
    Y(t) = 1 + t y(Ut)
    .\]

With $U \sim \text{Uniform}(0,1)$. If $y$ is well behaved then $E[Y(t)]=y(t)$ but we can't
calculate $Y(t)$ without accesses to $y(s),s<t$. Notice that we can replace $y$ by a
unbiased estimator of it without changing $E[Y(t)]=y(t)$ by the law of total expectance
($E[X] = E[E[X|Z]]$). By replacing $y$ by $Y$ itself we obtain a recursive expression for $Y$:

\begin{equation}\label{recursive RV}
    Y(t) = 1 + tY(Ut).
\end{equation}

Equation (\ref{recursive RV}) is a recursive random variable equation (RRVE). If you would implement equation
(\ref{recursive RV}) with recursion it will run indefinitely. A biased way of around this is by approximating
$Y(t) \approx 1$ near $t = 0$. Later we discuss Russian roulette (\ref{Russian roulette}) which
can be used as an unbiased stopping mechanism.

\vspace*{0.2cm}

\begin{pythonn}[implementation of (\ref{recursive RV})] \label{python eps ydy}
    \pythoncode{python code/eps_ydy.py}
    To gain insight into realizations of RRVEs, it can be helpful to plot
    all recursive calls $(t,Y(t))$, as shown in Figure \ref{fig:intro example}
    for this implementation.

    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/intro example.png}
        \caption{Recursive calls of (\ref{python eps ydy})}
        \label{fig:intro example}
    \end{figure}
\end{pythonn}

An issue with (\ref{python eps ydy}) is that the variance increases rapidly when $t$ increases. Later
this is issue gets resolved in the section on ODEs. Note that (\ref{python eps ydy}) keeps desirable properties
from unbiased Monte Carlo methods such as being embarrassingly parallel and
having simple error estimates.


\subsection{Contributions}
We write this at the end. Probably a lot of conjectures.

\subsection{Related Work}
work on
\begin{itemize}
    \item alternative methods for recursive integrals
    \item MC work on ODEs
    \item MC work on PDEs
    \item WoS
\end{itemize}
This is just to give a general overview we probably reference specific ideas when we first introduce them.

\section{Background}

\subsection{Notation}
Notations used in this thesis include:

\begin{itemize}
    \item $U \sim \text{Uniform}(0,1)$.
    \item $B(p) \sim \text{Bernoulli}(p)$.
    \item RV = random variable.
    \item RVs will be denoted with capital letters, e.g., $X,Y$ or $Z$.
    \item RRVE (recursive RV equation): An equation that defines a
          family of random variables in terms of its self.
    \item MC = Monte Carlo.
\end{itemize}


\subsection{Modifying Monte Carlo}
In this subsection, we discuss techniques for modifying RRVEs
in a way that preserves the expected value of the solution while
acquiring more desirable properties. \\

Russian roulette is a MC technique commonly used in rendering.
The main idea behind Russian roulette is to replace a random variable
with a less computationally expensive approximation sometimes.

\begin{definition}[Russian roulette] \label{Russian roulette}
    Define Russian roulette on $X$ with free parameters
    $Y_{1},Y_{2}: E[Y_{1}] = E[Y_{2}]$, $p \in [0,1]$ and $U$
    independent of $Y_{1},Y_{2},X$ the following way:
    \[
        X \rightarrow \begin{cases}
            \frac{1}{p}(X- (1-p)Y_{1}) & \text{ if } U<p \\
            Y_{2}                      & \text{ else }
        \end{cases}
        .\]
\end{definition}

\begin{example}[Russian roulette]
    Say that we are interested in estimating $E[Z]$ with $Z$
    defined in the following way:
    \[
        Z = U + \frac{f(U)}{1000}
        .\]
    where $f:\mathbb{R} \rightarrow [0,1]$ expensive to compute.
    Estimating $E[Z]$ directly would require calling $f$ each
    simulation. We can modify $Z$ to
    \[
        \tilde{Z} = U + B\left(\frac{1}{100}\right)\frac{f(U)}{10}
        .\]
    Now $\tilde{Z}$
    just requires calling $f$ on average once every $100$ simulations with the variance
    only increasing slightly compared to $Z$. \\

    In this example it is also possible to estimate the expectance of the $2$
    terms of $Z$ separately.
\end{example}

\begin{example}[Russian roulette on (\ref{recursive RV})]
    Russian roulette can fix the indefinite recursion issue of
    equation (\ref{recursive RV}) by approximating $Y$ near $t = 0$ with $1$
    sometimes. Concretely
    we replace the $t$ in front of the recursive term with $B(t)$
    when $t<1$.
    \[
        Y(t) =
        \begin{cases}
            1 + B(t)Y(Ut) & \text{ if } t<1 \\
            1 + tY(Ut)    & \text{ else}
        \end{cases}
        .\]
\end{example}

\vspace{0.2cm}

\begin{pythonn}[Russian roulette on (\ref{recursive RV})] \label{RRpython}
    \pythoncode{python code/RR_ydy.py}
    Interestingly, $Y(t)$ is constrained to take on only integer values.
    This is visually evident on Figure \ref{fig:russian roulette}.
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/russian roulette example.png}
        \caption{Recursive calls $(t,Y(t))$ of (\ref{RRpython}) }
        \label{fig:russian roulette}
    \end{figure}

\end{pythonn}

Splitting is a technique that has almost the reverse effect of Russian roulette.
Instead of reducing the number of simulations of a RV as Russian roulette does,
we increase it by using more samples (i.e., splitting the samples) which
reduces the variance.

\begin{definition}[splitting] \label{def:splitting}
    Splitting $X$ means using multiple $X_{j} \sim X$ not independent per se to
    lower variance by averaging them:
    \[
        \bar{X}= \frac{1}{N} \sum_{j=1}^{N} X_{j}
        .\]
\end{definition}

Splitting the recursive term in a RRVE can lead to (additive) branching recursion,
which requires extra care to ensure that the branches get terminated quickly to avoid
an exponential increase in computational complexity. This can be achieved by employing
termination strategies that have already been discussed. Later on, we will discuss
the use of coupled recursion as a technique for alleviating additive branching
recursion in RRVEs.

\begin{example}[splitting on (\ref{recursive RV})]
    We can "split" the recursive term of  (\ref{recursive RV}) in $2$:
    \[
        Y(t) = 1 + \frac{t}{2}(Y_{1}(Ut)+Y_{2}(Ut))
        .\]
    with $Y_{1}(t),Y_{2}(t)$ i.i.d. $Y(t)$.
\end{example}

\vspace{0.2cm}

\begin{pythonn}[splitting on (\ref{recursive RV})]
    \pythoncode{python code/SRR_ydy.py}
\end{pythonn}

\begin{definition}[$2$-level MC] \label{2 level}
    $2$-level MC on $X$ with parameters $\tilde{X}, Y: E[\tilde{X}]=E[Y]$:
    \[
        X \rightarrow X-\tilde{X} + Y
        .\]
\end{definition}

\begin{definition}[control variates] \label{CV}
    Control variate on $f(X)$ is
    \[
        f(X) \rightarrow f(X)-\tilde{f}(X) + E[\tilde{f}(X)]
        .\]
\end{definition}
Control variates are a special case of $2$-level MC. Usually $\tilde{f}$ is an approximation
of $f$ to reduce variance.

\begin{example}[control variate on (\ref{recursive RV})]
    To make a control variate for (\ref{recursive RV}) that reduces variance
    we use following approximation of $y(t) \approx 1+t$:
    \[
        Y(t)= 1+t+\frac{t^{2}}{2} + t(Y(Ut)-1-Ut)
        .\]
    Notice that we can cancel the constant term of the control variate
    but that would affect the Russian roulette negatively.
\end{example}

\vspace*{0.2cm}
\begin{pythonn}[control variate on (\ref{recursive RV})]
    \pythoncode{python code/CVRR_ydy.py}
\end{pythonn}

\begin{comment}
Introduces Russian roulette, splitting, control variates, importance sampling and maybe quasi Monte Carlo with the
$y'=y$ example. We are missing importance sampling and quasi MC
\end{comment}

\begin{related}
    Our favorite work that discusses these techniques is \cite{veach_robust_nodate}.
    More interesting works can be found on MC techniques in rendering.
    $2$-level gets discussed in \cite{giles_multilevel_2013}.
\end{related}
% need to fix veach refrence see bibliography

\subsection{Monte Carlo Trapezoidal Rule}
We present in this subsection a MC trapezoidal rule with similar convergence behavior to
methods discussed later. The MC trapezoidal rule will just be
regular MC control variated with the normal trapezoidal rule.

\begin{definition}[MC trapezoidal rule]
    Define the MC trapezoidal rule for $f$ on $[x,x+dx]$ the following
    way:
    \begin{equation}
        \int_{x}^{x+dx} f(s)ds \approx
        \frac{f(x)+f(x+dx)}{2} + f(S_{x})-f(x)-\frac{S_{x}-x}{dx} \left(f(x+dx)-f(x)\right)
    \end{equation}
    with $S_{x} = \text{Uniform}(x,x+dx)$.
\end{definition}


Defining the composite MC trapezoidal rule as
the sum of MC trapezoidal rules on equally divided intervals
is possible but expensive. Every interval would add a function call
compared to the normal composite MC trapezoidal rule. Instead
you can aggressively Russian roulette into the normal trapezoidal rule
such that the increase in functions calls is arbitrarily small.

\begin{definition}[composite MC trapezoidal rule] \label{MCtrap}
    Define the composite MC trapezoidal rule for $f$ on $[a,b]$ with
    $n$ intervals and a Russian roulette rate $l$ the following way:
    \begin{align}
         & \int_{a}^{b} f(s)ds \approx        \\
         & \sum_{x}  \frac{f(x)+f(x+dx)}{2} +
        l B \left(\frac{1}{l} \right)
        \left(f(S_{x})-f(x)-\frac{S_{x}-x}{dx}(f(x+dx)-f(x)) \right)
    \end{align}

    with $S_{x} = \text{Uniform}(x,x+dx)$.

\end{definition}

\begin{pythonn}[implementation of (\ref{MCtrap})]
    We implement (\ref{MCtrap}) for $\int_{0}^{1}e^{s}ds$.
    \vspace*{0.5cm}
    \pythoncode{python code/trap1.py}

    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/MCtrap.png}
        \caption{Log-log plot of (\ref{MCtrap}) for
        $\int_{0}^{1}e^{s}ds$ with $l=100$.
        %There are some artifacts of floating-point arithmetic.  
        }
        \label{fig:MCtrap}
    \end{figure}
\end{pythonn}

We postulate that this MC composite rule enhances the convergence
rate by $0.5$ orders compared to the standard composite rule for each dimension,
provided that the appropriate conditions of smoothness are met.
To substantiate this conjecture, we shall outline our rationale concerning
the accumulation of unbiased polynomial errors.\\

For the sake of simplicity, we reduce the study of the local truncation error
to the following expression:
\[
    \int_{0}^{h} s^{2}ds = O(h^{3})
    .\]

In the standard composite rule, we would drop this term, but in
the MC version, we eliminate the bias. As a result,
the local truncation error behaves like:

\[
    \int_{0}^{h} s^{2}ds- h(hU)^{2} = \int_{0}^{h} s^{2}ds- h^{3}U^{2} = O(h^{3})
    .\]

The main distinction between the standard and MC rule lies in how they
accumulate local truncation errors into global truncation error. In the standard
case, there is a loss of one order. When measuring the error of randomized algorithms
, the root mean square error is typically used, which, in the unbiased case,
is equivalent to the standard deviation:

\begin{align*}
    \sqrt{\text{Var}\left(\sum_{j=1}^{n} \int_{0}^{h} s^{2}ds- h^{3}U_{j}^{2}\right)}
     & =\sqrt{\text{Var}\left(\sum_{j=1}^{n} h^{3}U_{j}^{2}\right)}   \\
     & =h^{3} \sqrt{\text{Var}\left( \sum_{j=1}^{n} U_{j}^{2}\right)} \\
     & =h^{3} \sqrt{ \sum_{j=1}^{n}\text{Var} (U_{j}^{2})}            \\
     & =h^{3} \sqrt{ n \text{Var}(U^{2})}                             \\
     & =h^{3} \sqrt{n} \sqrt{ \text{Var}(U^{2})}                      \\
     & = O(h^{2.5}).
\end{align*}


\begin{related}
    Optimal theoretical bounds on randomized algorithms can be found in:
    (see literature randomized trapezoidal rule)
    \cite{wu_randomised_2020}. The half order convergence that randomized
    gains over determinstic isn't the same gain we consider.
\end{related}

\subsection{Unbiased Non-Linearity}
In this subsection we introduce techniques to deal with non-linearity.
At first it may looks only possible to deal with linear problems in an unbiased way but by using
independent samples it possible to deal with polynomial non-linearity's (which theoretically extend
to any continuos functions by the Weierstrass approximation theorem).  It is not always easy to
transform non-linearity into polynomials but it is not difficult to come up with
biased alternative approaches based on linearization or approximate polynomial non-linearity.


\begin{example}[$y'=y^{2}$]
    Let's do following example:
    \begin{equation} \label{dyy2}
        y'= y^2,y(1)=-1.
    \end{equation}
    This has solution $-\frac{1}{t}$. Integrate both sides of
    equation (\ref{dyy2}) to arrive at following integral equation:
    \begin{equation} \label{Integral dyy2}
        y(t) = -1 + \int_{1}^{t} y(s) y(s) ds .
    \end{equation}
    To estimate the recursive integral in equation (\ref{Integral ydy}) we use $2$
    independent $Y_{1},Y_{2}\sim Y$ :

    \begin{equation} \label{RRVE yy2}
        Y(t) = -1 + (t-1) Y_{1}(S) Y_{2}(S).
    \end{equation}

    With $S \sim \text{Uniform}(1,t)$. This is a branching RRVE this is
    typical when dealing with non-linearity.
\end{example}

\vspace*{0.2cm}
\begin{pythonn}[$y'=y^{2}$]
    %important note while implementing equation (\ref{RRVE yy2})  
    \pythoncode{python code/dyy2.py}
\end{pythonn}

\begin{example}[$e^{E[X]}$]
    $e^{\int x(s)ds}$ is common expression encountered when studying ODEs.
    In this example we demonstrate how you can generate unbiased estimates of
    $e^{E[X]}$ with simulations of $X$. The taylor series of $e^{x}$ is:
    \begin{align}
        e^{E[X]} & = \sum_{n=0}^{\infty} \frac{E^{n}[X]}{n!}     \\
                 & = 1 + \frac{1}{1}E[X]\left(1+ \frac{1}{2}E[X]
        \left(1+\frac{1}{3}E[X]\left(1+ ...\right)\right)\right). \label{taylor e}
    \end{align}
    Change the fractions of equation (\ref{taylor e}) to Bernoulli processes
    and replace all $X$ with independent $X_j$ with $E[X]=E[X_{i}]$.
    \begin{align*}
        e^{E[X]} & = E
        \left[1 + B\left(\frac{1}{1}\right)E[X_1]
        \left(1+ B\left(\frac{1}{2}\right)E[X_2]
        \left(1+B\left(\frac{1}{3}\right)E[X_3]
        \left(1+ ...\right)
        \right)
        \right)
        \right]              \\
                 & = E\left[
            1 + B\left(\frac{1}{1}\right)X_1
            \left(1+ B\left(\frac{1}{2}\right)X_2
            \left(1+B\left(\frac{1}{3}\right)X_3
            \left(1+ ...\right)
            \right)
            \right)
        \right]              \\
    \end{align*}
    What is inside the expectation is something that we can simulate with simulations of $X_{j}$.
\end{example}

\vspace{0.2cm}
\begin{pythonn}[$e^{E[X]}$]
    The following python code estimates $e^{\int_{0}^{t} s^{2}ds}$:
    \vspace*{0.4cm}
    \pythoncode{python code/expX.py}
    %}
\end{pythonn}

\begin{related}
    A similar approach to non-linearity can be found in \cite{ermakov_monte_2019}.
    We have more papers on how to deal with non-linearity stashed, no idea if they are
    worth mentioning.
\end{related}

\subsection{Recursion}
In this subsection we discuss recursion related techniques.

\begin{technique}[coupled recursion]
    The idea behind coupled recursion is sharing recursion calls of
    multiple RRVEs for simulation. This does make them dependent.
    It is like assuming $2$ induction hypotheses at the same
    time and proving both inductions steps at the same time vs
    doing separate induction proofs. Which should be easier
    because you have accesses to more assumptions at the same time.
\end{technique}

\begin{example}[coupled recursion]
    Lets say you are interested in calculating the
    sensitivity of the solution of an ODE to a
    parameter $a$:
    \begin{align}
        y'             & =ay,y(0)=1 \Rightarrow \label{couple recu ex1} \\
        \partial_{a}y' & = y + a \partial_{a}y \label{couple recu ex2}
    \end{align}
    Turn (\ref{couple recu ex1}) and (\ref{couple recu ex2}) into RRVEs.
    To emphasize that they are coupled, that they should
    recurse together we write them in a matrix equation:
    \begin{equation} \label{coupled mat}
        \begin{bmatrix}
            Y(t) \\
            \partial_{a}Y(t)
        \end{bmatrix}=
        \begin{bmatrix}
            1 \\
            0
        \end{bmatrix}+
        t \begin{bmatrix}
            a & 0 \\
            1 & a
        \end{bmatrix}
        \begin{bmatrix}
            Y(Ut) \\
            \partial_{a}Y(Ut)
        \end{bmatrix}.
    \end{equation}
    Notice how this gets rid of the additive branching
    recursion of equation (\ref{couple recu ex2}).

\end{example}

\begin{pythonn} [implementation of (\ref{coupled mat})]
    \pythoncode{python code/coupled_mat.py}
\end{pythonn}

\begin{technique}[recursion in recursion]
    Recursion in recursion is what is sounds like. It is like proving an induction
    step of an induction proof with induction.
\end{technique}

%\begin{example}[recursion in recursion]
%    maybe induction in induction proof example or a reference to ODE solvers later.
%\end{example}

\begin{related}[recursion in recursion]
    The next flight variant of WoS
    is a beautiful example of recursion in recursion described in
    \cite{sawhney_grid-free_2022}.
\end{related}

Most programming languages support recursion but this comes with restrictions
like maximum recursion depth and performance issues. When possible tail recursion is
a way to implement recursion that solves those
issues.

\begin{technique}[non-branching tail recursion]
    Tail recursion involves reordering all operations
    so that almost no operation needs to happen after
    the recursion call. This allows us to return the
    answer without retracing all steps when we reach
    the last recursion call, and it can achieve similar
    speeds to a forward implementation.
\end{technique}

The non-branching recursion presented in the RRVEs
can be implemented straightforwardly due to the associativity of
all operations ($(xy)z = x(yz)$) involved. However, tail recursion
may not always be desirable as it discards intermediate values of
the recursion calls which may be of interest. To retain some of these intermediate
values while still partly optimizing for performance, it is possible
to combine tail recursion with normal recursion.

\begin{pythonn}[tail recursion on (\ref{coupled mat})]
    We implement (\ref{coupled mat}) but this time with tail recursion.
    We collect addition operations in a vector $sol$ and multiplication
    in a matrix $W$.
    \vspace{0.3cm}
    \pythoncode{python code/tailrecu.py}
\end{pythonn}

%Branching tail recursion is hard. There  are multiple ways to
%do branching tail recursion with each their advantages and disadvantages. \\
%In the context of recursive MC there are $2$ techniques that
%stand out:

%\begin{technique}[tree regrowing]
%    The structure of branching recursion can be captured by a tree. Storing that tree
%    in memory can be expensive. In recursion you only need to retrace steps
%    $1$ by $1$ therefore you only need local parts of the recursion tree. Tree
%    regrowing tries to alleviate memory issues by instead storing the whole
%    tree only storing seeds (of the random generator) of parts of the
%    tree and growing them when needed.
%\end{technique}
%
%\begin{technique}[backward tail recursion]
%    One way of doing branching tail recursion is by using operation buffers for
%    all leafs which is not memory friendly. In backward tail recursion you retrace
%    steps and do all operations in reverse to recover the buffer needed.
%\end{technique}


\begin{related}[branching recursion]
    This blog discusses branching tail recursion:
    \url{https://jeroenvanwijgerden.me/post/recursion-1/}.
    Interesting techniques  like tail recursion  gets discussed in \cite{vicini_path_2021}.
\end{related}


\section{ODEs}

%\subsection{Linear Recursive Integrals}
%We have algo in mind for this case based on coupled recursion on disjunct sets.
%
%\begin{definition}[Volterra equation of the second kind]
%    A Volterra equation of the second kind for $x$  is of the following form:
%    $$
%        x(t)=f(t)+\int_a^t K(t, s) x(s) ds.
%    $$
%    Given the kernel  $K(t, s)$  and  $ f(t)$.
%\end{definition}
%


\subsection{Introduction}
In this subsection we discuss informally how to turn ODEs into integral equations mainly
by example.
Our main tool for this are green functions. Before defining green functions
we do some examples.  \\

\begin{example}[$y'=y$]
    Let's solve
    \begin{equation} \label{ydy int}
        y'=y.
    \end{equation}
    but this time with the following condition:
    \[
        \int_{0}^{1} y(s) ds = e-1
        .\]
    This still has solution $y(t)=e^{t}$. We define the corresponding source
    green function $G(t,x)$ for $y'$ and this type of condition as follows:
    \[
        G'= \delta(x-t), \int_{0}^{1}G(s,x)ds = 0
        .\]
    Solving this obtains:
    \[
        G(t,x) = H(t-x) +x-1
        .\]
    with
    \[
        H(x) = \begin{cases}
            0 & \text{ if } x<0 \\
            1 & \text{ else }
        \end{cases}
        .\]

    Note that we could have used a different green function corresponding
    to a different linear differential operator. \\

    It shouldn't be clear from this point but with this green
    function we form following integral equation for (\ref{ydy int}):
    \begin{equation} \label{int ydy int}
        y(t)= e -1 + \int_{0}^{1}G(t,s)y(s)ds.
    \end{equation}
    Turning equation (\ref{int ydy int}) into a RRVE with recursive MC gives:

    \begin{equation}\label{RRVE ydy int}
        Y(t)= e-1 + 2B\left(\frac{1}{2} \right)Y(S)(H(t-S)+S-1) .
    \end{equation}

    With $S \sim U$. We will be skipping over the python implementation of equation (\ref{RRVE ydy int})
    because it adds nothing new.
    Instead we plot realizations of equation (\ref{RRVE ydy int}) in Figure \ref{fig:ydy int}.

    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/ydy int.png}
        \caption{Recursive calls of (\ref{RRVE ydy int}) when
            calling $Y(0.5)$ $300$ times. Points accumulate on
            the green line due to the Russian roulette,
            and at  $t=0.5$ because it is the starting
            value of the simulation.
        }
        \label{fig:ydy int}
    \end{figure}

\end{example}

\begin{example}[$y''=y$]
    Lets solve the following boundary problem:
    \begin{equation} \label{ddyy}
        y'' = y, y(0) = 1, y'(1)=e.
    \end{equation}
    This has solution $y(t) = e^{t}$. We define the source green function $G(t,x)$
    for $y''$ and Dirichlet/Neumann boundary conditions in the following way:

    \[
        G''= \delta(t-x),G(0)=0,G'(1)=0
        .\]

    Solving this obtains:

    \[
        G(t,x) =
        \begin{cases}
            -t & \text{if } t <  x   \\
            -x & \text{if } t \ge  x
        \end{cases}
        .\]

    The boundary green function $P(t,x)$ (for $x \in \{0,1\}$)
    for $y''$ and Dirichlet/Neumann boundary conditions is defined
    the following way:
    \[
        P'' = 0, \left(P(0,x),P'(1,x) \right)=
        \begin{cases}
            (1 , 0) & \text{ if } x=0 \\
            (0 , 1) & \text{ if } x=1
        \end{cases}
        .\]
    Which is just a basis for the homogenous solutions for now. Solving
    this gives:

    \[
        P(t,x) =
        \begin{cases}
            1 & \text{ if } x=0 \\
            t & \text{ if } x=1
        \end{cases}
        .\]

    Again it shouldn't be clear from this point but with these set of green
    functions we form following integral equation for (\ref{ddyy}):

    \begin{equation} \label{int ddyy}
        y(t) = P(t,0)y(0) + P(t,1)y(1) + \int_{0}^{1}G(t,s) y(s) ds.
    \end{equation}

    Equation (\ref{int ddyy}) looks like:
    \begin{equation} \label{RRVE ddyy}
        Y(t) = 1 + te + l B\left(\frac{1}{l}\right)G(t,S)Y(S).
    \end{equation}
    With $S \sim U$ and $l>1 \in  \mathbb{R}$. We visualize equation (\ref{RRVE ddyy}) on
    Figure \ref{fig:ddyy}.

    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/ddyy.png}
        \caption{Recursive calls of (\ref{RRVE ddyy}), $l=2$ when
            calling $Y(0.5)$ $300$ times.}
        \label{fig:ddyy}
    \end{figure}

\end{example}


%\begin{definition}[boundary green function]
%    we write this later
%    %   The boundary green function of a linear differential problem with linear boundary
%    %   conditions.
%\end{definition}
%
%\begin{definition}[source green function]
%    we write this later
%    %    For
%    %    \[
%    %        L(y(z)) = f
%    %        .\]
%    %    with $L$ a linear differential operator, $z$ a point in the input space of $y$
%    %    ,$f$ arbitrary and linear boundary conditions.
%    %    We define the source green function $G(z,s)$ with following property
%    %    \[
%    %        L(G(z,s))=\delta(z-s).
%    %        .\C
%    %    and null boundary conditions.
%\end{definition}
%
%
%\begin{example}[numerical green functions]
%    There will be probably some green functions that we need
%    that don't have an analytic expression yet.
%\end{example}

% Green's function vs green function (check chatgpt for the answer)
\begin{definition}[green function]
    Vaguely speaking we define the green function as a type of kernel function that we use
    to solve linear problems with linear conditions. The Green's function is the kernel that
    we need to put in front of  the linear conditions or the source term that we integrate
    over and to obtain the solution  and the green function has the property that it satisfies
    either null linear conditions and a Dirac delta source term, or vice versa.
\end{definition}

% maybe an example of difference equation

\subsection{Convergence}

The ODE examples we have seen so far exhibit rapidly increasing variance as the domain increases,
some cases this leads to non-convergence. However, we have not yet discussed convergence
criteria for recursive Monte Carlo. Rather than delving deeply into variance
or convergence analysis, we will suggest potential solutions in this subsection.

\begin{example}[Dirichlet $y''=y$] \label{main dirichlet}
    The following problem will be the main testing example for
    boundary value problems:
    \begin{equation} \label{eq:main dirichlet}
        y''=y, y(b_{0}),y(b_{1}).
    \end{equation}
    The green functions corresponding to $y''$ and Dirichlet conditions are:

    \begin{align*}
        P(t,x) & = \begin{cases}
                       \frac{b_{1}-t}{b_{1}-b_{0}} & \text{if } x = b_{0} \\
                       \frac{t-b_{0}}{b_{1}-b_{0}} & \text{if } x = b_{1}
                   \end{cases}       \\
        G(t,s) & = \begin{cases}
                       -\frac{(b_{1}-t)(s-b_{0})}{b_{1}-b_{0}} & \text{if } s<t \\
                       -\frac{(b_{1}-s)(t-b_{0})}{b_{1}-b_{0}} & \text{if } t<s
                   \end{cases}.
    \end{align*}
    Straight from these green functions you get following integral equation and RRVE:
    \begin{align} \label{inteq:main dirichlet}
        y(t) & = P(t,b_{0}) y(b_{0}) + P(t,b_{1}) y(b_{1}) + \int_{b_{0}}^{b_{1}} G(t,s)y(s) ds \\
        Y(t) & = P(t,b_{0}) y(b_{0}) + P(t,b_{1}) y(b_{1})
        + l B\left(\frac{1}{l} \right)(b_{1}-b_{0}) G(t,S)y(S) . \label{RRVE:main dirichlet}
    \end{align}
    With $l \in \mathbb{R}$ the Russian roulette rate and $S \sim \text{Uniform}(b_{1},b_{0})$.

\end{example}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plots/mainD explosion.png}
    \caption{The logarithmic percentage error of $Y(0)$ for
    (\ref{RRVE:main dirichlet}), with $l=1.2$ and initial conditions
    $y(-k)=e^{-k}$ and $y(k)=e^{k}$, displays an exponential
    increase until approximately $k=1.5$, beyond which additional
    simulations fail to reduce the error, indicating that the variance
    doesn't exist.}
    \label{fig:mainD explosion}
\end{figure}

\begin{definition}[Fredholm equation of the second kind]
    A Fredholm equation of the second kind for $\varphi$  is of the following form:
    $$
        \varphi(t)=f(t)+\lambda \int_a^b K(t, s) \varphi(s) ds.
    $$
    Given the kernel  $K(t, s)$  and  $ f(t)$.
\end{definition}

% comes straight from wikipedia
% \begin{definition}[Liouville–Neumann series]
%     The Liouville–Neumann series for a Fredholm equation of the second kind
%     is defined as
%     \begin{equation}
%         \phi(x)=\sum_{n=0}^{\infty} \lambda^n \phi_n(x).
%     \end{equation}

%     If the $n$th iterated kernel is defined as $n-1$ nested integrals of $n$ operators $K$,

%     $$
%         K_n(x, z)=\iint \cdots \int K\left(x, y_1\right) K\left(y_1, y_2\right)
%         \cdots K\left(y_{n-1}, z\right) d y_1 d y_2 \cdots d y_{n-1}
%     $$
%     $K_0$ may be taken to be $\delta(x-z)$.

%     then

%     $$
%         \phi_n(x)=\int K_n(x, z) f(z) d z
%     $$

%     With

%     $$
%         \phi_0(x)=f(x),
%     $$

%     so
% \end{definition}

If both $K$ and $f$ are nice, then for sufficiently small $\lambda$,
it is straightforward to establish the existence and uniqueness of solutions
for Fredholm equations of the second kind using a fix point argument. \\


We would like to have MC algorithm that converges in that case. Our best guess is
a combination of splitting and coupling.



\begin{example}[coupled splitting on (\ref{main dirichlet})]
    Next to normal splitting (\ref{def:splitting}) we can
    also split the domain in equation (\ref{inteq:main dirichlet}):
    \begin{align}\label{inteq:coupled splitting}
        y(t) & = P(t,b_{0}) y(b_{0}) + P(t,b_{1}) y(b_{1}) +
        \frac{1}{2} \int_{b_{0}}^{b_{1}} G(t,s)y(s) ds +
        \frac{1}{2} \int_{b_{0}}^{b_{1}} G(t,s)y(s) ds                                              \\
        y(t) & = P(t,b_{0}) y(b_{0}) + P(t,b_{1}) y(b_{1}) + \label{inteq:coupled domain splitting}
        \int_{b_{0}}^{\frac{b_{1}+b_{0}}{2}} G(t,s)y(s) ds +
        \int_{\frac{b_{1}+b_{0}}{2}}^{b_{1}} G(t,s)y(s) ds
    \end{align}

    Coupling can get rid of the additive branching recursion in the RRVEs corresponding
    to (\ref{inteq:coupled splitting}) and (\ref{inteq:coupled domain splitting}).
    Resulting in following RRVE:
    \begin{equation} \label{RRVE:coupled splitting}
        X(t_{1},t_{2})=
        \begin{bmatrix}
            P(t_{1},b_{0}) & P(t_{1},b_{1}) \\
            P(t_{2},b_{0}) & P(t_{2},b_{1})
        \end{bmatrix}
        \begin{bmatrix}
            y(b_{0}) \\
            y(b_{1})
        \end{bmatrix}
        +
        W
        \begin{bmatrix}
            G(t_{1},S_{1}) & G(t_{1},S_{2}) \\
            G(t_{2},S_{1}) & G(t_{2},S_{2})
        \end{bmatrix}
        X(S_{1},S_{2}).
    \end{equation}
    With $W$ the right weighting matrix and $S_{1},S_{2}$ can be chosen in various
    ways.

    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/coupled split.png}
        \caption{Recursive calls of equation (\ref{RRVE:coupled splitting}) when
        calling $X(0)$ once,
        with a split size of $20$, $S_{j}$ being domain split coupled such
        they're equally spaced and coupling is colored.
        The initial conditions for this call are $y(-1)=e^{-1}$ and $y(1)=e^{1}$,
        with $l=1.2$.  }
        \label{fig:coupled splitting}
    \end{figure}

\end{example}
It appears that  Figure \ref{fig:coupled splitting}
resemble a fixed point iterations, leading us to hypothesize
that coupled splitting can achieve convergence in most cases
where a fixed point argument holds true. \\
Coupled splitting was tested on the example shown in Figure
\ref{fig:mainD explosion}, but it did not contribute to the
convergence of the method. This suggests that a fix point argument
would not be effective for this particular example.

\begin{related}[coupled splitting]
    Coupled splitting is very similar to the ideas discussed in
    \cite{sabelfeld_sparsified_2009}. (the paper on using more rows
    for MC in linear systems)
\end{related}

explaining that coupled split is cool for global problems but for
ODEs and PDEs we are interested in exploiting locality.

\subsection{IVPs ODEs}
In this subsection we do some IVPs examples.

\begin{example}[RRMC $y'=y$]
    intro example of RRMC + convergence result
\end{example}

talk about how to get higher order convergence with
control variates

\begin{example}[control RRMC $y'=y$]
    example of control variated RRMC
\end{example}

talk about non-linearity and bias, Newton (linearized in time) and maybe
how other methods deal with nonlinearity and a fix by special CVs strategies.

\begin{example}[nonlinear RRMC]

    We made an example to show that RRMC works for non linear problems but it is biased.
    The inner recursions are correlated because they use the same info from the outer
    recursions, this doesn't mean that reducing variance by splitting doesn't work
    , you just have to be careful with the bias. (see statistical learning they have
    a whole set of tools to estimate performance when considering bias vs variance)

    Consider:
    $$
        y' = y^{2} - t^{4} +2t,y(0)=0.
    $$
    with solution: $y(t)=t^{2}$. With integral equation:
    $$
        y(t)= y(T) + \int_{T}^{t} y^{2}(s) ds - \frac{t^{5}-T^{5}}{5} +(t^{2}-T^{2}) .
    $$
    control variating $y^{2}(s)$ up to second order:
    \begin{align*}
        y^{2}(t) & \approx y^{2}(T) + 2(t-T)y(T)y'(T) + ((t-T)y'(T))^{2} + O((t-T)^{2}) \\
                 & \approx y^{2}(T) + 2(t-T)y(T)y'(T)+ O((t-T)^{2})
    \end{align*}

    we could have kept the third term we think it would be more accurate but we're lazy. Then we have to integrate the control variate:

    \begin{align*}
        \int_{T}^{t} & y^{2}(T) + 2(s-T)y(T)y'(T) ds                                          \\
                     & = (t-T)y^{2}(T)+ 2\left(\frac{t^{2}-T^{2}}{2} -T(t-T) \right)y(T)y'(T)
    \end{align*}
    .
\end{example}

talk about stability and then conjecture a solution DRRMC

\begin{example}[DRRMC]
    diagonal RRMC
\end{example}

talk about performance stability and maybe comparison to parareal
(critical path and how to measure performance)


\subsection{BVPs ODEs}

\begin{example}[local BVP]
    a RRMC algo for dirichlet see period 5
\end{example}

discuss getting higher order

\begin{example}[higher order local BVP]
    a higher order RRMC algo + convergence
\end{example}


\section{Recursive Brownian Motion}

\subsection{Brownian Motion}
introduces Brownian motion

\subsection{Boundary Green Function Of The Heat Equation}
introduce with $1$D case, numerically calculating it

\subsection{Recursive Brownian Motion}
WoS like way to simulate Brownian motion which is related to the green function
of the heat equation, this

\begin{related}[recursive Brownian motion]
    see Brownian motion tag in zotero
\end{related}

\subsection{Heat Equation}
a geometric robust way to solve the heat equation and maybe a higher order method to solve
the heat equation



\newpage
\printbibliography
\newpage

\section{Appendix}
Derivation of the green functions and some expressions.
\end{document}
