\documentclass[a4paper,12pt]{article}


\setlength{\textwidth}{15.0cm}
\setlength{\textheight}{24.0cm}
\setlength{\topmargin}{0cm}
\setlength{\headsep}{0cm}
\setlength{\headheight}{0cm}
\pagestyle{plain}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=blue,
    citecolor=blue,
    linktoc=page
}
\usepackage[dvips]{epsfig}
\usepackage{tikz}

\usepackage[
backend=biber,
style=alphabetic,
]{biblatex}

\renewcommand{\bibfont}{\footnotesize}

\usepackage{amsmath,amssymb,amsthm}
\input{environments.tex}

\usepackage{comment}
\usepackage{listings}
\input{custom commands.tex}

\addbibresource{bibliography2.bib} 
\setlength{\parindent}{0pt}

\begin{document}

\begin{comment}
\title{Recursive Monte Carlo}
\author{Isidoor Pinillo Esquivel}
\maketitle
\end{comment}

\input{titelblad_MP.tex}

\newpage
\tableofcontents
\newpage

\begin{abstract}
    We will write this at the end. Also need a dutch abstract
\end{abstract}

\section{Introduction}

\subsection{Introductory Example}
In this subsection we introduce recursive
Monte Carlo with our main example
for initial value problems:

\begin{equation} \label{ydy}
    y'=y, y(0)=1.
\end{equation}

Integrating both sides of (\ref{ydy}) obtains:

\begin{equation} \label{Integral ydy}
    y(t) = 1 + \int_{0}^{t} y(s) ds.
\end{equation}

Equation (\ref{Integral ydy}) is a recursive integral equation or to be more specific
a linear Volterra integral equation of the second type. By estimating the recursive integral
of equation (\ref{Integral ydy}) with Monte Carlo one derives following estimator:

\begin{equation}
    Y(t) = 1 + t y(Ut).
\end{equation}

With $U \sim \text{Uniform}(0,1)$. If $y$ is well behaved then $E[Y(t)]=y(t)$ but we can not
calculate $Y(t)$ without accesses to $y(s),s<t$. Notice that we can replace $y$ by a
unbiased estimator of it without changing $E[Y(t)]=y(t)$ by the law of total expectance
($E[X] = E[E[X|Z]]$). By replacing $y$ by $Y$ itself we obtain a recursive expression for $Y$:

\begin{equation}\label{recursive RV}
    Y(t) = 1 + tY(Ut).
\end{equation}

Equation (\ref{recursive RV}) is a recursive random variable equation. If you would implement equation
(\ref{recursive RV}) with recursion it will run indefinitely. A biased way of around this is by approximating
$Y(t) \approx 1$ near $t = 0$. Later we discuss Russian roulette (\ref{Russian roulette}) which
can be used as an unbiased stopping mechanism.

\vspace*{0.2cm}

\begin{pythonn}[implementation of (\ref{recursive RV})] \label{python eps ydy}
    \pythoncode{python code/eps_ydy.py}
    To gain insight into realizations of recursive random variable equation,
    it can be helpful to plot
    all recursive calls $(t,Y(t))$, as shown in Figure \ref{fig:intro example}
    for this implementation.

    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/intro example.png}
        \caption{Recursive calls of (\ref{python eps ydy})}
        \label{fig:intro example}
    \end{figure}
\end{pythonn}

An issue with (\ref{python eps ydy}) is that the variance increases rapidly when $t$ increases. Later
this is issue gets resolved in (\ref{ex:RRMC IVP}). Note that (\ref{python eps ydy}) keeps desirable properties
from unbiased Monte Carlo methods such as being embarrassingly parallel and
having simple error estimates.

\subsection{Notation}
Notations used in this thesis include:

\begin{itemize}
    \item $B(p) \sim \text{Bernoulli}(p) =
              \begin{cases}
                  1 & \text{ if } U<p \\
                  0 & \text{ else }
              \end{cases}. $
    \item $ H(x) =
              \begin{cases}
                  0 & \text{ if } x<0 \\
                  1 & \text{ else }
              \end{cases}.$
    \item $U \sim \text{Uniform}(0,1)$.
    \item BVP = Boundary Value Problem.
    \item FP = First Passage.
    \item IVP = Initial Value Problem.
    \item MC = Monte Carlo.
    \item ODE = Ordinary Differential Equation.
    \item PDE = Partial Differential Equation.
    \item RMC = Recursive Monte Carlo.
    \item RRMC = Recursion in Recursion Monte Carlo.
    \item RRVE (Recursive Random Variable Equation): An equation that defines a
          family of random variables in terms of its self.
    \item RV = Random Variable.
    \item Random variables will be denoted with capital letters, e.g., $X,Y$ or $Z$.
\end{itemize}

\subsection{Related Work}
The main motivation for this thesis is the walk on sphere method for $2$nd order elliptic PDEs
with varying coefficients with Dirichlet boundary conditions
discussed in \citeauthor{sawhney_grid-free_2022}'s
\citeyear{sawhney_grid-free_2022} \cite{sawhney_grid-free_2022} paper.
This recursive Monte Carlo method
is accurate even if the boundary conditions are geometric complex. We studied the
mechanics behind these type of Monte Carlo techniques.

\begin{related}[MC for IVPs ODEs]
    Monte Carlo methods for initial value problems for systems of ordinary
    differential equations are little studied. The most significant works are:
    \begin{itemize}
        \item \citeauthor{jentzen_random_2009}'s \citeyear{jentzen_random_2009}
              \cite{jentzen_random_2009} paper describes a random Euler scheme for
              weak smoothness conditions.

        \item \citeauthor{daun_randomized_2011}'s \citeyear{daun_randomized_2011}
              \cite{daun_randomized_2011} paper describes a randomized algorithm that
              achieves higher order of convergence order optimal even
              then deterministic algorithms under the
              same smoothness conditions by using polynomial extrapolation and
              control variates.

        \item \citeauthor{ermakov_monte_2019}'s \citeyear{ermakov_monte_2019}
              \cite{ermakov_monte_2019}
              and \citeauthor{ermakov_monte_2021}'s \citeyear{ermakov_monte_2021}
              \cite{ermakov_monte_2021}
              papers study unbiased  methods
              for linear problems and slightly biased for nonlinear based
              on the Volterra integral equations.

    \end{itemize}

    % Previous Monte Carlo methods have limited applicability for
    % initial value problems for systems of ordinary differential equations.
    % From our personal perspective, the current literature on
    % this subject lacks rewarding insights.

    % Current is literature is quite involved

\end{related}

% \begin{related}[MC for linear systems]
%     MC methods can be employed to tackle an ODE or a PDE indirectly
%     by using it on the resulting linear system obtained through
%     a discretization technique. This approach may yield a similar
%     behavior to the original problem. Sampling the Von Neumann series
%     is the primary technique utilized for MC methods in linear systems.

%     \begin{itemize}
%         \item MC methods are common for the page rank problem \cite{zhang_advanced_2021}.
%         \item 
%     \end{itemize}

%     mmm

% \end{related}


\subsection{Contributions}
A significant part of this thesis is dedicated to informally introducing recursive Monte Carlo
with plenty of examples. The key contributions are:

\begin{itemize}
    \item An unbiased Monte Carlo method (\ref{ex:CV RRMC IVP}) for
          linear initial value problems for systems of ordinary
          differential equations. This method achieves a higher order of convergence
          in the time step size that is comparable to explicit deterministic methods.
    \item Coupled recursion (\ref{ex:coupled recursion}) and
          recursion in recursion (\ref{tech:recu in recu}) reformulations of the coupling in
          \cite{vicini_path_2021} and next flight in rendering see \cite{sawhney_grid-free_2022}
          the next flight version of walk on sphere.
\end{itemize}

In the background section we introduce Monte Carlo techniques, a
Monte Carlo trapezoidal rule and discuss
coupled recursion / recursion in recursion. \\

In the ordinary differential equation section we introduce green functions
to transform ODEs to integral equations and
build up to the our main algorithm for linear initial
value problems for systems of ordinary differential equations(\ref{ex:CV RRMC IVP}). \\

In the Brownian motion section we derive the connection of Brownian
Motion to the heat equation with recursive Monte Carlo and
introduce recursive first passage sampling. \\



\section{Background}



\subsection{Modifying Monte Carlo}
In this subsection, we discuss techniques for modifying RRVEs
in a way that preserves the expected value of the solution while
acquiring more desirable properties. \\

Russian roulette is a MC technique commonly used in rendering.
The main idea behind Russian roulette is to replace a random variable
with a less computationally expensive approximation sometimes.

\begin{definition}[Russian roulette] \label{Russian roulette}
    Define Russian roulette on $X$ with free parameters
    $Y_{1},Y_{2}: E[Y_{1}] = E[Y_{2}]$, $p \in [0,1]$ and $U$
    independent of $Y_{1},Y_{2},X$ the following way:
    \begin{equation}
        X \rightarrow \begin{cases}
            \frac{1}{p}(X- (1-p)Y_{1}) & \text{ if } U<p \\
            Y_{2}                      & \text{ else }
        \end{cases}.
    \end{equation}
\end{definition}

\begin{example}[Russian roulette] \label{ex:simple russian roulette}
    Say that we are interested in estimating $E[Z]$ with $Z$
    defined in the following way:
    \begin{equation}
        Z = U + \frac{f(U)}{1000}.
    \end{equation}
    where $f:\mathbb{R} \rightarrow [0,1]$ expensive to compute.
    Estimating $E[Z]$ directly would require calling $f$ each
    simulation. We can modify $Z$ to
    \begin{equation}
        \tilde{Z} = U + B\left(\frac{1}{100}\right)\frac{f(U)}{10}.
    \end{equation}
    Now $\tilde{Z}$
    just requires calling $f$ on average once every $100$ simulations with the variance
    only increasing slightly compared to $Z$. \\

\end{example}

\begin{related}[Russian roulette]
    In example (\ref{ex:simple russian roulette}) it is possible to estimate
    the expectance of the $2$ terms of $Z$ separately. Given the variances and
    computational complexity  of both terms you can calculate the asymptotical optimal
    division of samples for each term. \\
    In \cite{rath_ears_2022} they approximate optimal Russian roulette and splitting
    (RRS) factors with fixed-point iterations to maximize the efficiency in a renderer.
\end{related}

\begin{example}[Russian roulette on (\ref{recursive RV})]
    Russian roulette can fix the indefinite recursion issue of
    equation (\ref{recursive RV}) by approximating $Y$ near $t = 0$ with $1$
    sometimes. Concretely
    we replace the $t$ in front of the recursive term with $B(t)$
    when $t<1$.
    \begin{equation}
        Y(t) =
        \begin{cases}
            1 + B(t)Y(Ut) & \text{ if } t<1 \\
            1 + tY(Ut)    & \text{ else}
        \end{cases}.
    \end{equation}
\end{example}

\vspace{0.2cm}

\begin{pythonn}[Russian roulette on (\ref{recursive RV})] \label{RRpython}
    \pythoncode{python code/RR_ydy.py}
    Interestingly, $Y(t)$ is constrained to take on only integer values.
    This is visually evident on Figure \ref{fig:russian roulette}.
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/russian roulette example.png}
        \caption{Recursive calls $(t,Y(t))$ of (\ref{RRpython}) }
        \label{fig:russian roulette}
    \end{figure}

\end{pythonn}

Splitting is a technique that has almost the reverse effect of Russian roulette.
Instead of reducing the number of simulations of a RV as Russian roulette does,
we increase it by using more samples (i.e., splitting the samples) which
reduces the variance.

\begin{definition}[splitting] \label{def:splitting}
    Splitting $X$ means using multiple $X_{j} \sim X$ not independent per se to
    lower variance by averaging them:
    \begin{equation}
        \bar{X}= \frac{1}{N} \sum_{j=1}^{N} X_{j}.
    \end{equation}
\end{definition}

Splitting the recursive term in a RRVE can lead to (additive) branching recursion,
which requires extra care to ensure that the branches get terminated quickly to avoid
an exponential increase in computational complexity. This can be achieved by employing
termination strategies that have already been discussed. Later on, we will discuss
the use of coupled recursion as a technique for alleviating additive branching
recursion in RRVEs (see (\ref{ex:coupled splitting})).

\begin{example}[splitting on (\ref{recursive RV})]
    We can "split" the recursive term of  (\ref{recursive RV}) in $2$:
    \begin{equation}
        Y(t) = 1 + \frac{t}{2}(Y_{1}(Ut)+Y_{2}(Ut)).
    \end{equation}
    with $Y_{1}(t),Y_{2}(t)$ i.i.d. $Y(t)$.
\end{example}

\vspace{0.2cm}

\begin{pythonn}[splitting on (\ref{recursive RV})]
    \pythoncode{python code/SRR_ydy.py}
\end{pythonn}

\begin{definition}[$2$-level MC] \label{2 level}
    $2$-level MC on $X$ with parameters $\tilde{X}, Y: E[\tilde{X}]=E[Y]$:
    \begin{equation}
        X \rightarrow X-\tilde{X} + Y.
    \end{equation}
\end{definition}

\begin{definition}[control variates] \label{CV}
    Control variate on $f(X)$ is
    \begin{equation}
        f(X) \rightarrow f(X)-\tilde{f}(X) + E[\tilde{f}(X)].
    \end{equation}
\end{definition}
Control variates are a special case of $2$-level MC. Usually $\tilde{f}$ is an approximation
of $f$ to reduce variance.

\begin{example}[control variate on (\ref{recursive RV})]
    To make a control variate for (\ref{recursive RV}) that reduces variance
    we use following approximation of $y(t) \approx 1+t$:
    \begin{equation}
        Y(t)= 1+t+\frac{t^{2}}{2} + t(Y(Ut)-1-Ut).
    \end{equation}
    Notice that we can cancel the constant term of the control variate
    but that would affect the Russian roulette negatively.
\end{example}

\vspace*{0.2cm}
\begin{pythonn}[control variate on (\ref{recursive RV})]
    \pythoncode{python code/CVRR_ydy.py}
\end{pythonn}

\begin{comment}
Introduces Russian roulette, splitting, control variates,
importance sampling and maybe quasi Monte Carlo with the
$y'=y$ example. We are missing importance sampling and quasi MC
\end{comment}

\begin{related}[MC modification]
    Our favorite work that discusses these techniques is \cite{veach_robust_nodate}.
    More interesting MC techniques  can be found in rendering.
    $2$-level gets discussed in \cite{giles_multilevel_2013} a introductory paper to
    multilevel MC.
\end{related}
% need to fix veach refrence see bibliography

\subsection{Monte Carlo Trapezoidal Rule}
We present in this subsection a MC trapezoidal rule with similar convergence behavior to
methods discussed later. The MC trapezoidal rule will just be
regular MC control variated with the normal trapezoidal rule.

\begin{definition}[MC trapezoidal rule]
    Define the MC trapezoidal rule for $f$ on $[x,x+dx]$ the following
    way:
    \begin{equation}
        \int_{x}^{x+dx} f(s)ds \approx
        \frac{f(x)+f(x+dx)}{2} + f(S_{x})-f(x)-\frac{S_{x}-x}{dx} \left(f(x+dx)-f(x)\right)
    \end{equation}
    with $S_{x} = \text{Uniform}(x,x+dx)$.
\end{definition}


Defining the composite MC trapezoidal rule as
the sum of MC trapezoidal rules on equally divided intervals
is possible but expensive. Every interval would add a function call
compared to the normal composite MC trapezoidal rule. Instead
you can aggressively Russian roulette into the normal trapezoidal rule
such that the increase in functions calls is arbitrarily small.

\begin{definition}[composite MC trapezoidal rule] \label{MCtrap}
    Define the composite MC trapezoidal rule for $f$ on $[a,b]$ with
    $n$ intervals and a Russian roulette rate $l$ the following way:
    \begin{align}
         & \int_{a}^{b} f(s)ds \approx        \\
         & \sum_{x}  \frac{f(x)+f(x+dx)}{2} +
        l B \left(\frac{1}{l} \right)
        \left(f(S_{x})-f(x)-\frac{S_{x}-x}{dx}(f(x+dx)-f(x)) \right)
    \end{align}

    with $S_{x} = \text{Uniform}(x,x+dx)$.

\end{definition}

\begin{pythonn}[implementation of (\ref{MCtrap})]
    We implement (\ref{MCtrap}) for $\int_{0}^{1}e^{s}ds$.
    \vspace*{0.5cm}
    \pythoncode{python code/trap1.py}

    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/MCtrap.png}
        \caption{Log-log plot of the error of (\ref{MCtrap}) for
        $\int_{0}^{1}e^{s}ds$ with $l=100$.
        The spikes in the graph are artifacts
        of floating-point arithmetic.
        }
        \label{fig:MCtrap}
    \end{figure}
\end{pythonn}

We postulate that this MC composite rule enhances the convergence
rate by $0.5$ orders compared to the standard composite rule for each dimension,
provided that the appropriate conditions of smoothness are met.
To substantiate this conjecture, we shall outline our rationale concerning
the accumulation of unbiased polynomial errors.\\

For the sake of simplicity, we reduce the study of the local truncation error
to the following expression:
\begin{equation}
    \int_{0}^{h} s^{2}ds = O(h^{3}).
\end{equation}

In the standard composite rule, we would drop this term, but in
the MC version, we eliminate the bias. As a result,
the local truncation error behaves like:

\begin{equation}
    \int_{0}^{h} s^{2}ds- h(hU)^{2} = \int_{0}^{h} s^{2}ds- h^{3}U^{2} = O(h^{3}).
\end{equation}

The main distinction between the standard and MC rule lies in how they
accumulate local truncation errors into global truncation error. In the standard
case, there is a loss of one order. When measuring the error of randomized algorithms
, the root mean square error is typically used, which, in the unbiased case,
is equivalent to the standard deviation:

\begin{align}
    \sqrt{\text{Var}\left(\sum_{j=1}^{n} \int_{0}^{h} s^{2}ds- h^{3}U_{j}^{2}\right)}
     & =\sqrt{\text{Var}\left(\sum_{j=1}^{n} h^{3}U_{j}^{2}\right)}   \\
     & =h^{3} \sqrt{\text{Var}\left( \sum_{j=1}^{n} U_{j}^{2}\right)} \\
     & =h^{3} \sqrt{ \sum_{j=1}^{n}\text{Var} (U_{j}^{2})}            \\
     & =h^{3} \sqrt{ n \text{Var}(U^{2})}                             \\
     & =h^{3} \sqrt{n} \sqrt{ \text{Var}(U^{2})}                      \\
     & = O(h^{2.5}).
\end{align}


\begin{related}[MC trapezoidal rule]
    In \cite{wu_randomised_2020} an improvement of a half order
    for a MC trapezoidal is also discussed but we aren't sure that it is similar to our
    half order improvement.
\end{related}

\subsection{Unbiased Non-Linearity}
In this subsection we introduce techniques to deal with non-linearity.
At first it may looks only possible to deal with linear problems in an unbiased way but by using
independent samples it possible to deal with polynomial non-linearity's (which theoretically extend
to any continuos functions by the Weierstrass approximation theorem).  It is not always easy to
transform non-linearity into polynomials but it is not difficult to come up with
biased alternative approaches based on linearization or approximate polynomial non-linearity.


\begin{example}[$y'=y^{2}$]
    Let's do following example:
    \begin{equation} \label{dyy2}
        y'= y^2,y(1)=-1.
    \end{equation}
    This has solution $-\frac{1}{t}$. Integrate both sides of
    equation (\ref{dyy2}) to arrive at following integral equation:
    \begin{equation} \label{Integral dyy2}
        y(t) = -1 + \int_{1}^{t} y(s) y(s) ds .
    \end{equation}
    To estimate the recursive integral in equation (\ref{Integral ydy}) we use $2$
    independent $Y_{1},Y_{2}\sim Y$ :

    \begin{equation} \label{RRVE yy2}
        Y(t) = -1 + (t-1) Y_{1}(S) Y_{2}(S).
    \end{equation}

    With $S \sim \text{Uniform}(1,t)$. This is a branching RRVE this is
    typical when dealing with non-linearity.
\end{example}

\vspace*{0.2cm}
\begin{pythonn}[$y'=y^{2}$]
    %important note while implementing equation (\ref{RRVE yy2})  
    \pythoncode{python code/dyy2.py}
\end{pythonn}

\begin{example}[$e^{E[X]}$] \label{ex:exp int}
    $e^{\int x(s)ds}$ is common expression encountered when studying ODEs.
    In this example we demonstrate how you can generate unbiased estimates of
    $e^{E[X]}$ with simulations of $X$. The taylor series of $e^{x}$ is:
    \begin{align}
        e^{E[X]} & = \sum_{n=0}^{\infty} \frac{E^{n}[X]}{n!}     \\
                 & = 1 + \frac{1}{1}E[X]\left(1+ \frac{1}{2}E[X]
        \left(1+\frac{1}{3}E[X]\left(1+ ...\right)\right)\right). \label{taylor e}
    \end{align}
    Change the fractions of equation (\ref{taylor e}) to Bernoulli processes
    and replace all $X$ with independent $X_j$ with $E[X]=E[X_{i}]$.
    \begin{align}
        e^{E[X]} & = E
        \left[1 + B\left(\frac{1}{1}\right)E[X_1]
        \left(1+ B\left(\frac{1}{2}\right)E[X_2]
        \left(1+B\left(\frac{1}{3}\right)E[X_3]
        \left(1+ ...\right)
        \right)
        \right)
        \right]              \\
                 & = E\left[
            1 + B\left(\frac{1}{1}\right)X_1
            \left(1+ B\left(\frac{1}{2}\right)X_2
            \left(1+B\left(\frac{1}{3}\right)X_3
            \left(1+ ...\right)
            \right)
            \right)
        \right]              \\
    \end{align}
    What is inside the expectation is something that we can simulate with simulations of $X_{j}$.
\end{example}

\vspace{0.2cm}
\begin{pythonn}[$e^{E[X]}$]
    The following python code estimates $e^{\int_{0}^{t} s^{2}ds}$:
    \vspace*{0.4cm}
    \pythoncode{python code/expX.py}
    %}
\end{pythonn}

\begin{related}[unbiased non-linearity]
    A similar approach to non-linearity can be found in \cite{ermakov_monte_2019}.
\end{related}

\subsection{Recursion}
In this subsection we discuss recursion related techniques.

\begin{technique}[coupled recursion]
    The idea behind coupled recursion is sharing recursion calls of
    multiple RRVEs for simulation. This does make them dependent.
    It is like assuming $2$ induction hypotheses at the same
    time and proving both inductions steps at the same time vs
    doing separate induction proofs. Which should be easier
    because you have accesses to more assumptions at the same time.
\end{technique}

\begin{example}[coupled recursion] \label{ex:coupled recursion}
    Lets say you are interested in calculating the
    sensitivity of the solution of an ODE to a
    parameter $a$:
    \begin{align}
        y'             & =ay,y(0)=1 \Rightarrow \label{couple recu ex1} \\
        \partial_{a}y' & = y + a \partial_{a}y \label{couple recu ex2}
    \end{align}
    Turn (\ref{couple recu ex1}) and (\ref{couple recu ex2}) into RRVEs.
    To emphasize that they are coupled, that they should
    recurse together we write them in a matrix equation:
    \begin{equation} \label{coupled mat}
        \begin{bmatrix}
            Y(t) \\
            \partial_{a}Y(t)
        \end{bmatrix}=
        X(t)=
        \begin{bmatrix}
            1 \\
            0
        \end{bmatrix}+
        t \begin{bmatrix}
            a & 0 \\
            1 & a
        \end{bmatrix}
        X(Ut).
        % \begin{bmatrix}
        %     Y(Ut) \\
        %     \partial_{a}Y(Ut)
        % \end{bmatrix}.
    \end{equation}
    Notice how this gets rid of the additive branching
    recursion of equation (\ref{couple recu ex2}).

\end{example}

\begin{pythonn} [implementation of (\ref{coupled mat})]
    \pythoncode{python code/coupled_mat.py}
\end{pythonn}

\begin{related}[coupled recursion]
    Example (\ref{ex:coupled recursion}) is inspired by \cite{vicini_path_2021}.
    \cite{yilmazer_solving_2022} extends \cite{vicini_path_2021} to walk on spheres.
    % Coupling feels close to percolation \cite{duminil-copin_sixty_2019}.
    % maybe I should search a paper that coupling in happens
\end{related}

\begin{technique}[recursion in recursion]\label{tech:recu in recu}
    Recursion in recursion is what is sounds like. It is like proving an induction
    step of an induction proof with induction.
\end{technique}

\begin{related}[recursion in recursion]
    Beautiful examples of recursion in recursion are
    the next flight variant of WoS in
    \cite{sawhney_grid-free_2022} and epoch based algorithms in optimization
    \cite{gupta_convergence_2021}.
\end{related}

Most programming languages support recursion but this comes with restrictions
like maximum recursion depth and performance issues. When possible tail recursion is
a way to implement recursion that solves those
issues.

\begin{technique}[non-branching tail recursion]
    Tail recursion involves reordering all operations
    so that almost no operation needs to happen after
    the recursion call. This allows us to return the
    answer without retracing all steps when we reach
    the last recursion call, and it can achieve similar
    speeds to a forward implementation.
\end{technique}

The non-branching recursion presented in the RRVEs
can be implemented with tail recursion due to the associativity of
all operations ($(xy)z = x(yz)$) involved. However, tail recursion
may not always be desirable as it discards intermediate values of
the recursion calls which may be of interest. To retain some of these intermediate
values while still partly optimizing for performance, it is possible
to combine tail recursion with normal recursion.

\begin{pythonn}[tail recursion on (\ref{coupled mat})]
    We implement (\ref{coupled mat}) but this time with tail recursion.
    We collect addition operations in a vector $sol$ and multiplication
    in a matrix $W$.
    \vspace{0.3cm}
    \pythoncode{python code/tailrecu.py}
\end{pythonn}


\subsection{Limitations and Future Work}
There are alot MC techniques we did not discuss like quasi MC and important sampling.
We would like to mention SALT as a MC technique that we find
particularly interesting and has received relatively little attention.

\begin{technique}[SALT]
    Sequential Approximation in L-Two (SALT) is an adaptive MC technique
    which builds control variates with a (bi-) orthonormal basis. The
    rough idea behind it is that calculating coefficients for
    an (bi-) orthonormal basis can be found by MC integration and
    the current estimate of those coefficients can accelerate MC integration.
    It can be seen as interesting case of stochastic gradient descent.
\end{technique}

% \begin{example}[SALT wavelet]
%     check period 3
% \end{example}

\begin{related}[SALT]
    SALT gets discussed in \cite{gobet_new_nodate}. Other papers noteworthy papers on
    adaptive MC techniques are \cite{he_adaptive_2021} on adaptive important sampling
    and \cite{salaun_regression-based_2022} on regression based MC.
\end{related}

% improving (\ref{ex:exp int})

Our current method for handling non-linearity, as demonstrated
in (\ref{ex:exp int}), is rudimentary and only applicable to small
levels of non-linearity. At present, we have not implemented any
variance reduction techniques in this context.
% \begin{example}[fixpoint]
%     check period 1
% \end{example}


The study of branching tail recursion is relatively scarce, but
it holds potential to improve our approach to handling non-linearity.
There exist multiple methods of implementing branching tail recursion,
each with its own set of benefits and drawbacks. When it comes to recursive
Monte Carlo, there are two techniques that are particularly noteworthy.

\begin{technique}[tree regrowing]
    The structure of branching recursion can be captured by a tree. Storing that tree
    in memory can be expensive. In recursion you only need to retrace steps
    $1$ by $1$ therefore you only need local parts of the recursion tree. Tree
    regrowing tries to alleviate memory issues by instead storing the whole
    tree only storing seeds (of the random generator) of parts of the
    tree and growing them when needed.
\end{technique}

\begin{technique}
    One way of doing branching tail recursion is by using operation buffers for
    all leafs which is not memory friendly. In backward tail recursion you retrace
    steps and do all operations in reverse to recover the buffer needed.
\end{technique}

\begin{related}[branching tail recursion]
    Tree regrowing and backward tail recursion ideas appear in
    \cite{vicini_path_2021}.
    This blog discusses branching tail recursion:
    \url{https://jeroenvanwijgerden.me/post/recursion-1/}.
\end{related}

\section{Ordinary Differential Equations }

%\subsection{Linear Recursive Integrals}
%We have algo in mind for this case based on coupled recursion on disjunct sets.
%
%\begin{definition}[Volterra equation of the second kind]
%    A Volterra equation of the second kind for $x$  is of the following form:
%    $$
%        x(t)=f(t)+\int_a^t K(t, s) x(s) ds.
%    $$
%    Given the kernel  $K(t, s)$  and  $ f(t)$.
%\end{definition}
%


\subsection{Green Functions}
In this subsection we discuss informally how to turn ODEs into integral equations mainly
by example. Our main tool for this are green functions. Before defining green functions
we do some examples.  \\

\begin{example}[$y'=y$ average condition]
    Let's solve
    \begin{equation} \label{ydy int}
        y'=y.
    \end{equation}
    but this time with the following condition:
    \begin{equation}
        \int_{0}^{1} y(s) ds = e-1.
    \end{equation}

    This still has solution $y(t)=e^{t}$. We define the corresponding source
    green function $G(t,x)$ for $y'$ and this type of condition as follows:
    \begin{equation}
        G'= \delta(x-t), \int_{0}^{1}G(s,x)ds = 0.
    \end{equation}
    Solving this obtains:
    \begin{equation}
        G(t,x) = H(t-x) +x-1.
    \end{equation}

    Note that we could have used a different green function corresponding
    to a different linear differential operator. \\

    It should not be clear from this point but with this green
    function we form following integral equation for (\ref{ydy int}):
    \begin{equation} \label{int ydy int}
        y(t)= e -1 + \int_{0}^{1}G(t,s)y(s)ds.
    \end{equation}
    Turning equation (\ref{int ydy int}) into a RRVE with recursive MC gives:

    \begin{equation}\label{RRVE ydy int}
        Y(t)= e-1 + 2B\left(\frac{1}{2} \right)Y(S)(H(t-S)+S-1) .
    \end{equation}

    With $S \sim U$. We will be skipping over the python implementation of equation (\ref{RRVE ydy int})
    because it adds nothing new.
    Instead we plot realizations of equation (\ref{RRVE ydy int}) in Figure \ref{fig:ydy int}.

    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/ydy int.png}
        \caption{Recursive calls of (\ref{RRVE ydy int}) when
            calling $Y(0.5)$ $300$ times. Points accumulate on
            the green line due to the Russian roulette,
            and at  $t=0.5$ because it is the starting
            value of the simulation.
        }
        \label{fig:ydy int}
    \end{figure}

\end{example}

\begin{example}[$y''=y$ mixed boundary conditions]
    Lets solve the following boundary problem:
    \begin{equation} \label{ddyy}
        y'' = y, y(0) = 1, y'(1)=e.
    \end{equation}
    This has solution $y(t) = e^{t}$. We define the source green function $G(t,x)$
    for $y''$ and Dirichlet/Neumann boundary conditions in the following way:

    \begin{equation}
        G''= \delta(t-x),G(0)=0,G'(1)=0.
    \end{equation}

    Solving this obtains:

    \begin{equation}
        G(t,x) =
        \begin{cases}
            -t & \text{if } t <  x   \\
            -x & \text{if } t \ge  x
        \end{cases}.
    \end{equation}

    The boundary green function $P(t,x)$ (for $x \in \{0,1\}$)
    for $y''$ and Dirichlet/Neumann boundary conditions is defined
    the following way:
    \begin{equation}
        P'' = 0, \left(P(0,x),P'(1,x) \right)=
        \begin{cases}
            (1 , 0) & \text{ if } x=0 \\
            (0 , 1) & \text{ if } x=1
        \end{cases}.
    \end{equation}

    Which is just a basis for the homogenous solutions for now. Solving
    this gives:

    \begin{equation}
        P(t,x) =
        \begin{cases}
            1 & \text{ if } x=0 \\
            t & \text{ if } x=1
        \end{cases}.
    \end{equation}

    Again it shouldn't be clear from this point but with these set of green
    functions we form following integral equation for (\ref{ddyy}):

    \begin{equation} \label{int ddyy}
        y(t) = P(t,0)y(0) + P(t,1)y(1) + \int_{0}^{1}G(t,s) y(s) ds.
    \end{equation}

    Equation (\ref{int ddyy}) looks like:
    \begin{equation} \label{RRVE ddyy}
        Y(t) = 1 + te + l B\left(\frac{1}{l}\right)G(t,S)Y(S).
    \end{equation}
    With $S \sim U$ and $l>1 \in  \mathbb{R}$. We visualize equation (\ref{RRVE ddyy}) on
    Figure \ref{fig:ddyy}.

    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/ddyy.png}
        \caption{Recursive calls of (\ref{RRVE ddyy}), $l=2$ when
            calling $Y(0.5)$ $300$ times.}
        \label{fig:ddyy}
    \end{figure}

\end{example}

\begin{related}[$y''=y$ mixed boundary conditions]
    \cite{sawhney_walk_2023} discusses an algorithm for mixed boundary conditions.
\end{related}


%\begin{definition}[boundary green function]
%    we write this later
%    %   The boundary green function of a linear differential problem with linear boundary
%    %   conditions.
%\end{definition}
%
%\begin{definition}[source green function]
%    we write this later
%    %    For
%    %    \[
%    %        L(y(z)) = f
%    %        .\]
%    %    with $L$ a linear differential operator, $z$ a point in the input space of $y$
%    %    ,$f$ arbitrary and linear boundary conditions.
%    %    We define the source green function $G(z,s)$ with following property
%    %    \[
%    %        L(G(z,s))=\delta(z-s).
%    %        .\C
%    %    and null boundary conditions.
%\end{definition}
%
%
%\begin{example}[numerical green functions]
%    There will be probably some green functions that we need
%    that don't have an analytic expression yet.
%\end{example}

% Green's function vs green function (check chatgpt for the answer)
\begin{definition}[green function]
    Vaguely speaking we define the green function as a type of kernel function that we use
    to solve linear problems with linear conditions. The green's function is the kernel that
    we need to put in front of  the linear conditions or the source term that we integrate
    over to obtain the solution.  The green function has the property that it satisfies
    either null linear conditions and a dirac delta source term, or vice versa.
\end{definition}

\begin{related}[green function]
    Our notion of green function is similar to that in \cite{hwang_simulationtabulation_2001}.
\end{related}

% maybe an example of difference equation

% \subsection{Convergence}
\subsection{Fredholm Integral Equations}

The integral equations acquired in the last subsection are Fredholm integral equations
of the second kind. In this subsection we introduce coupled splitting a technique for
RMC for this kind of equations.


\begin{definition}[Fredholm equation of the second kind]
    A Fredholm equation of the second kind for $\varphi$  is of the following form:
    \begin{equation}
        \varphi(t)=f(t)+\lambda \int_a^b K(t, s) \varphi(s) ds.
    \end{equation}
    Given the kernel  $K(t, s)$  and  $ f(t)$.
\end{definition}

If both $K$ and $f$ are nice, then for sufficiently small $\lambda$,
it is straightforward to establish the existence and uniqueness of solutions
for Fredholm equations of the second kind using a fix point argument.

% We would like to have MC algorithm that converges in that case. Our best guess is
% a combination of splitting and coupling.

\begin{example}[Dirichlet $y''=y$] \label{main dirichlet}
    The following problem will be the main testing example for
    boundary value problems:
    \begin{equation} \label{eq:main dirichlet}
        y''=y, y(b_{0}),y(b_{1}).
    \end{equation}
    The green functions corresponding to $y''$ and Dirichlet conditions are:

    \begin{align}
        P(t,x) & = \begin{cases}
                       \frac{b_{1}-t}{b_{1}-b_{0}} & \text{if } x = b_{0} \\
                       \frac{t-b_{0}}{b_{1}-b_{0}} & \text{if } x = b_{1}
                   \end{cases}       \\
        G(t,s) & = \begin{cases}
                       -\frac{(b_{1}-t)(s-b_{0})}{b_{1}-b_{0}} & \text{if } s<t \\
                       -\frac{(b_{1}-s)(t-b_{0})}{b_{1}-b_{0}} & \text{if } t<s
                   \end{cases}.
    \end{align}
    Straight from these green functions you get following integral equation and RRVE:
    \begin{align} \label{inteq:main dirichlet}
        y(t) & = P(t,b_{0}) y(b_{0}) + P(t,b_{1}) y(b_{1}) + \int_{b_{0}}^{b_{1}} G(t,s)y(s) ds \\
        Y(t) & = P(t,b_{0}) y(b_{0}) + P(t,b_{1}) y(b_{1})
        + l B\left(\frac{1}{l} \right)(b_{1}-b_{0}) G(t,S)y(S) . \label{RRVE:main dirichlet}
    \end{align}
    With $l \in \mathbb{R}$ the Russian roulette rate and $S \sim \text{Uniform}(b_{1},b_{0})$.

\end{example}



% comes straight from wikipedia
% \begin{definition}[Liouville–Neumann series]
%     The Liouville–Neumann series for a Fredholm equation of the second kind
%     is defined as
%     \begin{equation}
%         \phi(x)=\sum_{n=0}^{\infty} \lambda^n \phi_n(x).
%     \end{equation}

%     If the $n$th iterated kernel is defined as $n-1$ nested integrals of $n$ operators $K$,

%     $$
%         K_n(x, z)=\iint \cdots \int K\left(x, y_1\right) K\left(y_1, y_2\right)
%         \cdots K\left(y_{n-1}, z\right) d y_1 d y_2 \cdots d y_{n-1}
%     $$
%     $K_0$ may be taken to be $\delta(x-z)$.

%     then

%     $$
%         \phi_n(x)=\int K_n(x, z) f(z) d z
%     $$

%     With

%     $$
%         \phi_0(x)=f(x),
%     $$

%     so
% \end{definition}


% fix point argument is when von neumann series converges


\begin{example}[coupled splitting on (\ref{main dirichlet})] \label{ex:coupled splitting}
    Next to normal splitting (\ref{def:splitting}) we can
    also split the domain in equation (\ref{inteq:main dirichlet}):
    \begin{align}\label{inteq:coupled splitting}
        y(t) & = P(t,b_{0}) y(b_{0}) + P(t,b_{1}) y(b_{1}) +
        \frac{1}{2} \int_{b_{0}}^{b_{1}} G(t,s)y(s) ds +
        \frac{1}{2} \int_{b_{0}}^{b_{1}} G(t,s)y(s) ds                                              \\
        y(t) & = P(t,b_{0}) y(b_{0}) + P(t,b_{1}) y(b_{1}) + \label{inteq:coupled domain splitting}
        \int_{b_{0}}^{\frac{b_{1}+b_{0}}{2}} G(t,s)y(s) ds +
        \int_{\frac{b_{1}+b_{0}}{2}}^{b_{1}} G(t,s)y(s) ds
    \end{align}

    Coupling can get rid of the additive branching recursion in the RRVEs corresponding
    to (\ref{inteq:coupled splitting}) and (\ref{inteq:coupled domain splitting}).
    Resulting in following RRVE:
    \begin{equation} \label{RRVE:coupled splitting}
        X(t_{1},t_{2})=
        \begin{bmatrix}
            P(t_{1},b_{0}) & P(t_{1},b_{1}) \\
            P(t_{2},b_{0}) & P(t_{2},b_{1})
        \end{bmatrix}
        \begin{bmatrix}
            y(b_{0}) \\
            y(b_{1})
        \end{bmatrix}
        +
        W
        \begin{bmatrix}
            G(t_{1},S_{1}) & G(t_{1},S_{2}) \\
            G(t_{2},S_{1}) & G(t_{2},S_{2})
        \end{bmatrix}
        X(S_{1},S_{2}).
    \end{equation}
    With $W$ the right weighting matrix (see code (\ref{py:coupled splitting}) for an example)
    and $S_{1},S_{2}$ can be chosen in various ways.
\end{example}

\begin{pythonn}[implementation of (\ref{RRVE:coupled splitting})] \label{py:coupled splitting}
    We implemented equation (\ref{RRVE:coupled splitting}) in example
    (\ref{ex:coupled splitting}) with recursion but in this case it
    is actually possible to implement it forwardly because the time
    proces is nice. \\
    \pythoncode{python code/coupled_splitting.py}

    % can probably make a better plot then this one
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/coupled split.png}
        \caption{Recursive calls of equation (\ref{RRVE:coupled splitting}) when
        calling $X(0)$ once,
        with a split size of $20$, $S_{j}$ coupled such
        they're equally spaced (they don't have to be independent) and coupling is colored.
        The initial conditions for this call are $y(-1)=e^{-1}$ and $y(1)=e^{1}$,
        with Russian roulette rate $l=1.2$.  }
        \label{fig:coupled splitting}
    \end{figure}
\end{pythonn}


Figure \ref{fig:coupled splitting}
resembles a fixed point iterations, leading us to hypothesize
that coupled splitting can achieve convergence in most cases
where a fixed point argument holds true and that the convergence
speed is very similar to fix points methods until the accuracy
of the stochastic approximation of the operator is reached
(the approximate operator bottleneck). The approximation of the operator
can be improved by increasing coupled splitting amount usually done when
approaching the bottleneck. Alternatively when reaching
the bottleneck it is possible to rely on MC convergence.
% (Additional
% iterations beyond the bottleneck do not
% bring the solution closer but they still remain unbiased with low variance)
\\


Example (\ref{ex:coupled splitting}) isn't the best example to demonstrate
coupled splitting. We don't exploit locality and smoothness of the problem.
We conjecture that this algorithm is useful for
linear Fredholm equations of the second kind in cases where MC integration win
over classic integration: high dimensional, non-smooth kernels or
nasty domains.

\begin{related}[coupled splitting]
    Coupled splitting is partly inspired by how \cite{sabelfeld_sparsified_2009}
    reduces variance by using a bigger submatrices .
    See \cite{gupta_convergence_2021} for a discussion on convergence
    of recursive stochastic algorithms. We highly recommend watching
    the corresponding video \cite{abhishek_gupta_recursive_2020} before reading
    the paper. Coupled splitting doesn't work for walk on sphere because
    of the dynamically changing domain. A technique based on reusing samples
    like coupled splitting  gets discussed in \cite{miller_boundary_2023}.
\end{related}

% explaining that coupled split is cool for global problems but for
% ODEs and PDEs we are interested in exploiting locality.

\subsection{Initial Value Problems}
Classic IVP solvers rely on shrinking the time steps for
convergence. In this subsection we build up to
Recursion in Recursion MC (RRMC) for IVPs that tries to emulate
this behavior.



\begin{example}[RRMC $y'=y$] \label{ex:RRMC IVP}
    Let's us explain RRMC for IVPs with our main example.
    Imagine we have a time stepping sheme $(t_{n})$ ($t_{n}> t_{n-1}$)
    then following integral equations hold:
    \begin{equation}
        y(t)= y(t_{n}) + \int_{t_{n}}^{t}y(s)ds , t>t_{n}.
    \end{equation}
    Turn these in following class of RRVEs:

    \begin{equation}
        Y_{n}(t) = y(t_{n}) + (t-t_{n})Y_{n}((t-t_{n})U+t_{n}), t>t_{n}.
    \end{equation}

    A problem with these RRVEs is that we do not know $y(t_{n})$.
    Instead we can replace it with an unbiased estimate $y_{n}$
    which we keep frozen:
    \begin{align}
        \label{eq:RRMC IVP inner}
        Y_{n}(t) & = y_{n} + (t-t_{n})Y_{n}((t-t_{n})U+t_{n}), t>t_{n} \\
        y_{n}    & = \begin{cases}
                         Y_{n-1}(t_{n}) & \text{ if } n \neq 0 \\
                         y(t_{0})       & \text{ if } n = 0
                     \end{cases}.
        \label{eq:RRMC IVP outer}
    \end{align}
    We refer to equation (\ref{eq:RRMC IVP inner}) as the inner recursion and
    equation (\ref{eq:RRMC IVP outer}) as the outer recursion of the recursion in
    recursion.
\end{example}
% maybe measurements of amount of calls to f

\begin{pythonn}[implementation of (\ref{ex:RRMC IVP})] \label{py:RRMC IVP}
    \pythoncode{python code/RRMC_IVP.py}
    We measured the convergence speed to be $O\left(\frac{h^{1.5}}{\sqrt{\text{nsim}}}
        \right)$.

    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/RRMC IVP.png}
        \caption{Recursive calls of equation (\ref{eq:RRMC IVP outer})
            when calling $Y_{\text{out}}(3,h)$ $30$ times for different $h$.  }
        \label{fig:RRMC IVP}
    \end{figure}
\end{pythonn}

$1.5$ order of convergence is cool but this begs the question on how to achieve
higher order of convergence in $h$. Again it is easy to imitate classical methods
to achieve higher order convergence. We do this by removing lower order terms which requires
smoothness with control variates like the MC trapezoidal rule (\ref{MCtrap}).

\begin{example}[CV RRMC $y'=y$]\label{ex:CV RRMC IVP}
    Let us control variate example (\ref{ex:RRMC IVP}). Start
    with:
    \begin{equation}
        y(t)= y(t_{n}) + \int_{t_{n}}^{t}y(s)ds , t>t_{n}.
    \end{equation}
    We need a lower order approximation of the integrand:
    \begin{align}
        y(s) & = y(t_{n}) + (s-t_{n})y'(t_{n}) + O((s-t_{n})^{2})       \\
             & \approx y(t_{n}) + (s-t_{n})f(y(t_{n}),t_{n})            \\
             & \approx y(t_{n}) +
        (s-t_{n})\left(\frac{y(t_{n})-y(t_{n-1})}{t_{n}-t_{n-1}}\right) \\
             & \approx y(t_{n})(1+s-t_{n}).
    \end{align}

    Using the last one as a control variate for the integral:
    \begin{align}
        y(t) & = y(t_{n}) + \int_{t_{n}}^{t}y(s)ds                                          \\
             & = y(t_{n}) + \int_{t_{n}}^{t}y(s)-y(t_{n})(1+s-t_{n}) +y(t_{n})(1+s-t_{n})ds \\
             & = y(t_{n})\left(1 + (1-t_{n})(t-t_{n})+\frac{t^{2}-t_{n}^{2}}{2}\right)
        + \int_{t_{n}}^{t}y(s)-y(t_{n})(1+s-t_{n})ds.
    \end{align}
    We won't discuss turning this into an RRVE nor the implementation. The implementation
    is very similar to (\ref{py:nonlinear RRMC IVP}) and
    Figure \ref{fig:CV RRMC IVP} is a convergence plot for this example.

    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/CV RRMC IVP.png}
        \caption{Log-log plot of example (\ref{ex:CV RRMC IVP}).}
        \label{fig:CV RRMC IVP}
    \end{figure}
\end{example}

\begin{related}[CV RRMC]
    \cite{daun_randomized_2011} similarly uses control variates to achieve
    a higher order of convergence.
\end{related}

RRMC is biased for our approach to non-linear problems.
The inner recursions are correlated because they use the same
information from the outer recursions, this doesn't mean that reducing
root mean square error by splitting doesn't work, you just have to be careful
with the bias. We conjecture that the bias in RRMC converges faster then the
variance when decreasing $h$.


\begin{example}[nonlinear RRMC IVP] \label{ex:nonlinear RRMC IVP}
    Consider:

    \begin{equation}
        y' = y^{2} - t^{4} +2t,y(0)=0.
    \end{equation}

    with solution: $y(t)=t^{2}$. With integral equation:

    \begin{equation}
        y(t)= y(t_{n}) + \int_{t_{n}}^{t} y^{2}(s) ds
        - \frac{t^{5}-t_{n}^{5}}{5} +(t^{2}-t_{n}^{2}) .
    \end{equation}

    control variating $y^{2}(s)$ up to second order (via Taylor):
    \begin{align}
        y^{2}(t) & \approx y^{2}(t_{n}) + 2(t-t_{n})y(t_{n})y'(t_{n})
        + ((t-t_{n})y'(t_{n}))^{2} + O((t-t_{n})^{2})                                   \\
                 & \approx y^{2}(t_{n}) + 2(t-t_{n})y(t_{n})y'(t_{n})+ O((t-t_{n})^{2})
    \end{align}

    Then we have to integrate the control variate:

    \begin{align}
        \int_{t_{n}}^{t} & y^{2}(t_{n}) + 2(s-t_{n})y(t_{n})y'(t_{n}) ds \\
                         & = (t-t_{n})y^{2}(t_{n})+
        2\left(\frac{t^{2}-t_{n}^{2}}{2} -t_{n}(t-t_{n}) \right)y(t_{n})y'(t_{n}).
    \end{align}
    We implement this example in (\ref{py:nonlinear RRMC IVP}) and
\end{example}

\begin{pythonn}[implementation of (\ref{ex:nonlinear RRMC IVP})] \label{py:nonlinear RRMC IVP}
    \pythoncode{python code/nonlinear_CVRRMC.py}
\end{pythonn}


% \subsection{BVPs ODEs}

% Now we hope we can imitate what we did for IVPs to get converging RMC
% algorithms for BVPs. The $2$ essential trick that we used for RRMC IVP are
% integral representations on subdomains and unbiased estimators for the linear
% conditions. \\

% TODO: fix it or leave it out
% \begin{example}[alternating RRMC]
%     We demonstrate alternating RRMC on example (\ref{main dirichlet})
%     with $y(-2)=e^{-2}$ and $y(2)=e^{2}$ which didn't have convergence on
%     (\ref{fig:mainD explosion}).
%     In alternating RRMC we use integral equations of overlapping domains see Figure
%     (\ref{fig:alternating RRMC}) and communicate boundary conditions in the outer recursion.
%     \begin{figure}[ht!]
%         \centering
%         \includegraphics[width=0.8\textwidth]{tikz figures/local RRMC/axis.pdf}
%         \caption{}
%         \label{fig:alternating RRMC}
%     \end{figure}
% \end{example}

% \begin{related}
%     Schwarz alternating method, walk on rectangles paper.
% \end{related}

\subsection{Limitations and Future Work}

Right now we don't have a RMC algorithm for IVPs that can
guarantee a reasonable variance or even existence when increasing the time domain.
Classing IVP solvers rely on shrinking the time steps for
convergence. Recursion in Recursion MC (RRMC) for IVPs tries to emulate
this behavior.

RMC convergence issues, exploding variance problems
quasi RRMC

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plots/mainD explosion.png}
    \caption{The logarithmic percentage error of $Y(0)$ for
    (\ref{RRVE:main dirichlet}), with $l=1.2$ and initial conditions
    $y(-k)=e^{-k}$ and $y(k)=e^{k}$, displays an exponential
    increase until approximately $k=1.5$, beyond which additional
    simulations fail to reduce the error, indicating that the variance
    doesn't exist.}
    \label{fig:mainD explosion}
\end{figure}

Coupled splitting was tested on the example shown in Figure
\ref{fig:mainD explosion}, but it did not contribute to the
convergence of the method. This suggests that a fix point argument
would not be effective for this particular example with this
Russian roulette setup. \\

Similarly to classic methods, RRMC struggles with big negative coefficients in front
of the recursive parts. DRRMC is a potential solution to this problem but we don't think
it is effective.

\begin{definition}[DRRMC]
    Consider a general linear ODE IVP problem:
    \begin{equation}
        x' = Ax+g, x(0)= x_{0}.
    \end{equation}
    Sometimes repeatedly multiplying by $A$ is unstable.
    Diagonal RRMC adds a positive diagonal matrix $D$
    to $A$ and hopes that it stabilizes.

    \begin{equation}
        x' + Dx = (A+D)x+g.
    \end{equation}

    Following integral equation can be derived by using integrating factor:

    \begin{equation}
        x(t)= e^{D(t_{n}-t)}x(t_{n}) + \int_{t_{n}}^{t} e^{D(s-t)}(A+D)x(s)ds+\int_{t_{n}}^{t} e^{D(s-t)}g(s)ds.
    \end{equation}

    Remember that the exponential of a diagonal matrix is the exponential of its elements.
    The recursive integral has the following trivial control variate:

    \begin{equation}
        \int_{t_{n}}^{t}  e^{D(s-t)}(A+D)x(t_{n})ds = D^{-1}(I-e^{D(t_{n}-t)})(A+D)x(t_{n}).
    \end{equation}

    Note that $D$ may be chosen differently every recursion.
\end{definition}

\begin{example}[DRRMC]
    Consider
    $$
        x'= Ax, x(0)=
        \begin{pmatrix}
            1 \\
            0
        \end{pmatrix}.
    $$

    With

    $$
        A = \begin{pmatrix}
            0     & 1     \\
            -1000 & -1001
        \end{pmatrix}.
    $$



    we choose $D$ fixed over all outer recursions:

    $$
        D = \begin{pmatrix}
            1 & 0    \\
            0 & 1000
        \end{pmatrix}.
    $$

\end{example}

% TODO: 
% (critical path and how to measure performance)  see period 6 tests

\begin{related}[DRRMC]
    DRRMC is inspired by  $\bar{\sigma}$ parameter in \cite{sawhney_grid-free_2022} but
    instead of importance sampling and weight window we use control variates  to deal with
    nonlinearity introduced by the exponential because it needs to work over
    an entire vector at the same time. Similar manipulations can also be found
    in exponential integrator methods.
\end{related}




\begin{example}[random ODEs] \label{ex:random ode}
    Let's solve:
    \begin{equation}
        Y' = AY, Y(0)=1 , A = \text{Uniform}(0,1).
    \end{equation}

    With solution $Y(t)= e^{tA}$ which is a RV. With
    the techniques we have right now we can simulate ''unbiased estimates
    of simulations of the solution'' $X$. With
    these you can get $E[f(Y(t))]$ (with $f$ analytic)
    to the problem:
    \begin{align}
        E_{A}[f(Y(t))] & = E_A[f(Y(t)) \mid  A]        \\
                       & = E_A[f(E_x[X(t,A)]) \mid  A]
    \end{align}
    We can estimate $f(E_x[X(t,A)])$ like (\ref{ex:exp int}).
    In our example we estimate the first $2$ moments which can
    be derived from the solution:
    \begin{align}
        E_A[Y(t)]     & =  \frac{e^{t}}{t} - \frac{1}{t}    \\
        E_A[Y^{2}(t)] & =  \frac{e^{2t}}{2t} - \frac{1}{2t}
    \end{align}
\end{example}

\begin{pythonn}[implementation of (\ref{ex:random ode})]
    \pythoncode{python code/random_ODE.py}
\end{pythonn}


IVPs solver problems slow and instable, maybe special cases.
CV in the inner recursion example with recursing on DY

notion of green function is vague maybe not the right tools
mention mixed boundary work
\section{Brownian Motion}

Current RMC algorithms for PDEs are linked to Brownian motion. In this
section build up to recursive first passage sampling which is similar to
walk on sphere.



\subsection{Heat Equation}
In this subsection we introduce the relation between the heat equation and
Brownian motion.

\begin{definition}[Brownian motion]
    Define Brownian motion $W_{t}$ as the limit/logical generalization
    when $n \rightarrow \infty$ of following discrete proces defined as:
    \begin{equation}
        \begin{cases}
            X_{t}^{n} = X_{t-\frac{1}{n}}^{n} + Z_{n} \\
            X^{n}_{0}=0
        \end{cases}.
    \end{equation}
    With $Z_{n}\sim N(0,\frac{1}{n})$ i.i.d . From this definition it is easily seen that
    $W_{t} \sim N(0,t)$.
\end{definition}


\begin{lemma}[self-affinity Brownian motion] \label{lem:self affine}
    Brownian motion is self affine as a random proces that means you can cut a small
    part of it move so it starts in $0$ and scale time to the original size
    and space such that the variance stays the same to get back the whole Brownian motion.

    \begin{equation}
        \forall c \in \mathbb{R}^{+}_{0}: \frac{W_{ct}}{\sqrt{c}} \sim W_{t}.
    \end{equation}
\end{lemma}

\begin{definition}[$1$D heat equation Dirichlet] \label{def:heat equation}
    We define the $1$D heat equation for $u$ on connected domain $\Omega$
    with  Dirichlet boundary conditions the following way:
    \begin{equation}
        \frac{\partial u}{\partial t} = \frac{\partial^{2} u}{\partial x ^{2}}.
    \end{equation}
    Given $u(x,t)=\psi(x,t) ,\forall (x,t) \in \partial \Omega: t<\sup \{
        t| (x,t) \in \Omega\}$ .
\end{definition}

% maybe should improve this 
An example how the Dirichlet condition is defined for a domain
is the parabola on Figure \ref{fig:Euler first passage para} but
reverse in time.

\begin{lemma}[Brownian motion and the heat equation] \label{lem:BM HE}
    For problem (\ref{def:heat equation}) if $ |\psi|< \infty$
    there is following formula:

    \begin{equation}
        u(x,t)=E[\psi(Y_{\tau},\tau) | Y_{t} =x].
    \end{equation}
    With $dY_{s} = dW_{-s},\tau = \sup\{s | (Y_{s},s) \notin \Omega\}$ .
\end{lemma}


\begin{proof}
    Discretize the heat equation
    with a regular rectangular mesh that includes $(x,t)$ with equally
    spaced intervals over space and time ($\Delta x, \Delta t$) with
    the corresponding difference equation:

    \begin{equation}
        \frac{u(x,t)-u(x,t-\Delta t)}{\Delta t} = \frac{u(x + \Delta x,t)-2 u(x,t) +u(x - \Delta x,t)}{\Delta x^{2}} .
    \end{equation}

    Isolate $u(x,t)$:

    \begin{equation} \label{eq:discrete iso heat equation}
        u(x,t) =
        \frac{\Delta t}{ 2 \Delta t + \Delta x^{2}}
        \left(
        u(x+\Delta x,t)+u(x-\Delta x,t)
        \right) +
        \frac{\Delta x^{2}}{ 2 \Delta t + \Delta x^{2}}
        \left(
        u(x,t-\Delta t)
        \right).
    \end{equation}

    Because $u(x+\Delta x,t) \approx u(x-\Delta x,t) \approx u(x,t-\Delta t) \approx$
    RHS of equation (\ref{eq:discrete iso heat equation}) we may Russian roulette
    to remove branching recursion and generate a recursion path instead of a tree.
    \begin{equation} \label{eq:RRVE discrete heat equation }
        Z(x,t) =
        \begin{cases}
            \psi(\text{argmin}_{b \in \partial \Omega} ||(x,t) - b||)
             & \text{ when } (x,t) \notin \Omega \\
            \begin{cases}
                Z(x+\Delta x , t)  & \text{ with chance  } \frac{\Delta t}{ 2 \Delta t + \Delta x^{2}}     \\
                Z(x-\Delta x , t)  & \text{ with chance  } \frac{\Delta t}{ 2 \Delta t + \Delta x^{2}}     \\
                Z(x, t - \Delta t) & \text{ with chance  } \frac{\Delta x^{2}}{ 2 \Delta t + \Delta x^{2}}
            \end{cases}
             & \text{ else }.
        \end{cases}
    \end{equation}
    This is a RRVE, $Z$ has finite variance because $ |\psi|< \infty$
    and $E[Z(x,t)]$ is the solution to the discretized heat equation. Taking the limit
    makes the discrete solution go the the real solution.
    For (\ref{eq:RRVE discrete heat equation }) the limit
    makes the recursion path go to Brownian motion $Y_{t}$.
    \begin{equation}
        Z(x,t) \rightarrow \psi(Y_{\tau},\tau)  .
    \end{equation}
    Finishing the proof.
\end{proof}

% maybe with the source

\begin{related}
    (\ref{lem:BM HE}) is a subcase of the Feynman-Kac formula.
    For a proof and a in depth discussion of the Feynman-Kac formula
    see \cite{oksendal_stochastic_2003}. \\
\end{related}


% \begin{theorem}[Feynman-Kac formula (wikipedia)] \label{thrm:feymankac}
%     Consider the partial differential equation
%     \begin{equation}
%         \frac{\partial u}{\partial t}(x, t)+\mu(x, t) \frac{\partial u}{\partial x}(x, t)+\frac{1}{2} \sigma^2(x, t) \frac{\partial^2 u}{\partial x^2}(x, t)-V(x, t) u(x, t)+f(x, t)=0,
%     \end{equation}
%     defined for all $x \in \mathbb{R}$ and $t \in[0, T]$, subject to the terminal condition
%     \begin{equation}
%         u(x, T)=\psi(x),
%     \end{equation}
%     where $\mu, \sigma, \psi, V, f$ are known functions, $T$ is a parameter, and $u: \mathbb{R} \times[0, T] \rightarrow \mathbb{R}$ is the unknown. Then the Feynman-Kac formula tells us that the solution can be written as a conditional expectation
%     \begin{equation}
%         u(x, t)=E^Q\left[\int_t^T e^{-\int_t^r V\left(X_\tau, \tau\right) d \tau} f\left(X_r, r\right) d r+e^{-\int_t^T V\left(X_\tau, \tau\right) d \tau} \psi\left(X_T\right) \mid X_t=x\right]
%     \end{equation}
%     under the probability measure $Q$ such that $X$ is an Itô process driven by the equation
%     \begin{equation}
%         d X_t=\mu(X, t) d t+\sigma(X, t) d W_t^Q
%     \end{equation}
%     with $W^Q(t)$ is a Wiener process (also called Brownian motion) under $Q$, and the initial condition for $X(t)$ is $X(t)=x$.
% \end{theorem}

\subsection{First Passage Sampling}
In this subsection we build up to sampling $(Y_{\tau},\tau)$
from (\ref{lem:BM HE}) efficiently and extend this to paths.

\begin{definition}[first passage time] \label{def:first passage time}
    Define the first passage time for a process $X_{t}$ for a set of valid states
    $V$ as
    \begin{equation}
        \text{FPt}(X_{t},S)=\inf \{t| (X_{t},t) \notin V \}
        .
    \end{equation}
    Note that the first passage time is a RV itself.
\end{definition}

\begin{definition}[first passage] \label{def:first passage}
    Define the first passage for a process $X_{t}$ for a set of valid states
    $V$ as
    \begin{equation}
        \text{FP}(X_{t},S)=(X_{\tau},\tau), \tau = \text{FPt}(X_{t},V)
        .
    \end{equation}
\end{definition}

\begin{theorem}
    The the density of first passages of Brownian motion for  exiting a  boundary is  the
    Dirichlet boundary green function for the heat equation.
\end{theorem}

\begin{proof}
    Follows from (\ref{lem:BM HE}).
\end{proof}

\begin{example}[Euler first passage sampling]
    In this example we approximately sample the first passage  of Brownian motion
    for a parabolic barrier by simulating Brownian motion with the Euler scheme. We plotted
    this on Figure \ref{fig:Euler first passage para}.

    \begin{figure}[ht!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/Euler first passage para.png}
        \caption{ $50$ realizations of Euler first passage sampling with step size $0.001$.}
        \label{fig:Euler first passage para}
    \end{figure}
\end{example}

\begin{lemma} \label{lem: FP order}
    When a process has more valid states the first passage time gets larger i.e.
    \begin{equation}
        V_{1} \subset V_{2} \Rightarrow
        \text{FPt}(X_{t}(\omega),V_{1}) \le  \text{FPt}(X_{t}(\omega),V_{2}) .
    \end{equation}
    The $\omega$ is to indicate we mean the same realization of $X_{t}$.
\end{lemma}


\begin{technique}[recursive first passage sampling]
    Recursive first passage sampling involves sampling an initial,
    simpler first passage that includes fewer valid states. Using
    this sampled first passage as a starting point, we
    then perform the same sampling process until the sampled
    first passage is almost invalid.
\end{technique}


\begin{example}[recursive first passage sampling] \label{ex:recursive first passage sampling}
    In this example we sample the first passage of Brownian motion from a parabolic barrier
    with recursive first passage sampling.
    For the simpler first passage sampler we scale and translate
    samples from a triangular barrier so its
    valid states are contained in the parabola generated
    by the Euler scheme. The precomputed samples are created
    by (\ref{py:euler FP sampling}) and used to produce first passages
    in (\ref{py:recu FP sampling}).

\end{example}

\begin{pythonn}[Euler first passage sampling] \label{py:euler FP sampling}
    \pythoncode{python code/sample_euler_triangle.py}
\end{pythonn}

\begin{pythonn}[recursive first passage sampling] \label{py:recu FP sampling}
    The maximum scaling of the triangular barrier that fits
    in the parabola is derived through (\ref{lem:self affine})
    and using the fact that a parabola domain is convex. To dampen barrier
    overstepping of (\ref{py:euler FP sampling}) we use a smaller scaling
    then the maximum. \\
    \pythoncode{python code/sample_recu_para.py}

    \begin{figure}[ht!]
        \centering
        \includegraphics[width=1\textwidth]{plots/recursive first passage para.png}
        \caption{ $50000$ of realizations of recursive first passage sampling produced
            by (\ref{py:recu FP sampling}). The precomputed sample of $5000$ first
            passages of a triangular barrier uses the Euler scheme with
            step size $0.001$.}
        \label{fig:recursive first passage para}
    \end{figure}
\end{pythonn}

\begin{related}[recursive first passage sampling]
    The original walk on spheres is a recursive first passage algorithm.
    Recursive first passage sampling gets discussed in \cite{herrmann_first-passage_2016}.
    % To add jumps you can use \cite{herrmann_exact_2021}.
    An alternative to resampling from an Euler scheme is to use tabulated
    inverse cumulative probability functions,
    as demonstrated in \cite{hwang_simulationtabulation_2001}.
\end{related}

% For recursive first passage sampling for high dimensional Brownian motion
% there symmetry trick to be pulled off


\begin{example}[recursive first passage average sampling]
    In example (\ref{ex:recursive first passage sampling}) it is possible to keep
    track of the average because scales and translates with our base first passage sampler.

    \begin{figure}[ht!]
        \centering
        \includegraphics[width=1\textwidth]{plots/recursive first passage average para.png}
        \caption{ $10000$ of realizations of recursive first passage sampling (for the average).
            The precomputed sample of $1000$ first passages and averages of a triangular barrier
            uses the Euler scheme with step size $0.001$.}
        \label{fig:recursive first passage average para}
    \end{figure}
\end{example}


\begin{technique}[Brownian motion path stitching]
    Instead of thinking in sampling first passages  you can also sample
    whole paths to the first passage. Similar to before we need to be
    able to generate paths for a simple first passage problem and "stich"
    these paths together. An advantage over normally generating paths
    is that a path can be represented by its subpaths and their scalings
    requiring less memory then a fully stored path. This can be useful
    in case you need to look back to a part of the path.
    The only downsides are that the time steps are inhomogeneous
    and storing paths for the simpler first passage problem.
\end{technique}

\begin{example}[path stitching parabola]
    This is the same as example (\ref{ex:recursive first passage sampling}) but now we have
    to keep track of the whole resampled Euler scheme generated paths.

    \begin{figure}[ht!]
        \centering
        \includegraphics[width=0.8\textwidth]{plots/path stitching para.png}
        \caption{ $10$ paths build with path stitching build out of
            precomputed Euler scheme generated paths with step size $0.01$.}
        \label{fig:path stitching para}
    \end{figure}
\end{example}

% For plotting the path we needed to accesses to all of its points.  

% A way around scaling base samples is limiting scaling to a
% discrete set and pick the biggest scaling that fits, instead
% of generating base samples for $1$ scale and scaling it dynamically
% precompute all the discrete scalings. \\


\begin{related}[path stitching]
    Path stitching appears frequently in rendering and also in \cite{das_sarma_fast_2015}
    and \cite{ji_reusing_2012}.
\end{related}

\subsection{Limitations and Future Work}
source term to (\ref{lem:BM HE}) different from Feynman kac

extending first passage averages sampling to geometric brownian motion
% Doing the same thing for geometric Brownian motion is difficult because the average
% behaves bad under transformation unlike the max. You can think of the average
% as an extra dimension to keep track of. What you would need  for geometric
% Brownian motion is the  first passage distribution of the average and exit
% point for every different position of the begin point for subpaths.\\
% And nothing holds you back of changing methods midway if you didn't
% the precompute a situation.
+ discrete scaling idea

recursive passage sampling in higher dimension

\newpage
\printbibliography
\newpage

% \section{Appendix}
% Derivation of the green functions and some expressions.
\end{document}
