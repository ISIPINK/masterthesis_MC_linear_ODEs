% This is my thesis, read it first and I will ask questions
% later also in comments. 

\documentclass[a4paper,12pt]{article}

\setlength{\textwidth}{15.0cm}
\setlength{\textheight}{24.0cm}
\setlength{\topmargin}{0cm}
\setlength{\headsep}{0cm}
\setlength{\headheight}{0cm}
\pagestyle{plain}


\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=blue,
    citecolor=blue,
    linktoc=page
}
\usepackage[dvips]{epsfig}
\usepackage{tikz}
\usepackage[english]{babel}
\usepackage{caption}
\captionsetup{font=it}
\usepackage[autostyle, english=american]{csquotes}


\usepackage[
backend=biber,
style=alphabetic,
]{biblatex}

\renewcommand{\bibfont}{\footnotesize}


\usepackage{amsmath,amssymb,amsthm}
\input{environments.tex}

\usepackage{comment}
\usepackage{listings}
\input{custom commands.tex}

\addbibresource{bibliography3.bib} 
\setlength{\parindent}{0pt}

\selectlanguage{English}
\begin{document}

\input{titelblad_MP.tex}

\newpage
\tableofcontents
\newpage

\begin{abstract}
  \input{english_abstract.tex}
\end{abstract}


\section{Introduction}

\subsection{Related Work}
The primary motivating paper for this work is the work
by \citeauthor{sawhney_grid-free_2022}
(\citeyear{sawhney_grid-free_2022}) \cite{sawhney_grid-free_2022},
which introduces the Walk on Spheres (WoS) method for solving second-order
elliptic PDEs with varying coefficients and Dirichlet boundary conditions.
Their techniques have shown high accuracy even in the presence of geometrically
complex boundary conditions. We were inspired to apply the underlying
mechanics of these Monte Carlo (MC) techniques to Inital Value Problems (IVPs) to explore
parallel in time and the possibility of extending their techniques
to other types of PDEs. \\

% A data map, which includes the literature for this thesis, 
% is available at \url{https://huggingface.co/spaces/ISIPINK/zotero_map}.\\

Existing randomized algorithms for solving IVPs generally rely on MC integration or randomizing parts
of deterministic algorithms. These are typically motivated by lower smoothness conditions where randomization
significantly enhances convergence speed, or solving ODEs where randomization aids in parallelization.
The most relevant literature in this context includes papers by
\citeauthor{daun_randomized_2011} and \citeauthor{ermakov_monte_2021}. \\


\citeauthor{daun_randomized_2011} \citeyear{daun_randomized_2011} \cite{daun_randomized_2011}
proposes a biased algorithm for nonlinear IVPs that has optimal Information-Based Complexity (IBC) for
some smoothness classes. Similar to \ref{ex:CV RRMC IVP}, their approach employs control variates. \\

\citeauthor{ermakov_monte_2021} \citeyear{ermakov_monte_2021} \cite{ermakov_monte_2021} proposes
an unbiased method for functionals of a Cauchy problem for large systems of linear ODEs. Their method, similar
to all our IVPs solvers, is based on Volterra integral equations.

\section{Background}

\subsection{Monte Carlo Integration}

In this subsection, we review basic MC theory. \\

\begin{notation}[Random Variables]
  Random variables (RVs) will be denoted with capital letters, e.g., $X$, $Y$ or $Z$.
\end{notation}


MC integration is any method that involves random sampling to
estimate an integral.
\begin{definition}[Uniform Monte Carlo Integration]
  We define uniform MC integration of
  $f:\mathbb{R} \rightarrow \mathbb{R}$
  over $[0,1]$ as
  an estimation of the expected value of $f(U)$, with
  $U \sim \text{Uniform}(0,1)$. A simple MC Integration
  scheme, can be summarized in the following formula:
  \begin{equation}\label{eq:BLUE}
    \int_{0}^1 f(s)ds \approx \frac{1}{n} \sum_{j=1}^{n}f(U_{j}),
  \end{equation}
  \juliacode{julia_code/uniform_MC.jl}
  where $n$ is the amount of samples used and $U_{j}$ i.i.d. $\text{Uniform}(0,1)$.
\end{definition}

Because estimators are random variables (RVs), the cost and error are also random
variables. In most cases, obtaining these RVs is difficult to impossible.
Directly comparing estimators based on these RVs can be challenging;
there is no Pareto front. Instead, comparisons can be made
using statistics. \\

Accuracy comparisons between estimators
are typically conducted with (root-)mean-square error (RMSE).
\begin{definition}[Root-Mean-Square Error]
  We define the Root-Mean-Square Error (RMSE) of an estimator $\tilde{\theta}$ for $\theta$  as follows:
  \begin{equation}
    \text{RMSE}(\tilde{\theta}) = \sqrt{E[||\tilde{\theta}-\theta||^{2}_{2}]}.
  \end{equation}
\end{definition}

Comparisons based on RMSE can be counterintuitive; consider Stein's paradox,
for example. We limit ourselves to simple cases such as $1$-dimensional
unbiased estimators, making MSE equivalent to variance.
Estimating variance is in most cases possible and can be used to calculate
confidence intervals using Chebyshev's inequality.\\

Average floating point operations or time per simulation are common cost statistics.
It may also be useful to consider \enquote*{at risk}  (analogous to \enquote*{value at risk})
in terms of memory or wall time.

If we limit ourselves to (\ref{eq:BLUE}) with a big sample size and
finite variance assumption on error and simulation time,
simulations can be computed in parallel, making them well-suited for a GPU implementation.
These assumptions are useful for establishing a baseline and
when they are close to being optimal, they become highly practical.
Given these assumption, there is a linear trade-off
between average simulation time and variance. This relationship can be quantified
using the following definition of MC efficiency.

\begin{definition}[Monte Carlo Efficiency]
  Define MC efficiency of an
  estimator $F$ as follows:
  \begin{equation}
    \epsilon[F]=\frac{1}{\text{Var}(F) T(F)},
  \end{equation}
  with $T$ the average simulation time.
\end{definition}

\begin{related}[Monte Carlo Efficiency]
  For further reference see \cite{veach_robust_1997} page 45.
\end{related}

For smooth $1$-dimensional integration, the linear trade-off between
variance and average simulation time is not close to optimal see
Theorem \ref{thrm:order trap}. \\
When it comes to comparing better trade-offs,
Information-Based Complexity (IBC) is often employed.
IBC primarily serves as a
qualitative measure and does not necessarily imply the
practicality of an algorithm. We will not delve into a
rigorous definition of IBC.

\begin{definition}[Information-Based Complexity]
  IBC is a way to describe asymptotically (for increasing accuracy/function calls)
  the trade-off between the average amount of function calls (information)
  needed and accuracy.
\end{definition}

Note that we consider the average amount of function calls as a measure of cost,
rather than the deterministic amount of function calls used. We implicitly assume that the variance of the amount
of function calls exists, which provides confidence intervals for the function calls through Chebyshev's inequality.


\begin{example}[IBC of (\ref{eq:BLUE})]
  In (\ref{eq:BLUE}) the function calls trades of
  linearly with variance. For $n$ function calls,
  the RMSE $= O\left(\frac{1}{\sqrt{n}}\right)$ or equivalently, if we want a
  RMSE of $\varepsilon$ we would need $O\left(\frac{1}{\varepsilon^{2}}\right)$
  function calls.
\end{example}


\subsection{Recursive Monte Carlo}
In this subsection, we introduce Recursive Monte Carlo (RMC)
with an example of an Initial Value Problem (IVP) and
Walk on Spheres.

\begin{notation}[$U,U_{j}$]
  We will frequently use the uniform distribution, so we will abbreviate it
  \begin{equation}
    U_{j}  \text{ i.i.d Uniform}(0,1).
  \end{equation}
  The subscripts are used to clarify independence
  between uniforms. However,
  when there is no risk of confusion,
  we simply use $U.$
\end{notation}

\begin{example}[$y'=y$]
  Consider following IVP:
  \begin{equation} \label{ydy}
    y_t = y, \quad y(0) = 1.
  \end{equation}
  By integrating both sides of (\ref{ydy}), we obtain:
  \begin{equation} \label{Integral ydy}
    y(t) = 1 + \int_{0}^{t} y(s) ds.
  \end{equation}
  (\ref{Integral ydy}) represents a recursive integral equation,
  specifically, a linear Volterra integral equation of the second type.

  By estimating the recursive integral in (\ref{Integral ydy})
  using MC, we derive the following estimator:
  \begin{equation}
    Y(t) = 1 + t  y(Ut).
  \end{equation}
  If $y$ is well-behaved, then $E[Y(t)] = y(t)$.
  However, we cannot directly simulate $Y(t)$ without access
  to $y(s)$ for $s < t$. Nevertheless, we can replace $y$ with
  an unbiased estimator without affecting $E[Y(t)] = y(t)$,
  by the law of total expectation ($E[X] = E[E[X|Z]]$).
  By replacing $y$ with $Y$ itself, we obtain a recursive
  expression for $Y$:
  \begin{equation} \label{recursive RV}
    y(t) \approx Y(t) = 1 + t  Y(Ut).
  \end{equation}

  \juliacode{julia_code/RMC_example.jl}

  (\ref{recursive RV}) is a Recursive Random Variable
  Equation (RRVE).

  Simulation of $Y$ with (\ref{recursive RV}),
  would recurse indefinitely (every $Y$ needs to sample another $Y$).
  To stop the recursion, approximate
  $Y(t) \approx 1$ near $t = 0$ introducing minimal bias.
  Later, we will discuss Russian roulette; see Definition \ref{Russian roulette},
  which can be used as an unbiased stopping mechanism.

\end{example}

\begin{definition}[Recursive Random Variable Equation (RRVE)]
  A Recursive Random Variable Equation (RRVE) is
  an equation that defines a
  family of random variables in terms of itself.
\end{definition}


\begin{example}[Walk on Spheres] \label{ex: walk on spheres}
  Classical Walk on Spheres estimates the solution of the Laplace equation:
  \begin{equation} \label{eq:laplace}
    \nabla^2 u = 0, \quad u|_{\partial \Omega} = g,
  \end{equation}
  in a point by applying RMC to the mean value property of the Laplace equation:
  \begin{equation}\label{eq:mean value}
    u(x) = \frac{1}{\text{Vol}(\partial B(x))} \int_{\partial B(x)} u(y) dy,
  \end{equation}
  with $B(x) \subseteq \Omega$ a ball around $x$ chosen sufficiently big.
  Obtaining following estimator:
  \begin{equation}
    u(x) \approx Y(x) = Y(U(\partial B(x)))
    .
  \end{equation}
  Recursion is terminated by approximating $Y(x)$ with the boundary condition $g$
  near the boundary.
\end{example}

\begin{related}[Walk on Spheres]
  For further reference see \cite{sawhney_monte_nodate}.
\end{related}


\subsection{Modifying Monte Carlo}

In this subsection, we discuss techniques for modifying RRVEs
in a way that preserves the expected value of the estimator while
acquiring more desirable properties. These techniques are only
effective when applied by using prior information
about the problem or computational costs. \\

We will frequently interchange RVs with the same expected values.
Therefore introducing following notation:
\begin{notation}[$\cong$]
  \[
    X \cong Y \iff E[X]=E[Y]
    .\]
\end{notation}

Russian roulette is a MC technique commonly employed in rendering algorithms.
The concept behind Russian roulette is to replace an RV with a
less computationally expensive approximation sometimes.

\begin{definition}[Russian roulette] \label{Russian roulette}
  We define Russian roulette on $X$ with free parameters
  $Y_{1} \cong Y_{2}$, $p \in [0,1]$
  and $U$ independent of $Y_{1}$, $Y_{2}$, $X$
  as follows:
  \begin{equation}
    X \cong
    \begin{cases}
      \frac{1}{p}(X - (1-p)Y_{1}) & \text{ if } U < p \\
      Y_{2}                       & \text{ else }
    \end{cases}.
  \end{equation}
\end{definition}


\begin{notation}[$B(p)$]
  Often Russian roulette will be used with $Y_{1}= Y_{2}= 0$.
  In that case, we use Bernoulli variables to shorten notation.
  \begin{equation}
    B(p) \sim \text{Bernoulli}(p) =
    \begin{cases}
      1 & \text{ if } U<p \\
      0 & \text{ else }
    \end{cases} .
  \end{equation}
\end{notation}

\begin{example}[Russian roulette] \label{ex:simple russian roulette}
  Consider the estimation of $E[Z]$, with $Z$:
  \begin{equation} \label{eq:simple russian roulette}
    Z = U + \frac{f(U)}{1000}.
  \end{equation}
  Here, let $f:\mathbb{R} \rightarrow [0,1]$ be $100$ times more expensive to compute then sampling $U$.
  $f(U)$ contributes relatively little to the variance compared to $U$. To address this, we Russian roulette $f(U)$:
  \begin{equation}
    Z \cong U + B\left(\frac{1}{100}\right)\frac{f(U)}{10}.
  \end{equation}
  This modification requires calling $f$ on
  average once every $100$ samples. This significantly reduces the
  computational burden while increasing the variance slightly thereby increasing
  the overall MC efficiency.\\
\end{example}



\begin{example}[Russian roulette on (\ref{recursive RV})] \label{ex: russian roulette}
  To address the issue of indefinite recursion in
  (\ref{recursive RV}), Russian roulette can be employed
  by approximating the value of $Y$ near $t = 0$ with $1$
  sometimes. Specifically, we replace the coefficient $t$
  in front of the recursive term with $B(t)$ when $t < 1$.
  The modified recursive expression for $Y(t)$ for $t<1$ becomes:

  \begin{equation}\label{eq:rr example}
    y(t) \cong Y(t) = 1 + B(t)Y(Ut)
  \end{equation}
  \juliacode{julia_code/RR_example.jl}

  Interestingly, $\forall t \le 1:Y(t)$ is the number of recursion calls
  to sample $Y(t)$ such that the average number of recursion
  calls to sample $Y(t)$ equals $e^{t}$.

\end{example}

Splitting is a technique that increases samples of important terms, similar to how Russian roulette
decreases the samples of unimportant terms.

\begin{definition}[Splitting] \label{def:splitting}
  Splitting $X$ refers to utilizing multiple $X_{j} \cong X$ (not necessarily independent) to
  reduce variance by taking their average:
  \begin{equation}
    X \cong \frac{1}{n} \sum_{j=1}^{n} X_{j}.
  \end{equation}
\end{definition}

\begin{example}[Splitting on (\ref{eq:simple russian roulette})] \label{ex:simple splitting}
  Consider Example \ref{ex:simple russian roulette} again.
  Instead of using Russian roulette on $f(U)$, we split $U$:
  \begin{equation}
    Z \cong \frac{\sum_{j=1}^{10} U_j}{10} + f(U_{1}).
  \end{equation}
  This modification requires sampling $U,$
  $10$ times as often which is insignificant compared to evaluating $f(U)$ once
  but reduces the variance significantly thereby increasing the overall MC efficiency.\\
\end{example}

\begin{related}[Examples \ref{ex:simple russian roulette}, \ref{ex:simple splitting}]
  In Example \ref{ex:simple russian roulette} and Example \ref{ex:simple splitting},
  it is also possible to estimate the expectations of the $2$ terms
  of $Z$ separately. Given the variances and computational costs
  of both terms, you can calculate the asymptotically optimal division
  of samples for each term. However, this is no longer the case with RMC.
  In \cite{rath_ears_2022}, a method is presented to estimate the optimal
  Russian roulette/splitting factors for rendering.
\end{related}

Splitting the recursive term in an RRVE can result in additive branching recursion,
necessitating cautious management of terminating the branches promptly to prevent
exponential growth in computational complexity. To accomplish this, termination
strategies that have been previously discussed can be employed. Subsequently,
we will explore the utilization of coupled recursion as a technique to mitigate
additive branching recursion in RRVEs (see Example \ref{ex:coupled splitting}).

\begin{example}[Splitting on (\ref{eq:rr example})] \label{ex:splitting}
  We can split the recursive term of (\ref{eq:rr example})
  into two parts as follows:
  \begin{equation}\label{eq:splitting}
    y(t) \cong Y(t) =1 + \frac{B(t)}{2}(Y_{1}(U_{1}t) + Y_{2}(U_{1}t))
  \end{equation}

  \juliacode{julia_code/split_example1.jl}

  \begin{equation}\label{eq:splitting2}
    y(t) \cong Y(t) =1 + \frac{B(t)}{2}(Y_{1}(U_{1}t) + Y_{2}(U_{2}t))
  \end{equation}

  \juliacode{julia_code/split_example2.jl}

  where $Y_{1}(t)$ and $Y_{2}(t)$ are i.i.d. with $Y(t)$.
\end{example}

\begin{definition}[Control variates] \label{CV}
  Define control variating $f(U)$ with $\tilde{f}$ an approximation of $f$ as:
  \begin{align}
    f(U) & \cong f(U_{1})-\tilde{f}(U_{1}) + E[\tilde{f}(U)] \\
         & = (f-\tilde{f})(U_{1}) + E[\tilde{f}(U)]
    .
  \end{align}
  Note that control variating requires the evaluation of
  $E[\tilde{f}(U)]$.  When this is estimated instead, we refer to it as $2$-level MC
  and recursively applying $2$-level is multilevel MC.
\end{definition}


\begin{example}[Control variate on (\ref{recursive RV})] \label{ex:CV}
  To create a control variate for (\ref{recursive RV}) that
  effectively reduces variance, we employ the approximation
  $y(t) \approx \tilde{y} =1+t$ and define the modified recursive term as follows:
  \begin{align}
    y(t) \cong Y(t) & = 1 + t(Y(U_{1}t) - \tilde{y}(U_{1}t) + E[\tilde{y}(Ut)])     \\
                    & = 1 + t \left( E[1 + Ut]  \right) + t(Y(U_{1}t) - 1 - U_{1}t) \\
                    & = 1 + t + \frac{t^2}{2} + t(Y(U_{1}t) - 1 - U_{1}t).
  \end{align}

  \juliacode{julia_code/CV_example.jl}

  Note that while we could cancel out the constant term
  of the control variate, doing so would have a negative impact
  on the Russian roulette implemented.
\end{example}

\begin{related}[MC modification]
  For further reference on Russian roulette, splitting and control variates
  see \cite{veach_robust_1997}.
\end{related}

\subsection{Monte Carlo Trapezoidal Rule}

In this subsection, we introduce a MC trapezoidal rule that
exhibits similar convergence behavior to the methods discussed later.
The MC trapezoidal rule is essentially a regular Monte Carlo method
enhanced with control variates based on the trapezoidal rule.

\begin{definition}[MC trapezoidal rule]
  We define the MC trapezoidal rule for approximating the integral
  of function $f$ over the interval $[x, x+\Delta x]$ with a Russian roulette rate
  $l$ and $\tilde{f}$ represents the linear approximation of $f$ corresponding
  to the trapezoidal rule as follows:
  \begin{align}
     & \int_{x}^{x+\Delta x} f(s) ds                           \\
     & = \int_{x}^{x+\Delta x}  \tilde{f}(s) ds +
    \int_{x}^{x+\Delta x}  f(s) - \tilde{f}(s) ds              \\
     & = \Delta x \frac{f(x) + f(x+\Delta x)}{2}
    + E \left[f(S) - \tilde{f}(S)\right]                       \\
     & \cong \Delta x \frac{f(x) + f(x+\Delta x)}{2} \nonumber \\
     & + \Delta x l B\left( \frac{1}{l}\right)
    \left(f(S) - f(x) - \frac{S - x}{\Delta x}
    \left(f(x+\Delta x) - f(x)\right) \right), \label{eq:MCtrap}
  \end{align}
  where $S \sim \text{Uniform}(x,x+\Delta x)$.
\end{definition}

\begin{lemma}[RMSE MC Trapezoidal Rule] \label{lem:rmse mctrap}
  The MC trapezoidal rule
  for a twice differentiable function has
  \begin{equation}
    \text{RMSE} =O\left( \Delta x^{3} \right) .
  \end{equation}
\end{lemma}

\begin{proof}
  Start from (\ref{eq:MCtrap}). The MSE is the variance
  so we can ignore addition by constants.
  \begin{equation}
    \text{MSE} = \text{Var}\left( \Delta x l B\left( \frac{1}{l}\right)
    \left(f(S) - f(x) - \frac{S - x}{\Delta x}
    \left(f(x+\Delta x) - f(x)\right) \right)\right)
  \end{equation}
  We substitute $S = \Delta x U + x$ and apply Taylor's theorem
  finishing the proof:
  \begin{align}
    \text{MSE} & = \text{Var}\left( \Delta x l B\left( \frac{1}{l}\right)
    \left(f(\Delta x U+x) - f(x) - U
    \left(f(x+\Delta x) - f(x)\right) \right)\right)                           \\
               & = \text{Var}\left( \Delta x l B\left( \frac{1}{l}\right)
    \left( U \Delta x f'(x)+ \frac{U^{2} \Delta x ^{2}}{2} f''(Z_{1})
    - U \left( \Delta x f'(x) +
    \Delta x ^{2} f''(z_{2})\right) \right)\right)                             \\
               & = \text{Var}\left( \Delta x l B\left( \frac{1}{l}\right)
    \left( \frac{U^{2} \Delta x ^{2}}{2} f''(Z_{1})
    -  \frac{U\Delta x ^{2}}{2} f''(z_{2}) \right)\right)                      \\
               & =\Delta x ^{6} \text{Var}\left(  l B\left( \frac{1}{l}\right)
    \left( \frac{U^{2} }{2} f''(Z_{1})
    -  \frac{U}{2} f''(z_{2}) \right)\right),
  \end{align}
  for some $Z_{1} \in [x,S], z_{2} \in [x,x+\Delta x]$. The variance term is bounded
  because the variance of a bounded RV is bounded.
  Note that the proof does not rely on Russian roulette ($l=1$).
\end{proof}

\begin{related}[proof of Lemma \ref{lem:rmse mctrap}]
  A more generalizable proof for other types of control variates can
  be constructed by applying the \enquote*{separation of the main part} technique,
  as shown in Lemma 4 of \cite{heinrich_monte_1993}.
\end{related}


\begin{definition}[Composite (MC) trapezoidal rule] \label{MCtrap}
  Define the MC trapezoidal rule for approximating the integral
  of function $f$ over the interval $[0, 1]$ with a uniform grid
  with $n$ intervals as follows:
  \begin{equation}
    \int_{0}^{1} f(s) ds \approx \Delta x \sum_{j=0}^{n-1}  \frac{f(x_{j}) + f(x_{j}+\Delta x)}{2} .
  \end{equation}

  \juliacode{julia_code/composite_trapezoidal.jl}

  Define the  corresponding composite MC trapezoidal
  with a Russian roulette rate $l$ as follows:
  \begin{align} \label{eq:cMCtrap}
    \int_{0}^{1} f(s) ds \cong \Delta x \sum_{j=0}^{n-1} & \frac{f(x_{j}) + f(x_{j}+\Delta x)}{2} \nonumber \\
                                                         & + l B\left(\frac{1}{l}\right)
    \left(f(S_j) - f(x_{j}) - \frac{S_j - x_{j}}{\Delta x}(f(x_{j}+\Delta x) - f(x_{j}))\right),
  \end{align}

  \juliacode{julia_code/MC_composite_trapezoidal.jl}

  where $S_j \sim \text{Uniform}(x,x+\Delta x)$.

\end{definition}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{julia_plots/trap_example.pdf}
  \caption{Log-log plot of the error of (\ref{eq:cMCtrap}) for
  $\int_{0}^{1}e^{s}ds$ with $l=100$. At floating point accuracy,
  the convergence ceases.
  }
  \label{fig:MCtrap}
\end{figure}

Figure \ref{fig:MCtrap} suggests that the order of convergence of RMSE of the
composite MC trapezoidal rule is better by $0.5$ than the normal composite trapezoidal rule.
The MC trapezoidal rule has on average $\frac{1}{l}$ more function calls than
the normal trapezoidal rule. For the composite rule with $n$ intervals,
there are $\text{Binomial}(n,\frac{1}{l})$ additional function calls
(repeated Bernoulli experiments).\\

\begin{theorem}[RMSE Composite Trapezoidal MC Rule] \label{thrm:order trap}
  The composite trapezoidal MC rule  with $n$ intervals
  for a twice differentiable function has
  \begin{equation}
    \text{RMSE} =O\left(\frac{1}{n^{2.5}} \right) .
  \end{equation}
\end{theorem}

The proof uses Lemma \ref{lem:rmse mctrap},
and is similar to the proof of the normal
trapezoidal rule. The main difference is the
accumulation of \enquote*{local truncation} errors into \enquote*{global truncation} error.
Normally there is a loss of one order but the MC trapezoidal loses only a half order
because the accumulation happens in variance instead of bias.
\begin{align}
  \sqrt{\text{Var}\left(\sum_{j=1}^{n}  \Delta x^{3}U_{j}^{2}\right)}
   & = \Delta x^{3} \sqrt{ \sum_{j=1}^{n}\text{Var} (U_{j}^{2})} \\
   & = \Delta x^{3} \sqrt{ n \text{Var}(U^{2})}                  \\
   & = O( \Delta x^{2.5}).
\end{align}
Note that the meaning of a bound on the error, which behaves as $O(\Delta x^{2})$,
and a bound on the RMSE, also behaving as $O(\Delta x^{2})$, is different.
A bound on the error implies a bound on the RMSE, but not vice versa.

\begin{related}[Monte Carlo Trapezoidal Rule]
  Due to an argument like Stein's paradox,
  it is always possible to bias the composite MC trapezoidal
  rule to achieve lower RMSE.
  The optimal IBC for the deterministic, random, and quantum integration are known
  for some smoothness classes; see \cite{heinrich_optimal_2001} for details.
\end{related}


\subsection{Unbiased Non-Linearity}

In this subsection, we present techniques for handling polynomial non-linearity.
The main idea behind this is using independent samples
$y^{2} \cong Y_{1} Y_{2}$ with $Y_{1}$ independent of $ Y_{2}$ and
$Y_{1} \cong Y_{2} \cong y$.


\begin{example}[$y_t=y^{2}$] \label{ex:nonlinear example}
  Consider the following ODE:
  \begin{equation} \label{eq:nonlinear example}
    y_t = y^2, \quad y(1) = -1.
  \end{equation}
  The solution to this equation is given by $y(t) = -\frac{1}{t}$.
  By integrating both sides of (\ref{eq:nonlinear example}),
  we obtain the following integral equation:
  \begin{equation}
    y(t) = -1 + \int_{1}^{t} y(s) y(s)ds.
  \end{equation}
  To estimate the recursive integral in (\ref{eq:nonlinear example}),
  we use  $Y_1,Y_2 \text{ i.i.d. } Y$ in following RRVE:
  \begin{equation} \label{RRVE: nonlinear example}
    y(t) \cong Y(t) = -1 + (t-1) Y_1(S_{1}) Y_2(S_{1}),
  \end{equation}

  \juliacode{julia_code/nonlinear_example.jl}

  where $S_{1} \sim \text{Uniform}(1,t)$.
\end{example}

\begin{example}[$e^{E[X]}$] \label{ex:exp int}
  $e^{\int x(s)ds}$ is a common expression encountered when studying ODEs.
  In this example, we demonstrate how you can generate unbiased estimates of
  $e^{E[X]}$ with simulations of $X$. The Taylor series of $e^{x}$ is:
  \begin{align}
    e^{E[X]} & = \sum_{n=0}^{\infty} \frac{E^{n}[X]}{n!}     \\
             & = 1 + \frac{1}{1}E[X]\left(1+ \frac{1}{2}E[X]
    \left(1+\frac{1}{3}E[X]\left(1+ ...\right)\right)\right). \label{taylor e}
  \end{align}
  Change the fractions of (\ref{taylor e}) to Bernoulli processes
  and replace all $X$ with independent $X_j \cong X$.
  \begin{align}
    e^{E[X]} & = E
    \left[1 + B\left(\frac{1}{1}\right)E[X_1]
    \left(1+ B\left(\frac{1}{2}\right)E[X_2]
    \left(1+B\left(\frac{1}{3}\right)E[X_3]
    \left(1+ ...\right)
    \right)
    \right)
    \right]                             \\
             & \cong \label{eq:exp int}
    1 + B\left(\frac{1}{1}\right)X_1
    \left(1+ B\left(\frac{1}{2}\right)X_2
    \left(1+B\left(\frac{1}{3}\right)X_3
      \left(1+ ...\right)
      \right)
    \right).
  \end{align}
  \juliacode{julia_code/expX.jl}
  Sampling (\ref{eq:exp int}) requires a finite amount of samples from $X_{j}$'s
  with probability $1$.
\end{example}

\begin{related}[Example \ref{ex:exp int}]
  NVIDIA has a great paper on optimizing Example \ref{ex:exp int}
  \cite{kettunen_unbiased_2021}.
\end{related}

\subsection{Recursion}

In this subsection, we discuss recursion-related techniques.

\begin{technique}[Coupled recursion]
  The idea behind coupled recursion is sharing recursion calls of
  multiple RRVEs for simulation. This does make them dependent.
\end{technique}

\begin{example}[Coupled recursion] \label{ex:coupled recursion}
  Consider calculating the
  sensitivity of following ODE to a
  parameter $a$:
  \begin{align}
    y_t             & =ay,y(0)=1 \Rightarrow \label{couple recu ex1} \\
    \partial_{a}y_t & = y + a \partial_{a}y \label{couple recu ex2}
  \end{align}
  Turn (\ref{couple recu ex1}) and (\ref{couple recu ex2}) into RRVEs.
  To emphasize that they are coupled and should
  recurse together we write them in a matrix equation:
  \begin{equation} \label{coupled mat}
    \begin{bmatrix}
      y(t) \\
      \partial_{a}y(t)
    \end{bmatrix} \cong
    \begin{bmatrix}
      Y(t) \\
      \partial_{a}Y(t)
    \end{bmatrix}=
    X(t)=
    \begin{bmatrix}
      1 \\
      0
    \end{bmatrix}+
    t \begin{bmatrix}
      a & 0 \\
      1 & a
    \end{bmatrix}
    X(Ut).
  \end{equation}

  \juliacode{julia_code/coupled_recursion.jl}

  Observe how this eliminates the additive branching recursion
  present in (\ref{couple recu ex2}).

\end{example}


\begin{technique}[Recursion in recursion]\label{tech:recu in recu}
  Later we will use recursion in recursion.
  Recursion in recursion is like proving an induction
  step of an induction proof with induction.
\end{technique}

\begin{related}[Recursion in recursion]
  A beautiful example of recursion in recursion is
  the next flight variant of Walk on Spheres in
  \cite{sawhney_grid-free_2022}.
\end{related}

Most programming languages do support recursion, but it often comes with certain
limitations such as maximum recursion depth and potential performance issues.
Non-branching recursion can be avoided by directly traversing the computational path in the
reverse order. Poisson time processes can be sampled in the reverse order
because of equal forward paths and backward paths distributions.

\begin{definition}[Main Poisson] \label{def:main poisson}
  Consider the following linear IVP with $\forall s>0 \in \mathbb{R}: f(s) \in \mathbb{R}^{n}, A(s) \in \mathbb{R}^{n \times n}$:
  \begin{align}
    y_t                              & = A(t) y + f(t) \Leftrightarrow                                                                       \\
    y_t + \sigma y                   & = (A(t) + \sigma I) y + f(t) \Leftrightarrow                                                          \\
    e^{-\sigma t} ( e^{\sigma t}y)_t & = (A(t) + \sigma I) y + f(t)  \Leftrightarrow                                                         \\
    y(t)                             & = e^{-\sigma t} y(0) + \int_{0}^{t} e^{(s-t) \sigma} \left(  (A(s) + \sigma I ) y(s) +f(s)\right) ds.
  \end{align}

  With $\sigma>0 \in \mathbb{R}$ . Do following substitution: $e^{(s-t)\sigma} = \tau$ equivalent to importance sampling
  the exponential term:
  \begin{equation} \label{eq:poisson main}
    y(t) = \int_{0}^{e^{-\sigma t}}  y(0) d\tau + \int_{e^{-\sigma t}}^{1} \left(  \frac{A(s)}{\sigma} + I\right)  y(s) + \frac{f(s)}{\sigma} d\tau
    .
  \end{equation}
  Sampling $\tau$ uniformly is equivalent to sampling the next event in a Poisson process,
  which produces an unbiased estimator of the solution to the linear IVP.
\end{definition}

\begin{julia}[Implementation of \ref{def:main poisson}] \label{jl:main poisson}
  (\ref{eq:poisson main}) can be turned into a RRVE by sampling $\tau \sim U$, no Russian roulette is needed for
  termination because sampling the first integral ends recursion. No recursion is used
  for the implementation as we can sample the Poisson process in the reverse order.

  \juliacode{julia_code/main_poisson.jl}

  Figure \ref{fig:main poisson error} and Figure \ref{fig:main poisson convergence} demonstrate the convergence
  behavior of the estimator. The estimated convergence of RMSE is $O(\sigma^{-0.5} nsim^{-0.5})$, the amount of
  time steps is simply $\sim$ Poisson($\sigma t$). Note that unlike MC integration the cost of a simulation is not
  a bounded, resulting in increased wall clock time at risk as $nsim$ grows for parallel simulations.

\end{julia}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{julia_plots/main_poisson_error.pdf}
  \caption{
    Intermediate points of $5$ realizations of the error ($Y(t)-y(t)$) of \ref{jl:main poisson} for (\ref{couple recu ex1}) and (\ref{couple recu ex2}) with $a=1, \sigma = \{10,1000\}$.
    Regression over the realizations and time is done with ordinary least square onto
    a second degree polynomial. The uniform qqplot of the time realizations indicate that the time realizations
    are uniformly distributed.
  }
  \label{fig:main poisson error}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{julia_plots/main_poisson_convergence.pdf}
  \caption{Realizations of norm of the error at $t=1$ of \ref{jl:main poisson} for (\ref{couple recu ex1}) and (\ref{couple recu ex2}) with $a=1$,
    $nsim =1$ and $\sigma$ variable or $nsim$ variable and $\sigma = 1$ . $nsim$ denoting the number of simulations
    when splitting the whole estimator.}
  \label{fig:main poisson convergence}
\end{figure}

\begin{related}[Main Poisson]
  \cite{acebron_monte_2016} derives a similar estimator for solving
  $1$-dimensional telegraph equations.
  % Unlike \ref{jl:point estimator heat} the recursion process they use can be reversed
  % because the paths consist of a Poisson process and reflections.
\end{related}

Tail recursion is commonly used in rendering to implement non-branching recursion.

\begin{technique}[Non-branching tail recursion]
  Tail recursion involves reordering all operations
  so that almost no operation needs to happen after
  the recursion call. This allows us to return the
  answer without retracing all steps when we reach
  the last recursion call.
\end{technique}

The non-branching recursion presented in the RRVEs can
be implemented using tail recursion due to the associativity
of all operations ($(xy)z = x(yz)$) involved.

\begin{julia}[Tail recursion for Example \ref{def:main poisson}]
  We collect the sum in the variable sol and the matrix multiplications in W.
  Notice that the computation is going backwards in time.

  \juliacode{julia_code/tail_poisson.jl}
\end{julia}

Tail recursion loses the intermediate values
of the recursive calls and
may increase computational costs because of the reordering of operations.
The computational cost of matrix multiplications are sensitive
to reordering operations.

\begin{related}[Non-branching tail recursion]
  % Example \ref{ex:coupled recursion} is inspired by \cite{vicini_path_2021}.
  \cite{vicini_path_2021} proposes an efficient unbiased backpropagation
  algorithm for rendering exploiting properties of non-branching tail recursion
  by inverting local Jacobian matrices which is only feasible for small matrices.
  To access intermediate values in tail recursion they use path replay.
\end{related}


The expensive matrix multiplications disappear when solving for $v^{T}y(t)$.

\begin{julia}[Adjoint tail recursion for Example \ref{def:main poisson}] \label{jl:adjoint main poisson}
  We collect the sum in the variable sol and instead of matrix multiplications in W
  matrix-vector multiplications in $v$.

  \juliacode{julia_code/adjoint_poisson.jl}

  We are interested in methods that can keep $v$ sparse.
  When $(v)_{j} = \delta_{jn}$ we obtain an estimator for $(y(t))_{n}$.
\end{julia}

\begin{related}[Adjoint tail recursion]
  \cite{ermakov_monte_2021}  also proposes an unbiased method for functionals of linear IVPs.
\end{related}

\section{Ordinary Differential Equations}

\subsection{Green's Functions}
\label{sec:greens functions}

In this subsection, we discuss how to transform ODEs into integral equations using Green's functions and
subsequently solve them. \\

A Green's function is a type of kernel function used
for solving linear problems with linear conditions. In this context,
Green's functions are analogous to homogeneous and particular solutions
to a specific problem, which are combined through integration to solve
more general problems.

\begin{related}[Green's function]
  Our notion of the Green's function is similar to that presented
  in \cite{hwang_simulationtabulation_2001}.
\end{related}


\begin{notation}[$H$]
  We denote the Heaviside step function with:
  \begin{equation}
    H(x) = \begin{cases}
      0 & \text{ if } x<0 \\
      1 & \text{ else }
    \end{cases}.
  \end{equation}
\end{notation}

\begin{notation}[$\delta$]
  We denote the Dirac delta function as $\delta(x)$.
\end{notation}


To clarify Green's functions, let us look at the following example.

\begin{example}[$y_t=y$ average condition]
  Consider equation:
  \begin{equation} \label{ydy int}
    y_t = y,
  \end{equation}
  with following condition making the solution unique:
  \begin{equation}
    \int_{0}^{1} y(s) ds = e-1.
  \end{equation}
  The solution to this equation remains the same: $y(t) = e^{t}$.
  We define the corresponding source Green's function $G(t,x)$ for $y_t$
  and this type of condition as follows:
  \begin{equation}
    G_t = \delta(x-t), \quad \int_{0}^{1} G(s,x) ds = 0.
  \end{equation}
  Solving this equation yields:
  \begin{equation}
    G(t,x) = H(t-x) + x - 1.
  \end{equation}
  We define the corresponding boundary Green's function $G(t,x)$ for $y_t$
  and this type of condition as follows:
  \begin{equation}
    P_{t} = 0, \quad \int_{0}^{1} P(s) ds = e -1.
  \end{equation}
  Solving this equation yields:
  \begin{equation}
    P(t) = e -1.
  \end{equation}
  The Green's functions are constructed
  to form the following integral equation
  for (\ref{ydy int}):
  \begin{equation} \label{int ydy int}
    y(t) = P(t) + \int_{0}^{1} G(t,s) y(s) ds.
  \end{equation}
  Converting (\ref{int ydy int}) into an RRVE
  using RMC, we obtain:
  \begin{equation}\label{RRVE ydy int}
    y(t) \cong Y(t) = e - 1 + 2B\left(\frac{1}{2}\right)Y(S)(H(t-S)+S-1),
  \end{equation}
  where $S \sim U$. We plot realizations of
  (\ref{RRVE ydy int}) in Figure \ref{fig:ydy int}.

  \begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plots/ydy_int.png}
    \caption{Recursive calls $(t,Y(t))$ of (\ref{RRVE ydy int}) when
      calling $Y(0.5)$ $300$ times. Points accumulate on
      the Green's line due to the Russian roulette,
      and at  $t=0.5$ because of the first recursion call.
    }
    \label{fig:ydy int}
  \end{figure}

\end{example}

(\ref{int ydy int}) is a Fredholm integral
equation of the second kind.

\begin{definition}[Fredholm equation of the second kind]
  A Fredholm equation of the second kind for $\varphi$  is of the following form:
  \begin{equation}
    \varphi(t)=f(t)+\lambda \int_a^b K(t, s) \varphi(s) ds.
  \end{equation}
  Here, $K(t, s)$ represents a kernel, and $f(t)$ is a given function.
\end{definition}

If both $K$ and $f$ satisfy certain regularity conditions, then for sufficiently
small $\lambda$, it is relatively straightforward to establish the existence
and uniqueness of solutions using a fixed-point argument.

\begin{example}[Dirichlet $y_{tt}=y$] \label{main dirichlet}
  Consider following BVP:
  \begin{equation} \label{eq:main dirichlet}
    y_{tt}=y.
  \end{equation}
  With boundary conditions $y(b_{0}),y(b_{1})$. The Green's functions corresponding to $y_{tt}$ and Dirichlet conditions are:
  \begin{align}
    P(t|x) & = \begin{cases}
                 \frac{b_{1}-t}{b_{1}-b_{0}} & \text{if } x = b_{0} \\
                 \frac{t-b_{0}}{b_{1}-b_{0}} & \text{if } x = b_{1}
               \end{cases},       \\
    G(t,s) & = \begin{cases}
                 -\frac{(b_{1}-t)(s-b_{0})}{b_{1}-b_{0}} & \text{if } s<t \\
                 -\frac{(b_{1}-s)(t-b_{0})}{b_{1}-b_{0}} & \text{if } t<s
               \end{cases}.
  \end{align}
  Directly from these Green's functions, we obtain the following integral equation and RRVE:
  \begin{align} \label{inteq:main dirichlet}
    y(t) & = P(t|b_{0}) y(b_{0}) + P(t|b_{1}) y(b_{1}) +
    \int_{b_{0}}^{b_{1}} G(t,s)y(s) ds,                  \\
    Y(t) & = P(t|b_{0}) y(b_{0}) + P(t|b_{1}) y(b_{1})
    + l B\left(\frac{1}{l} \right)(b_{1}-b_{0}) G(t,S)y(S) , \label{RRVE:main dirichlet}
  \end{align}
  with the Russian roulette rate $l \in \mathbb{R}$  and
  $S \sim \text{Uniform}(b_{0},b_{1})$. In Figure \ref{fig:plots/main_dirichlet_viz.png} and \ref{fig:mainD explosion}
  we test convergence of (\ref{RRVE:main dirichlet}).
\end{example}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{plots/main_dirichlet_viz.png}
  \caption{Recursive calls $(t,Y(t))$ of (\ref{RRVE:main dirichlet}) when
  calling $Y(0)$ $75$ times, with $l=1.2$ and boundary conditions
  $y(-k)=e^{-k}$ and $y(k)=e^{k}$.
  }
  \label{fig:plots/main_dirichlet_viz.png}
\end{figure}


\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{plots/main_dirichlet_convergence.png}
  \caption{The logarithmic percentage error of $Y(0)$ for
  (\ref{RRVE:main dirichlet}), with $l=1.2$ and boundary conditions
  $y(-k)=e^{-k}$ and $y(k)=e^{k}$, displays an exponential
  increase until approximately $k=1.5$, beyond which additional
  simulations fail to reduce the error, indicating that the variance
  does not exist.}
  \label{fig:mainD explosion}
\end{figure}




We tested coupled splitting on Example \ref{main dirichlet}.
Coupled splitting removes the additive branching of splitting by coupling (reusing)
samples.

\begin{example}[Coupled splitting on Example \ref{main dirichlet}] \label{ex:coupled splitting}
  In addition to normal splitting (see definition \ref{def:splitting}),
  we can also split the domain in (\ref{inteq:main dirichlet})
  as follows:
  \begin{align}\label{inteq:coupled splitting}
    y(t_1) & = P(t_1|b_{0}) y(b_{0}) + P(t_1|b_{1}) y(b_{1})                \\
           & + \int_{b_{0}}^{\frac{b_{0}+b_{1}}{2}} G(t_1,s_1)y(s_1) ds_1 +
    \int_{\frac{b_{0}+b_{1}}{2}}^{b_{1}} G(t_1,s_2)y(s_2) ds_2              \\ \label{inteq:coupled domain splitting}
    y(t_2) & = P(t_2|b_{0}) y(b_{0}) + P(t_2|b_{1}) y(b_{1})                \\
           & + \int_{b_{0}}^{\frac{b_{0}+b_{1}}{2}} G(t_2,s_1)y(s_1) ds_1
    +\int_{\frac{b_{0}+b_{1}}{2}}^{b_{1}} G(t_2,s_2)y(s_2) ds_2.
  \end{align}
  By coupling, we can eliminate the additive branching recursion
  in the RRVEs corresponding to (\ref{inteq:coupled splitting})
  and (\ref{inteq:coupled domain splitting}). In other words,
  to estimate $y(t_1)$ and $y(t_2)$ we need to estimate $y(s_1)$ and $y(s_2)$
  instead of doing it twice we reuse the same estimate.

  This results in the following RRVE:
  \begin{equation} \label{RRVE:coupled splitting}
    X(t_{1},t_{2})=
    \begin{bmatrix}
      P(t_{1}|b_{0}) & P(t_{1}|b_{1}) \\
      P(t_{2}|b_{0}) & P(t_{2}|b_{1})
    \end{bmatrix}
    \begin{bmatrix}
      y(b_{0}) \\
      y(b_{1})
    \end{bmatrix}
    +
    \frac{b_{1}-b_{0}}{2}
    \begin{bmatrix}
      G(t_{1},S_{1}) & G(t_{1},S_{2}) \\
      G(t_{2},S_{1}) & G(t_{2},S_{2})
    \end{bmatrix}
    X(S_{1},S_{2}),
  \end{equation}

  \juliacode{julia_code/coupled_splitting.jl}
  with $S_{1} = b_{0} + \frac{U}{2} (b_{1} - b_{0}) $ and
  $S_{2} = b_{0} + \frac{U+1}{2} (b_{1} - b_{0}) $.
  (\ref{RRVE:coupled splitting}) is unbiased in the following way:
  $X(t_{1},t_{2}) \cong [y(t_{1}) \quad y(t_{2})]^{T}$.

\end{example}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{plots/coupled_split.png}
  \caption{Recursive calls of (\ref{RRVE:coupled splitting}) when
  calling $X(0)$ once. We chose $X$ to have $20$ points and
  colored each call. The $S_{j}$ are coupled such that
  they are equally spaced.
  The initial conditions for this call are $y(-1)=e^{-1}$ and $y(1)=e^{1}$,
  with Russian roulette rate $l=1.2$. }
  \label{fig:coupled splitting}
\end{figure}

\begin{related}[Coupled splitting]
  Coupled splitting is partly inspired by the approach
  of \cite{sabelfeld_sparsified_2009}, which reduces
  variance by using larger submatrices in unbiased sparsification
  of matrices.
  Reusing samples for Walk on Spheres is discussed in both
  \cite{miller_boundary_2023} and \cite{bakbouk_mean_2023}.
\end{related}

Figure \ref{fig:coupled splitting}
resembles fixed-point iterations, leading us to hypothesize
that the convergence
speed is very similar to fix-points methods until the accuracy
of the stochastic approximation of the operator is reached
(the approximate operator bottleneck). The approximation of the operator
can be improved by increasing the coupled splitting amount when
approaching the bottleneck. Alternatively when reaching
the bottleneck it is possible to rely on splitting to converge.

\begin{related}[Convergence coupled splitting]
  See \cite{gupta_convergence_2021} for a discussion on the convergence
  of recursive stochastic algorithms.
\end{related}


\begin{related}[IBC integral equations]
  Optimal IBC is known for integral equations see \cite{heinrich_monte_1998}
  for the solution at $1$ point and the global solution.
\end{related}

\subsection{Initial Value Problems}
Classic IVP solvers rely on shrinking the time steps for
convergence. In this subsection, we introduce
Recursion in Recursion MC (RRMC) for IVPs which tries to emulate
this behavior.


\begin{example}[RRMC $y_t=y$] \label{ex:RRMC IVP}
  We demonstrate RRMC for IVPs with
  \begin{equation}
    y_t = y, \quad y(0) = 1.
  \end{equation}
  Imagine we have a time-stepping scheme $(t_{n}), \forall n: t_{n-1} < t_{n}$
  then the following integral equations hold:
  \begin{equation}
    y(t)= y(t_{n}) + \int_{t_{n}}^{t}y(s)ds , \quad t>t_{n}.
  \end{equation}
  Turn these in the following class of RRVEs:
  \begin{equation}
    y(t) \cong Y_{j}(t) = y(t_{j}) + (t-t_{j})Y_{j}((t-t_{j})U+t_{j}), \quad t>t_{j}.
  \end{equation}
  The problem with these RRVEs is that we do not know $y(t_{j})$.
  Instead, we can replace it with an unbiased estimate $y_{j}$
  which we keep fixed in the inner recursion:
  \begin{align}
    \label{eq:RRMC IVP inner}
    y(t) \cong Y_{j}(t)  & = y_{j} + (t-t_{j})Y_{j}((t-t_{j})U+t_{j}), \quad t>t_{j} \\
    y(t_{j}) \cong y_{j} & = \begin{cases}
                               Y_{j-1}(t_{j}) & \text{ if } j \neq 0 \\
                               y(t_{0})       & \text{ if } j = 0
                             \end{cases}.
    \label{eq:RRMC IVP outer}
  \end{align}
  \juliacode{julia_code/RRMC_IVP.jl}
  We refer to (\ref{eq:RRMC IVP inner}) as the inner recursion and
  (\ref{eq:RRMC IVP outer}) as the outer recursion of the recursion in
  recursion.
  The measured RMSE for estimating $y(t)$ is of the order
  $O\left(h^{1.5} \right)$, where $h$ represents
  the step size. For the implementation we used a scaled version
  of the time process from Example \ref{ex: russian roulette}
  for the inner recursion, such that the average number of total inner recursion calls
  is $e n$, where $n$ represents the total number of outer recursion calls.
\end{example}


\begin{conjecture}[local RMSE RMC]
  Consider a general linear IVP:
  \begin{equation}
    y_{t}(t)= A(t)y(t)+g(t), y(t_{0}),
  \end{equation}
  with $A$ a matrix and $g$ a vector function, both
  once Lipschitz differentiable with the corresponding RRVE:
  \begin{equation}
    y(t) \cong Y(t) = y(t_{0}) + h B \left( \frac{t-t_{0}}{h}\right)
    A(S) Y(S) + g(S),
  \end{equation}
  where $S \sim \text{Uniform}(t_{0},t)$. Then, the following relation holds:
  \begin{equation}
    E[||y(t_{1})-Y(t_{1})||^{2}] = O(h^{2}),
  \end{equation}
  with $t_{1} = t_{0} + h$.
\end{conjecture}


To achieve a higher order of convergence RRMC can be combined with control variates.
\begin{example}[CV RRMC $y_t=y$]\label{ex:CV RRMC IVP}
  Let us control variate Example \ref{ex:RRMC IVP}.
  \begin{equation}
    y(t)= y(t_{n}) + \int_{t_{n}}^{t}y(s)ds , \quad t>t_{n}.
  \end{equation}
  We build a control variate with a lower-order approximation
  of the integrand:
  \begin{align}
    y(s) & = y(t_{n}) + (s-t_{n})y_t(t_{n}) + O((s-t_{n})^{2})      \\
         & \approx y(t_{n}) + (s-t_{n})f(y(t_{n}),t_{n})            \\
         & \approx y(t_{n}) +
    (s-t_{n})\left(\frac{y(t_{n})-y(t_{n-1})}{t_{n}-t_{n-1}}\right) \\
         & \approx y(t_{n})(1+s-t_{n}). \label{eq:CVCV RRMC}
  \end{align}
  Using (\ref{eq:CVCV RRMC}) as a control variate for the integral:
  \begin{align}
    y(t) & = y(t_{n}) + \int_{t_{n}}^{t}y(s)ds                                          \\
         & = y(t_{n}) + \int_{t_{n}}^{t}y(s)-y(t_{n})(1+s-t_{n}) +y(t_{n})(1+s-t_{n})ds \\
         & = y(t_{n})\left(1 + (1-t_{n})(t-t_{n})+\frac{t^{2}-t_{n}^{2}}{2}\right)
    + \int_{t_{n}}^{t}y(s)-y(t_{n})(1+s-t_{n})ds. \label{eq: int CV RRMC}
  \end{align}
  Figure \ref{fig:CV RRMC IVP} displays the error
  of realizations of an RRVE constructed from (\ref{eq: int CV RRMC})
  for various step sizes.

  \begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{julia_plots/CV_RRMC_IVP.pdf}
    \caption{Log-log plot of the error for Example
      \ref{ex:CV RRMC IVP} at $Y(10)$.}
    \label{fig:CV RRMC IVP}
  \end{figure}
\end{example}

% \begin{related}[CV RRMC]
%   \cite{daun_randomized_2011} similarly uses control variates to achieve
%   a higher order of convergence.
% \end{related}

Similar to explicit solvers, RRMC performs poorly on stiff problems.
We attempted to make RRMC more like implicit solvers but this proved difficult.
Instead, we believe that an approach more like exponential integrators
is more viable.
% We experimented with Diagonal RRMC in this direction with
% little success.

% \begin{definition}[Diagonal RRMC] \label{def:DRRMC}
%     Consider a general linear ODE IVP problem:
%     \begin{equation}
%         x' = Ax+g, \quad x(0)= x_{0}.
%     \end{equation}
%     In some cases, repeatedly multiplying by matrix $A$ can lead to instability.
%     Diagonal RRMC attempts to address this issue by adding a positive diagonal matrix $D$
%     to matrix $A$ .

%     \begin{equation}
%         x' + Dx = (A+D)x+g.
%     \end{equation}

%     The following integral equation can be derived by using integrating factor:

%     \begin{equation}\label{eq:int eq DRRMC}
%         x(t)= e^{D(t_{n}-t)}x(t_{n}) + \int_{t_{n}}^{t} e^{D(s-t)}(A(s)+D)x(s)ds+\int_{t_{n}}^{t} e^{D(s-t)}g(s)ds.
%     \end{equation}

%     The recursive integral has the following trivial control variate:

%     \begin{equation}\label{eq: CV DRRMC}
%         \int_{t_{n}}^{t}  e^{D(s-t)}(A(t_{n})+D)x(t_{n})ds = D^{-1}(I-e^{D(t_{n}-t)})(A(t_{n})+D)x(t_{n}).
%     \end{equation}

%     Note that $D$ may be chosen differently for every outer recursion.
% \end{definition}

% \begin{example}[DRRMC] \label{ex:DRRMC}
%     Consider:
%     \begin{equation}
%         x'= Ax, x(0)=
%         \begin{bmatrix}
%             1 \\
%             0
%         \end{bmatrix}.
%     \end{equation}

%     With

%     \begin{equation}
%         A = \begin{bmatrix}
%             0     & 1     \\
%             -1000 & -1001
%         \end{bmatrix}.
%     \end{equation}

%     This has the following solution:

%     \begin{equation}
%         x(t) = \frac{1}{999}
%         \begin{bmatrix}
%             -  e^{-1000t}+ 1000 e^{-t} \\
%             1000 e^{-1000t}- 1000e^{-t}
%         \end{bmatrix}.
%     \end{equation}

%     We choose $D$ fixed across outer recursions:

%     \begin{equation}
%         D = \begin{bmatrix}
%             1 & 0    \\
%             0 & 1000
%         \end{bmatrix}.
%     \end{equation}

%     We make a convergence plot for this example with
%     (\ref{eq:int eq DRRMC}) with control variate
%     (\ref{eq: CV DRRMC}) implemented with recursion in recursion
%     on Figure \ref{fig:DRRMC}.

%     \begin{figure}[h!]
%         \centering
%         \includegraphics[width=0.8\textwidth]{plots/DRRMC.png}
%         \caption{Log-log plot of the error of Example \ref{ex:DRRMC}.
%             We plotted the second component of the error transparent.
%         }
%         \label{fig:DRRMC}
%     \end{figure}

% \end{example}

% \begin{related}[DRRMC]
%     DRRMC is inspired by the $\bar{\sigma}$ parameter in \cite{sawhney_grid-free_2022}.
%     However, instead of relying on importance sampling, we employ control
%     variates to address the nonlinearity introduced by the exponential
%     function.
% \end{related}


\section{Partial Differential Equations}

In this section we discuss how to solve ODEs derived from the semi-discretized heat equation
with Dirichlet boundary conditions in $1$ point and acceleration with recursive first-passage sampling
combined with presampled path stitching.

\subsection{Heat Equation}
\begin{definition}[1D heat equation Dirichlet] \label{def:heat equation square}
  We define the 1D heat equation for $u(x,t)$ with $ (x,t) \in \Omega = [0,1]^2$
  with Dirichlet boundary conditions the following way:
  \begin{align}
    \frac{\partial u}{\partial t} & = \frac{\partial^{2} u}{\partial x^{2}}  \Leftrightarrow   \\
    u_t(x,t)                      & = u_{xx}(x,t), \quad \forall (x,t) \in \Omega = [0,1]^2  .
  \end{align}
  Given $\left\{u(x,0),u(1,t),u(0,t) | \forall x,t \in [0,1]  \right\} $.
\end{definition}

\begin{definition}[Semi-discretization 1D heat equation Dirichlet] \label{def:discrete heat equation square}
  We define the semi-discretization 1D heat equation for $\tilde{u}$ as space discretized heat equation
  using the central difference scheme:
  \begin{equation}
    \tilde{u}_t(j \Delta x,t)  = \frac{\tilde{u}((j+1) \Delta x, t)-2\tilde{u}(j \Delta x, t)+\tilde{u}((j-1) \Delta x, t)}{\Delta x^{2}}
  \end{equation}
  $\forall (j,t) \in \{0, 1, \ldots, N\} \times [0,1]$. \\
  Given $\left\{\tilde{u}(j \Delta x,0),\tilde{u}(1,t),\tilde{u}(0,t) | \forall j \in \{0, 1, \ldots, N\}, \forall t \in  [0,1]  \right\} $.

  It is well-known that the solution to the semi-discretization 1D heat equation converges to the solution of the 1D heat equation with
  corresponding boundary conditions as $\Delta x \rightarrow 0$.
\end{definition}



\begin{example}[Point estimator of \ref{def:discrete heat equation square}] \label{ex: point estimator of semi heat}
  We want a point estimator for the solution to the semi-discretization 1D heat equation. Apply (\ref{eq:poisson main})
  with $\sigma = \frac{2}{\Delta x^{2}}$ at interior point $j$ this is:
  \begin{equation}
    \tilde{u}(j \Delta x,t) = \int_{0}^{e^{-\frac{2t}{\Delta x^{2}}}}  \tilde{u}(j \Delta x,0) d\tau+
    \int_{e^{-\frac{2t}{\Delta x^{2}}}}^{1} \frac{\tilde{u}((j+1) \Delta x,s)+\tilde{u}((j-1) \Delta x,s)}{2}d\tau. \label{eq:int semi heat}
  \end{equation}
  This can be turned into an estimator $Y(j \Delta x,t,\Delta x ) \cong  \tilde{u}(j \Delta x,t)$
  by sampling $\tau \sim U$,
  sampling either $\tilde{u}((j+1) \Delta x,s)$ or $\tilde{u}((j-1) \Delta x,s)$ to avoid branching recursion and
  terminating recursion when either hitting the boundary condition or sampling the first integral. Either sampling
  $\tilde{u}((j+1) \Delta x,s)$ or $\tilde{u}((j-1) \Delta x,s)$ loses
  the convergence in $\sigma$ demonstrated in Figure \ref{fig:main poisson convergence}.
\end{example}

\begin{julia}[Implementation of estimator of (\ref{eq:int semi heat})]\label{jl:point estimator heat}

  \juliacode{julia_code/point_estimator_heat_tail.jl}

  $Y(j \Delta x,t,\Delta x )$ is just the boundary condition
  for the first passage point from the time space domain for a Poisson time process and a random walk in space.
  Therefore if the boundary conditions are bounded, $Y(j \Delta x,t,\Delta x )$ is bounded and has bounded variance.
  In this implementation as  $\Delta x \rightarrow 0$  the cost of calculating the first passage time grows
  $\approx O(\Delta x ^{-2})$ and the process converges to Brownian motion. Note that the estimator needs
  only $1$ function call from the boundary conditions.

\end{julia}

\begin{example}[\ref{ex: point estimator of semi heat} + source + coefficients] \label{ex:semi heat source}

  Consider the equations in \ref{def:discrete heat equation square} with a source term and $0$-order coefficients, the
  semi-discretization of:
  \begin{equation}
    u_{t} = u_{xx} + a(x,t)u + f(x,t)
    .
  \end{equation}
  Again by applying (\ref{eq:poisson main}) with $\sigma = \frac{2}{\Delta x^{2}} +a_{0}$
  we obtain at an interior point:
  \begin{equation} \label{eq:int semi heat source}
    \tilde{u} =
    \int_{0}^{e^{-t \sigma }} \tilde{u}_{0} d\tau  + \int_{e^{-t \sigma }}^{1}
    \sigma^{-1}
    \left(
    \frac{\tilde{u}_{+} + \tilde{u}_{-}}{\Delta x^{2}} +(a(x,s)+ a_{0}) \tilde{u}+ f
    \right)
    d\tau
    .
  \end{equation}

  This can be turned into a estimator $Y(j \Delta x,t,\Delta x ) \cong  \tilde{u}(j \Delta x,t)$
  by sampling $\tau \sim U$.
  To avoid branching recursion we sample
  based on the magnitude of coefficients of the recursive terms, let $a_m$ be approximately the magnitude of
  $(a(x,s)+ a_{0})$. We chose to sample the $(a(x,s)+ a_{0})\tilde{u}$ term and $f$
  with probability $p_{\text{source}} = \frac{a_m}{a_m + \frac{2}{\Delta x^{2}}}$.
  As $\Delta x \rightarrow 0$ the $\frac{\tilde{u}_{+} + \tilde{u}_{-}}{\Delta x^{2}}$ term is
  the main contribution to the second integral therefore
  being sampled almost always.
  In total for $1$ fully recursed sample,
  the $f(x,s)$ and the $(a(x,s)+ a_{0})\tilde{u}$ term only
  is sampled a few times and this does not scale with $\Delta x$. We
  sampled $f$ together with $(a(x,s)+ a_{0})\tilde{u}$ for simplicity.

\end{example}

\begin{julia}[Implementation of estimator of (\ref{eq:int semi heat source})]\label{jl:point estimator heat source}
  Because of the high chance of sampling the $\frac{\tilde{u}_{+} + \tilde{u}_{-}}{\Delta x^{2}}$ it is efficient
  to sample the interarrival until not sampling it which is geometrically distributed.

  \juliacode{julia_code/pest_heat_varcoef.jl}
\end{julia}

Computing the estimator requires knowing more then the first passage point
unlike Example \ref{ex: point estimator of semi heat} but this is limited
to a few points of the time space process and this amount does not scale with $\Delta x$.


\begin{technique}[Presampling the process of \ref{jl:point estimator heat source}] \label{tech:presampling heat}
  As $\Delta x \rightarrow 0$ the bottleneck is sampling the process that moves through space and time.
  This process is independent of the boundary conditions, $a(x,t)$ and $f(x,t)$. So it is possible to
  precompute samples of the process and reuse them.
  Reusing paths makes the solutions correlated. To compute the estimator we need to know where we sampled the
  source term to update $sol$ and $w$, how many steps we took in between to update $w$ for the
  multiplications in not source points (line 13 of \ref{jl:point estimator heat source})
  and where termination happens.

  \juliacode{julia_code/genpath_pest_heat_varcoef.jl}

  Paths for smaller $\tilde{a}_{m}$'s can be obtained by thinning the Bernoulli process,
  by rejecting source points with probability $\frac{\tilde{a}_{m}}{a_{m}}$. As $\Delta x \rightarrow 0$
  $genPath$ converges, the dependence on $a_{0}$ also disappears. For the heat equation
  $genPath$ presampled paths only depend on geometry and the starting point.

  \begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{./julia_plots/paths_pest_heat_varcoef.pdf}
    \caption{$20$ samples of genPath$(x=0.5,t=0.15,dx=\{0.1,0.001\},a_{0}=0,a_{m} = 30)$. The source term is sampled
    at the intermediate points. Note that the amount of
    intermediate points does not differ much between $\Delta x = 0.1$ and $\Delta x = 0.001$.
    Points with $t<0$ do not cause any bias, the method is unbiased for the semi-discretized heat equation. }
    \label{fig:presampled paths pest heat var}
  \end{figure}

\end{technique}

\begin{julia}[\ref{jl:point estimator heat source} using precomputed paths]\label{jl:path point estimator heat source}
  We implement \ref{jl:point estimator heat source} with a precomputed path from \ref{tech:presampling heat} using tail
  recursion. Note that $(x,t)$ is
  never explicitly used, only for figuring out how we exited the domain. The whole calculation is linear in
  $a,f$ evaluated in the source points and $u_\text{bound}$ evaluated in the exit points so there are various
  ways to optimize it for example using unbiased estimates instead of exact evaluations.

  \juliacode{julia_code/path_pest_heat_varcoef.jl}
\end{julia}




\subsection{First Passage Sampling}

In this subsection we discuss recursive first passage sampling to efficiently
first passage sample complicated geometries.


\begin{definition}[First passage time] \label{def:first passage time}
  Define the first passage time for a process $X_{t}$ for a set of valid states
  $V$ as
  \begin{equation}
    \text{FPt}(X_{t},V)=\inf \{t>0| (X_{t},t) \notin V \}
    .
  \end{equation}
  Note that the first passage time is a RV itself.
\end{definition}

\begin{definition}[First passage] \label{def:first passage}
  Define the first passage for a process $X_{t}$ for a set of valid states
  $V$ as
  \begin{equation}
    \text{FP}(X_{t},V)=(X_{\tau},\tau), \tau = \text{FPt}(X_{t},V)
    .
  \end{equation}
\end{definition}

\begin{lemma} \label{lem: FP order}
  When a process has more valid states the first passage time gets larger i.e.
  \begin{equation}
    V_{1} \subset V_{2} \Rightarrow
    \text{FPt}(X_{t}(\omega),V_{1}) \le  \text{FPt}(X_{t}(\omega),V_{2}) .
  \end{equation}
  The $\omega$ is to indicate the same realization of $X_{t}$.
\end{lemma}

\begin{theorem}[Green's functions and first passage distribution]
  The density of first passages of Code \ref{jl:point estimator heat} is the
  corresponding Dirichlet boundary Green's function for the semi-discretized heat equation.
\end{theorem}

% notation for the Green's function is bad
\begin{proof}
  Follows directly from the definition.
  Let $P(x,t|x_{0},t_{0})$ denote the boundary Green's
  function for the semi-discretized heat equation and $X_{t}$
  the corresponding space time process.
  \begin{align}
    P(x,t|x_{0},t_{0}) & = E[Y(x_0,t_0)]                                         \\
                       & = E[\tilde{u}(X_{\tau},\tau) | X_{t_0} = x_0 ]          \\
                       & = E[\delta_{((X_{\tau},\tau) = (x,t))}| X_{t_0} = x_0 ] \\
                       & = P((X_{\tau},\tau) = (x,t)| X_{t_0} = x_0 )
    .
  \end{align}
\end{proof}


Another way to obtain an unbiased estimator for the semi-discretized heat equation is using unbiased estimates
of the boundary Green's boundary function. Because of:
\begin{align}
  \tilde{u}(x_{0},t_{0}) & = \int_{\partial \Omega} \tilde{u}(x,t) P(x,t|x_{0},t_{0}) d(x,t)                    \\
                         & = \int_{\partial \Omega} \tilde{u}(x,t)  dP((X_{\tau},\tau) = (x,t)| X_{t_0} = x_0 )
  .
\end{align}

\begin{related}[Recursively estimating Green's functions]
  In \cite{qi_bidirectional_2022} unbiased estimators for the boundary Green's function are constructed
  by recursively sampling known Green's functions.
\end{related}

Similar to recursively  sampling simpler Green's function we recursively sample first passages.

\begin{technique}[Recursive first passage sampling]
  Recursive first passage sampling involves sampling an initial,
  simpler first passage, the base that includes fewer valid states. Using
  this sampled first passage as a starting point, we
  then perform the same sampling process until the sampled
  first passage is almost invalid.
\end{technique}

\begin{example}[Euler first passage sampling] \label{ex:euler first passage sampling}
  In this example, we approximately sample the first passage of Brownian motion
  for a parabolic barrier by simulating Brownian motion with the Euler scheme. We plotted
  this in Figure \ref{fig:Euler first passage para}. The accuracy of the sampled first passage
  are $O(\Delta t)$ and the cost to sample is $O(\Delta t ^{-1})$.

  \juliacode{julia_code/sample_euler_triangle.jl}
  \begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plots/Euler_first_passage_para.png}
    \caption{ $50$ realizations of Euler first passage sampling with step size $0.001$.}
    \label{fig:Euler first passage para}
  \end{figure}
\end{example}


\begin{example}[Recursive first passage sampling] \label{ex:recursive first passage sampling}
  In this example, we sample the first passage of Brownian motion from a parabolic barrier
  with recursive first passage sampling.
  For the simpler first passage sampler, we  exploit the self-affinity of Brownian motion
  ($\frac{W_{ct}}{\sqrt{c}} \sim W_{t}$)
  by scaling and translating
  samples from a triangular barrier so its
  valid states are contained in the parabola generated
  by the Euler scheme. The precomputed samples are created
  by \ref{ex:euler first passage sampling}.
  Assuming that the error of the base sampler is insignificant.
  The accuracy of the sampled first passage
  are $O(\varepsilon)$ and the cost to sample is $O(\ln \left(\varepsilon^{-1}\right))$.
  Note that resampling with replacement produces dependent samples and introduces additional error.
  For MC applications dependence is not an issue and when the additional error is significant resampling
  without replacement can be used.

  \juliacode{julia_code/sample_recu_para.jl}
  When the domain is convex, the maximum scaling of the triangular barrier that fits
  is easier to obtain.
  To dampen barrier
  overstepping of \ref{ex:euler first passage sampling} we use a smaller scaling
  than the maximum.

  \begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{plots/recursive_first_passage_para.png}
    \caption{ $50000$ of realizations of recursive first passage sampling produced
      by (\ref{ex:recursive first passage sampling}). The precomputed sample of $5000$ first
      passages of a triangular barrier uses the Euler scheme with
      step size $0.001$.}
    \label{fig:recursive first passage para}
  \end{figure}

\end{example}

\begin{related}[Recursive first passage sampling]
  Walk on Spheres see \ref{ex: walk on spheres} is a recursive first passage algorithm.
  Recursive first passage sampling for
  Brownian motion is discussed in \cite{herrmann_first-passage_2016}
  and by transformation also first passage problems for the
  Ornstein-Uhlenbeck process.
  % To add jumps you can use \cite{herrmann_exact_2021}.
  An alternative to resampling from an Euler scheme is to use tabulated
  inverse cumulative probability functions,
  as demonstrated in \cite{hwang_simulationtabulation_2001}.
\end{related}


\begin{technique}[Brownian motion path stitching]
  Sampling approximate Brownian motion paths also can be
  framed as a first passage problem. Instead of sampling
  first passage points we sample first passage paths.
  This requires a simple first passage paths sampler and the paths
  sampled this way are stitched together.
\end{technique}

\begin{example}[Path stitching parabola]
  Example \ref{ex:recursive first passage sampling} but
  resampling full Euler scheme generated paths.
  The advantages over generating paths directly from
  the Euler scheme are that computations for all small steps from the
  base sampler are avoided and the full path
  can be represented by its subpaths and their scalings
  requiring less memory than a fully stored path.
  The only downsides are correlation between paths and
  inhomogeneous time steps.

  \begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{plots/path_stitching_para.png}
    \caption{ $10$ paths build with path stitching build out of
      resampled Euler scheme generated paths with step size $0.01$.}
    \label{fig:path stitching para}
  \end{figure}
\end{example}


\begin{related}[Path stitching]
  Path stitching appears frequently in rendering and also in \cite{das_sarma_fast_2015}
  and \cite{ji_reusing_2012}.
\end{related}

% Path stitching combined with resampling paths for applied to the semi-discretized heat equation can be
% interpreted as estimation with a U-statistic. The recursive path is a stitching of scaled i.i.d. subpaths.


\section{Limitations and Future Work}

In this section, we discuss limitations of our work and propose potential future work.
Some parts are underdeveloped, unexplored, or insufficiently integrated
into the existing body of literature. At the time of writing this thesis, our
primary reference was the Walk on Spheres literature. We independently rediscovered
the improved random convergence of integration and IVPs, the
use of a Poisson process to circumvent recursion (as shown in \ref{jl:main poisson}),
and the recursive estimator for $e^{E[X]}$ (as demonstrated in example \ref{ex:exp int}).
These discoveries subsequently led us to other relevant literature. \\

The section on RRMC was written before we discovered algorithm \ref{jl:main poisson}.
It may be possible to circumvent recursion in RRMC similar to algorithm \ref{jl:main poisson}.
Our application of
recursion in recursion in RRMC for IVPs is primarily aimed at achieving convergence behavior
akin to classical solvers, while maintaining unbiasedness. This recursive approach allows us to
'freeze' terms in the outer recursion without bias. The next logical step would be
to attempt 'freezing' terms that vary slowly. We believe that RRMC, even after optimizations, would
be useful in specific use cases. Furthermore, insights from unbiased algorithms could
help develop biased algorithms. \\

Our techniques for linear IVPs are based on transforming to integral equations which should be extendable
to linear delay differential equations. Another potential direction involves directly estimating
the Magnus expansion, where unbiased estimators for $e^{\int_{0}^{\Delta t} A(s)ds} y(0)$ are required.
This is related to work on evaluating matrix functions with Monte Carlo methods, as seen in \cite{guidotti_fast_2023}. \\

In subsection \ref{sec:greens functions}, we developed global integral equations for a test problem.
Despite the inherent local nature of ODEs, we are curious whether this locality is retained in the global integral equations.
More specifically, we are interested in whether this local nature can be leveraged to enhance the efficiency of
estimators solving these global integral equations, even without knowledge of the original ODEs.  \\

Coupled splitting's convergence behavior and unbiasedness at each iteration are key attributes.
However, the use of recursion and Russian roulette in its implementation poses practical challenges.
Despite these challenges, numerous opportunities exist to further optimize the performance of coupled splitting
with typical MC techniques.

We employed the adjoint main Poisson method \ref{jl:adjoint main poisson} as the foundation for deriving our
point estimators for the heat equation. However, it remains uncertain which class of problems can be addressed
by the adjoint main Poisson method in a manner similar to the heat equation.
% maybe I should add this
We have not fully discussed how to combine presampling with path stitching and when it is possible to do so.
We think that this can be interpreted as U-statistic with i.i.d. subpaths. \\


% We believe that understanding and optimizing unbiased and deterministic linear ODE solvers
% is the key to developing better randomized ODE/PDE solvers.
% Randomized ODE/PDE solvers are useful for cases with little structure
% where the advantage of IBC is significant or where the linear trade-off
% between cost and variance is close to optimal. \\

% Besides the time process, other areas of development could
% include the cheaper construction of control variates,
% different types of control variates, adaptive schemes,
% freezing less important terms in the inner recursion or Russian rouletting
% them into reasonable approximations, error estimates based on variance in the
% inner recursion, etc. \\

% To handle stiff problems we weigh towards exponential integrators
% type of methods. The biggest obstacle to implementing them similar to diagonal RRMC
% is getting unbiased estimates of $e^{A(t-s)} y(s)$ type of expressions. In the case
% of a big matrix $A$  unbiased sparsifaction will probably be useful
% see \cite{sabelfeld_sparsified_2009}.
% Initially, we came up with Example \ref{ex:exp int}, but some time later,
% we found the paper from NVIDIA \cite{kettunen_unbiased_2021} that optimizes
% that example. Closely related to this is directly estimating the Magnus expansion,
% where expressions like $e^{\int_{0}^{\Delta t} A(s)ds} y(0)$ are needed.
% In this case, \cite{kettunen_unbiased_2021} doesn't utilize the smoothness of
% $A(s)$, which is necessary
% for optimal IBC.

One of the elements lacking in our findings is rigor.
\cite{ermakov_monte_2021} presents Theorems $1$ and $2$ to
show that their estimators have finite variance and provide an expression for it.
Before becoming aware of \cite{ermakov_monte_2021}, we
previously attempted to derive an expression for the variance
by employing the law of total variance, similar to (16) in \cite{rath_ears_2022}. \\
We believe that proving the optimality of IBC in Example \ref{ex:CV RRMC IVP} is feasible
but tedious.
\cite{daun_randomized_2011} presented a proof for optimal IBC for their algorithm.
The proof we have in mind is using a lower bound on IBC
from integration and proving it is attained.\\

% Optimal IBC isn't everything. Being optimal in IBC doesn't necessarily mean it's optimized.
% An algorithm that uses $1000$ times more function calls may still have the same
% IBC. Additionally, the computational goal
% might not align well with the IBC framework.
% We admire \cite{becker_learning_2022},
% which employs deep learning to extend beyond the IBC framework.
% The emphasis here is on performing multiple rapid solves (inferences)
% while allowing for an expensive precomputation (training).
% IBC also doesn't take into account the parallel nature of computations.
% Given infinite parallel resources, it would be reasonable to cease reducing
% variance by decreasing the step size and instead opt for splitting the final estimator.
% The only necessary communication in splitting is averaging the final
% estimator. We hypothesize that for RMC, the wall time at risk
% increases logarithmically with the size of the splitting.



\newpage
\begin{abstract}
  \input{dutch_abstract.tex}
\end{abstract}

\printbibliography
\newpage

\end{document}

% Base your answers on the thesis.  
% You are expert in solving ODEs, WoS, IBC, PDEs giving feedback.
%
% Answer as a markdown file.
% Use subnumerings in mark down form in numbering the question 
% that works in a markdown file and use different headers. Like this: 
%
% # Content tests
% ##  0.1. How does the main algorithm work of the thesis?
% answer
%
% Here are the questions : 
% # Content tests
% 0.1. How does the main algorithm work of the thesis?
% 0.2. What is the biggest limitation of the main algorithm of the thesis?
% 0.3. How important is coupled splitting to the thesis?
% 0.4. How does Stein's paradox pop up in the thesis? (see subsection on MC integration)
% 0.5. Rate the language of the thesis.
% 0.6. List the 5 unclearest parts of the thesis.
% 0.7. What is special about the Monte Carlo trapezoidal rule?
% 0.8. What is the main advantage of the primary motivating work? 
% 0.9.  How does the thesis define Russian Roulette?
% 0.10. How does the thesis define control variates?
% 0.11. Summarize the approach for exponential of the expectance in the unbiased non-linearity section.
% 0.12. How does the thesis define tail recursion?
% 0.13. How does the thesis define Green's functions? 
% 0.14. Summarize convergence behavior of the main algorithm.
% 0.15. List your 5 favorite/intrestring parts of the thesis.
% 0.16. What seem to be missing in the thesis?
% 0.17. Any abbreviation that should/shouldn't be used?
% 0.18. List 5 inaccuracies things in the thesis.
% 0.19. List 5 controversial things in the thesis.
% 0.20. List 5 suggestions to improve the thesis.
%
% # Feedback 1
% 1.1 Does the thesis differentiate between the original contributions and prior work? 
% 1.2 Does the thesis has a good overview?
% 1.3 Does the thesis has a good conclusion?
% 1.4 Does everything gets defined in the thesis?
% 1.5 Are there symbols that don't get defined in the thesis?
% 1.6 What are the advantages of the solvers in the subsection of initial value problems 
% compared to classical solver?
% 1.7 Are the explanations for the graphs in the thesis sufficient?
% 1.8 Do equations, examples, definition, etc get referenced with consistent notation?
% 1.9 List 2 uncommon abbreviations that don't get introduced the first time they get used. 
%
% # Feedback 2
% 2.1 Has the elementary theory of Monte Carlo been covered in the thesis?
% 2.2 In the subsection of recursive Monte Carlo why is there indefinite 
% recursion?
% 2.3 Does the thesis give the necessary references to concepts?
% 2.4 Does additive branching gets explained clearly?
% 2.5 What is the Russian roulette rate ?
% 2.6 Does the local truncation error get defined ?

% # Requirements
% 3.1 Title Page: Does the thesis have a title page? 
% 3.2 Table of Contents: Does the thesis include a table of contents?
% 3.3 Introduction: 
%     Does the introduction provide a clear context for the research?
%     Is the problem statement or research question clearly formulated in the introduction?

% 3.4 Exposition:
%     Is the argumentation detailed and logical, leading to the final result of the research?
%     Is the substructure effectively used to organize and clarify the content within the exposition?

% 3.5 Dutch Summary:

%     Does the thesis include a Dutch summary?
%     Is the Dutch summary concise, effectively summarizing the main points of the thesis within the specified page limit?

% 3.6 Bibliography:

%     Is the bibliography section present and well-structured?
%     Are all the cited sources accurately listed in the bibliography according to the specified citation style?

% 3.7 Layout and Readability:
%   - Is the layout designed to enhance readability, including appropriate font, line spacing, and paragraph structure?
%   -  Is the use of headings, subheadings, and other formatting elements consistent and effective in guiding the reader through the content?

% 3.8 Language Quality:
% - Is the language used throughout the thesis refined and well-crafted?
% - Are grammar, spelling, and punctuation accurate?

% 3.9 Results and Analysis:

% - Are the results presented clearly and comprehensively?
% - Is the analysis of the results thorough, and do the conclusions logically follow from the data?

% 3.10 Argumentation and Coherence:

% - Is there a clear and logical progression of ideas throughout the thesis?
% - Do transitions between sections and paragraphs enhance the overall coherence of the document?

% 3.11 Original Contribution:
% - Does the thesis make a unique and valuable contribution to the field of study?
% - Is there a clear statement about how the research fills a gap in existing knowledge?

% 3.12 Discussion and Implications:
% - Does the discussion section provide insights into the broader implications of the research findings?
% - Are any practical applications or future research directions suggested?

% 3.13 Clarity and Conciseness:
% - Is the writing style clear and concise, avoiding unnecessary jargon?
% - Are complex concepts explained in a way that is understandable to the intended audience?

% 3.14 Overall Contribution:
% - Does the thesis contribute significantly to the field's body of knowledge and understanding?
% - Is the thesis likely to be cited and referenced by others in the field?

